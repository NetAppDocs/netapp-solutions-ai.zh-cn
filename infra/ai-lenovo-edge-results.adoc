---
sidebar: sidebar 
permalink: infra/ai-lenovo-edge-results.html 
keywords: test, results, aff, offline, single-stream, ef 
summary: '我们进行了大量的测试来评估所提出的架构的性能。有六种不同的工作负载（图像分类、对象检测 [小]、对象检测 [大]、医学成像、语音转文本和自然语言处理 [NLP]），您可以在三种不同的场景中运行 - 离线、单流和多流。' 
---
= 测试结果
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
我们进行了大量的测试来评估所提出的架构的性能。

有六种不同的工作负载（图像分类、对象检测[小]、对象检测[大]、医学成像、语音转文本和自然语言处理[NLP]），您可以在三种不同的场景中运行：离线、单流和多流。


NOTE: 最后一种场景仅用于图像分类和对象检测。

这给出了 15 种可能的工作负载，它们都在三种不同的设置下进行了测试：

* 单服务器/本地存储
* 单服务器/网络存储
* 多服务器/网络存储


结果在以下章节中描述。



== AFF离线场景下的AI推理

在这种情况下，所有数据都可供服务器使用，并且测量了处理所有样本所需的时间。我们将每秒样本的带宽作为测试结果进行报告。当使用多台计算服务器时，我们会报告所有服务器的总带宽。下图显示了所有三个用例的结果。对于双服务器的情况，我们报告两台服务器的组合带宽。

image:ai-edge-012.png["该图显示输入/输出对话框或表示书面内容"]

结果表明，网络存储不会对性能产生负面影响——变化很小，对于某些任务来说，没有发现任何变化。当添加第二台服务器时，总带宽要么正好翻倍，要么在最坏的情况下，变化小于 1%。



== AFF单流场景下的 AI 推理

该基准测量延迟。对于多计算服务器的情况，我们报告平均延迟。下图给出了这组任务的结果。对于双服务器的情况，我们报告两台服务器的平均延迟。

image:ai-edge-013.png["该图显示输入/输出对话框或表示书面内容"]

结果再次表明，网络存储足以处理这些任务。在一台服务器的情况下，本地存储和网络存储之间的差异很小或者没有。类似地，当两台服务器使用相同的存储时，两台服务器上的延迟保持不变或变化很小。



== AFF多流场景下的 AI 推理

在这种情况下，结果是系统在满足 QoS 约束的同时可以处理的流的数量。因此，结果始终是一个整数。对于多台服务器，我们报告所有服务器上的流总数。并非所有工作负载都支持此场景，但我们执行了支持此场景的工作负载。下图总结了我们的测试结果。对于双服务器的情况，我们报告来自两个服务器的流的总数。

image:ai-edge-014.png["该图显示输入/输出对话框或表示书面内容"]

结果显示该设置的性能完美——本地和网络存储给出相同的结果，并且添加第二台服务器使建议的设置可以处理的流数量增加一倍。



== EF 测试结果

我们进行了大量的测试来评估所提出的架构的性能。有六种不同的工作负载（图像分类、对象检测[小]、对象检测[大]、医学成像、语音转文本和自然语言处理[NLP]），它们在两种不同的场景中运行：离线和单流。结果在以下章节中描述。



=== EF 离线场景下的 AI 推理

在这种情况下，所有数据都可供服务器使用，并且测量了处理所有样本所需的时间。我们将每秒样本的带宽作为测试结果进行报告。对于单节点运行，我们报告两台服务器的平均值，而对于双服务器运行，我们报告所有服务器的总带宽总和。用例的结果如下图所示。

image:ai-edge-015.png["该图显示输入/输出对话框或表示书面内容"]

结果表明，网络存储不会对性能产生负面影响——变化很小，对于某些任务来说，没有发现任何变化。当添加第二台服务器时，总带宽要么正好翻倍，要么在最坏的情况下，变化小于 1%。



=== EF 单流场景下的 AI 推理

该基准测量延迟。对于所有情况，我们报告运行中涉及的所有服务器的平均延迟。给出了这一系列任务的结果。

image:ai-edge-016.png["该图显示输入/输出对话框或表示书面内容"]

结果再次表明网络存储足以处理这些任务。在一台服务器的情况下，本地存储和网络存储之间的差异很小或者没有。类似地，当两台服务器使用相同的存储时，两台服务器上的延迟保持不变或变化很小。
