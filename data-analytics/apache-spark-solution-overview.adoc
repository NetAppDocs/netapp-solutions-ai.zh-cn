---
sidebar: sidebar 
permalink: data-analytics/apache-spark-solution-overview.html 
keywords: introduction, overview, 4570, tr4570, customer challenges, justification 
summary: 本文档重点介绍 Apache Spark 架构、客户用例以及与大数据分析和人工智能相关的NetApp存储产品组合。它还展示了使用行业标准 AI、机器学习和深度学习工具针对典型 Hadoop 系统进行的各种测试结果，以便您可以选择合适的 Spark 解决方案。 
---
= TR-4570：适用于 Apache Spark 的NetApp存储解决方案：架构、用例和性能结果
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


Rick Huang，Karthikeyan Nagalingam， NetApp

[role="lead"]
本文档重点介绍 Apache Spark 架构、客户用例以及与大数据分析和人工智能 (AI) 相关的NetApp存储产品组合。它还展示了使用行业标准 AI、机器学习 (ML) 和深度学习 (DL) 工具针对典型 Hadoop 系统进行的各种测试结果，以便您可以选择合适的 Spark 解决方案。首先，您需要一个 Spark 架构、适当的组件和两种部署模式（集群和客户端）。

该文档还提供了解决配置问题的客户用例，并讨论了与大数据分析以及 Spark 的 AI、ML 和 DL 相关的NetApp存储产品组合的概述。然后，我们得到来自 Spark 特定用例和NetApp Spark 解决方案组合的测试结果。



== 客户挑战

本节重点关注零售、数字营销、银行、离散制造、流程制造、政府和专业服务等数据增长行业中客户面临的大数据分析和 AI/ML/DL 挑战。



=== 不可预测的表现

传统的 Hadoop 部署通常使用商品硬件。为了提高性能，您必须调整网络、操作系统、Hadoop 集群、生态系统组件（如 Spark）和硬件。即使您调整每一层，也很难达到所需的性能水平，因为 Hadoop 运行在并非为您的环境的高性能而设计的商用硬件上。



=== 介质和节点故障

即使在正常条件下，商品硬件也容易出现故障。如果数据节点上的一个磁盘发生故障，则 Hadoop 主服务器默认认为该节点不健康。然后，它通过网络将该节点上的特定数据从副本复制到健康节点。此过程会减慢任何 Hadoop 作业的网络数据包速度。当不健康的节点恢复健康状态时，集群必须再次复制数据并删除过度复制的数据。



=== Hadoop供应商锁定

Hadoop 分销商拥有自己的 Hadoop 发行版和版本控制，从而将客户锁定在这些发行版上。然而，许多客户需要内存分析支持，而这种支持不会将客户绑定到特定的 Hadoop 发行版。他们需要自由地改变分布，同时仍然保留他们的分析能力。



=== 缺乏对多种语言的支持

客户通常需要除了 MapReduce Java 程序之外的多种语言支持来运行他们的作业。  SQL 和脚本等选项为获取答案提供了更大的灵活性，为组织和检索数据提供了更多的选项，以及将数据移动到分析框架的更快的方式。



=== 使用难度

一段时间以来，人们一直抱怨 Hadoop 难以使用。尽管 Hadoop 的每个新版本都变得更简单、更强大，但这种批评仍然存在。  Hadoop 要求您了解 Java 和 MapReduce 编程模式，这对数据库管理员和具有传统脚本技能的人员来说是一个挑战。



=== 复杂的框架和工具

企业AI团队面临多重挑战。即使拥有专业的数据科学知识，不同部署生态系统和应用程序的工具和框架也可能无法简单地从一个转换到另一个。数据科学平台应该与基于 Spark 构建的相应大数据平台无缝集成，易于数据移动、可重复使用的模型、开箱即用的代码以及支持原型设计、验证、版本控制、共享、重用和快速将模型部署到生产的最佳实践的工具。



== 为什么选择NetApp？

NetApp可以通过以下方式改善您的 Spark 体验：

* NetApp NFS 直接访问（如下图所示）允许客户在其现有或新的 NFSv3 或 NFSv4 数据上运行大数据分析作业，而无需移动或复制数据。它可以防止数据的多次复制，并且无需将数据与源同步。
* 更高效的存储和更少的服务器复制。例如， NetApp E 系列 Hadoop 解决方案需要两个而不是三个数据副本，而FAS Hadoop 解决方案需要一个数据源，但不需要数据复制或副本。  NetApp存储解决方案还能减少服务器之间的流量。
* 驱动器和节点故障期间的 Hadoop 作业和集群行为更好。
* 更好的数据提取性能。


image:apache-spark-001.png["替代的 Apache Spark 配置。"]

例如，在金融和医疗保健领域，数据从一个地方移动到另一个地方必须满足法律义务，这不是一件容易的事。在这种情况下， NetApp NFS 直接访问会从原始位置分析财务和医疗保健数据。另一个主要优势是，使用NetApp NFS 直接访问可以通过使用本机 Hadoop 命令简化 Hadoop 数据的保护，并利用NetApp丰富的数据管理产品组合实现数据保护工作流。

NetApp NFS 直接访问为 Hadoop/Spark 集群提供了两种部署选项：

* 默认情况下，Hadoop 或 Spark 集群使用 Hadoop 分布式文件系统 (HDFS) 进行数据存储和默认文件系统。  NetApp NFS 直接访问可以用 NFS 存储替换默认的 HDFS 作为默认文件系统，从而实现对 NFS 数据的直接分析。
* 在另一个部署选项中， NetApp NFS 直接访问支持在单个 Hadoop 或 Spark 集群中将 NFS 与 HDFS 一起配置为附加存储。在这种情况下，客户可以通过 NFS 导出共享数据，并从同一个集群访问数据以及 HDFS 数据。


使用NetApp NFS 直接访问的主要优势包括：

* 从当前位置分析数据，从而避免将分析数据移动到 Hadoop 基础架构（如 HDFS）这一耗时耗能的任务。
* 将副本数量从三个减少到一个。
* 使用户能够分离计算和存储以独立扩展它们。
* 利用ONTAP丰富的数据管理功能提供企业数据保护。
* 通过 Hortonworks 数据平台认证。
* 支持混合数据分析部署。
* 利用动态多线程功能减少备份时间。


看link:hdcs-sh-solution-overview.html["TR-4657： NetApp混合云数据解决方案 - 基于客户用例的 Spark 和 Hadoop"^]用于备份 Hadoop 数据、从云端到本地的备份和灾难恢复、对现有 Hadoop 数据进行 DevTest、数据保护和多云连接以及加速分析工作负载。

以下部分介绍了对 Spark 客户来说重要的存储功能。



=== 存储分层

通过 Hadoop 存储分层，您可以根据存储策略存储具有不同存储类型的文件。存储类型包括 `hot`， `cold` ， `warm` ， `all_ssd` ， `one_ssd` ， 和 `lazy_persist`。

我们在NetApp AFF存储控制器和具有不同存储策略的 SSD 和 SAS 驱动器的 E 系列存储控制器上对 Hadoop 存储分层进行了验证。带有AFF-A800 的 Spark 集群有四个计算工作节点，而带有 E 系列的集群有八个。这主要是为了比较固态硬盘 (SSD) 与硬盘 (HDD) 的性能。

下图显示了NetApp针对 Hadoop SSD 的解决方案的性能。

image:apache-spark-002.png["是时候对 1TB 数据进行排序了。"]

* 基线 NL-SAS 配置使用八个计算节点和 96 个 NL-SAS 驱动器。此配置在 4 分 38 秒内生成了 1TB 的数据。看 https://www.netapp.com/pdf.html?item=/media/16462-tr-3969.pdf["TR-3969 NetApp E系列Hadoop解决方案"^]有关集群和存储配置的详细信息。
* 使用 TeraGen，SSD 配置生成 1TB 数据的速度比 NL-SAS 配置快 15.66 倍。此外，SSD 配置使用了一半数量的计算节点和一半数量的磁盘驱动器（总共 24 个 SSd 驱动器）。根据作业完成时间，它几乎比 NL-SAS 配置快两倍。
* 使用 TeraSort，SSD 配置对 1TB 数据的排序速度比 NL-SAS 配置快 1138.36 倍。此外，SSD 配置使用了一半数量的计算节点和一半数量的磁盘驱动器（总共 24 个 SSd 驱动器）。因此，每个驱动器的速度大约比 NL-SAS 配置快三倍。
* 要点是从旋转磁盘过渡到全闪存可以提高性能。计算节点的数量不是瓶颈。借助 NetApp 的全闪存存储，运行时性能可以很好地扩展。
* 使用 NFS，数据在功能上相当于被集中在一起，这可以根据您的工作负载减少计算节点的数量。  Apache Spark 集群用户在更改计算节点数量时不必手动重新平衡数据。




=== 性能扩展 - 横向扩展

当您需要从AFF解决方案中的 Hadoop 集群获取更多计算能力时，您可以添加具有适当数量存储控制器的数据节点。  NetApp建议从每个存储控制器阵列 4 个数据节点开始，然后根据工作负载特点将每个存储控制器的数据节点数量增加到 8 个。

AFF和FAS非常适合就地分析。根据计算要求，您可以添加节点管理器，并且无中断操作允许您按需添加存储控制器而无需停机。我们提供AFF和FAS的丰富功能，例如 NVME 媒体支持、保证效率、数据减少、QOS、预测分析、云分层、复制、云部署和安全性。为了帮助客户满足他们的需求， NetApp提供了文件系统分析、配额和机上负载平衡等功能，无需额外的许可费用。 NetApp在并发作业数量、更低的延迟、更简单的操作以及更高的每秒千兆字节吞吐量方面比我们的竞争对手表现更佳。此外， NetApp Cloud Volumes ONTAP可在三大云提供商上运行。



=== 性能扩展 - 扩大规模

当您需要额外的存储容量时，扩展功能允许您将磁盘驱动器添加到AFF、 FAS和 E 系列系统。使用Cloud Volumes ONTAP，将存储扩展到 PB 级别需要结合两个因素：将不常用的数据从块存储分层到对象存储，以及堆叠Cloud Volumes ONTAP许可证而无需额外的计算。



=== 多种协议

NetApp系统支持大多数 Hadoop 部署协议，包括 SAS、iSCSI、FCP、InfiniBand 和 NFS。



=== 运营和支持的解决方案

本文档中描述的 Hadoop 解决方案由NetApp支持。这些解决方案也经过了主要 Hadoop 分销商的认证。更多信息，请参阅 http://hortonworks.com/partner/netapp/["Hortonworks"^]站点和 Cloudera http://www.cloudera.com/partners/partners-listing.html?q=netapp["认证"^]和 http://www.cloudera.com/partners/solutions/netapp.html["伙伴"^]站点。
