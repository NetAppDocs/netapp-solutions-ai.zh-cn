<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">阅读 AI/ML 博客，了解行业趋势、创新和实际影响，以及开发人员资源、社区见解和使用NetApp AI 解决方案的实用工具。</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">阅读NetApp专家的 AI 解决方案博客</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">阅读 AI/ML 博客，了解行业趋势、创新和实际影响，以及开发人员资源、社区见解和使用NetApp AI 解决方案的实用工具。</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">人工智能趋势和行业洞察</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英语</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">探索各个领域的行业趋势、创新以及现实世界的人工智能影响。<block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[AI,Analytics,artificial-intelligence]++[在NetApp上阅读 AI 博客^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">开发者资源和社区</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">在 Pub 上阅读 AI 博客</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">为 AI/ML 从业者提供技术见解、实用工具和社区驱动的内容。<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">本文提供了使用 AWS 服务构建 MLOps 管道的指南，重点关注自动化模型再训练、部署和成本优化。</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">第 3 部分 - 构建简化的 MLOps 管道 (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">本文提供了使用 AWS 服务构建 MLOps 管道的指南，重点关注自动模型再训练、部署和成本优化。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">简介</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">在本教程中，您将学习如何利用各种 AWS 服务构建一个包含持续集成 (CI)、持续训练 (CT) 和持续部署 (CD) 的简单 MLOps 管道。与传统的 DevOps 管道不同，MLOps 需要额外的考虑才能完成操作周期。通过学习本教程，您将深入了解如何将 CT 纳入 MLOps 循环，从而实现模型的持续训练和推理的无缝部署。本教程将指导您完成利用 AWS 服务建立此端到端 MLOps 管道的过程。</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">显现</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">功能</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">名称</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">注释</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">数据存储</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">第 1 部分 - 将Amazon FSx for NetApp ONTAP (FSx ONTAP) 作为私有 S3 存储桶集成到 AWS SageMaker</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">请参阅<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">数据科学 IDE</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS SageMaker</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">第 2 部分 - 利用Amazon FSx for NetApp ONTAP (FSx ONTAP) 作为 SageMaker 模型训练的数据源</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">本教程基于<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block>。</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">触发 MLOps 管道的函数</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS Lambda 函数</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Cron 作业触发器</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS EventBridge</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">深度学习框架</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">PyTorch</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS Python 开发工具包</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">编程语言</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Python</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">前提条件</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">预配置的 FSx ONTAP文件系统。本教程利用 FSx ONTAP中存储的数据进行训练过程。</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">配置为与上面提到的 FSx ONTAP文件系统共享相同 VPC 的 *SageMaker Notebook 实例*。</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">在触发 *AWS Lambda 函数* 之前，请确保 *SageMaker Notebook 实例* 处于 *已停止* 状态。</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">需要 *ml.g4dn.xlarge* 实例类型来利用深度神经网络计算所需的 GPU 加速。</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">架构</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">这个 MLOps 管道是一个实际的实现，它利用 cron 作业来触发无服务器功能，进而执行使用生命周期回调函数注册的 AWS 服务。 *AWS EventBridge* 充当 cron 作业。它定期调用负责重新训练和重新部署模型的 *AWS Lambda 函数*。此过程涉及启动 *AWS SageMaker Notebook* 实例以执行必要的任务。</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">分步配置</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">生命周期配置</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">要为 AWS SageMaker Notebook 实例配置生命周期回调函数，您需要使用*生命周期配置*。此服务允许您定义启动笔记本实例时需要执行的必要操作。具体来说，可以在*生命周期配置*中实现一个 shell 脚本，以便在训练和部署过程完成后自动关闭笔记本实例。这是必需的配置，因为成本是 MLOps 中的主要考虑因素之一。</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">值得注意的是，*生命周期配置*的配置需要提前设置。因此，建议在继续其他 MLOps 管道设置之前优先配置这一方面。</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">要设置生命周期配置，请打开 *Sagemaker* 面板并导航到 *Admin configuration* 部分下的 *Lifecycle configuration*。</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">SageMaker 面板</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">选择“笔记本实例”选项卡，然后单击“创建配置”按钮</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">生命周期配置欢迎页面</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">将以下代码粘贴到输入区域。</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">该脚本执行 Jupyter Notebook，用于处理模型的重新训练和重新部署以进行推理。执行完成后，笔记本将在5分钟内自动关机。要了解有关问题陈述和代码实现的更多信息，请参阅<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block>。</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">创建生命周期配置</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">创建后，导航到 Notebook 实例，选择目标实例，然后单击“操作”下拉菜单下的“更新设置”。</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">更新设置下拉菜单</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">选择创建的*生命周期配置*，然后单击*更新笔记本实例*。</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">更新笔记本的生命周期配置</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">AWS Lambda 无服务器函数</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">如前所述，*AWS Lambda 函数*负责启动 *AWS SageMaker Notebook 实例*。</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">要创建 *AWS Lambda 函数*，请导航到相应的面板，切换到 *函数* 选项卡，然后单击 *创建函数*。</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">AWS lambda 函数欢迎页面</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">请在页面上提交所有必需的条目，并记得将运行时切换为 *Python 3.10*。</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">创建 AWS lambda 函数</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">请验证指定的角色是否具有所需的权限*AmazonSageMakerFullAccess*，然后单击*创建功能*按钮。</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">选择执行角色</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">选择创建的Lambda函数。在代码选项卡中，将以下代码复制并粘贴到文本区域中。此代码启动名为 *fsxn-ontap* 的笔记本实例。</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">单击“*部署*”按钮以应用此代码更改。</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">部署</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">要指定如何触发此 AWS Lambda 函数，请单击添加触发器按钮。</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">添加 AWS 函数触发器</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">从下拉菜单中选择 EventBridge，然后单击标有“创建新规则”的单选按钮。在计划表达式字段中，输入<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block>，然后单击添加按钮以创建并将此新的 cron 作业规则应用于 AWS Lambda 函数。</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">完成触发器</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">完成这两步配置后，每天，*AWS Lambda 函数*都会启动 *SageMaker Notebook*，使用 *FSx ONTAP* 存储库中的数据执行模型重新训练，将更新后的模型重新部署到生产环境，并自动关闭 *SageMaker Notebook 实例*以优化成本。这确保模型保持最新。</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">开发 MLOps 管道的教程到此结束。</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">这是 FSx ONTAP MLOps 部分的介绍页面。</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">适用于 MLOps 的Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">本节深入探讨 AI 基础架构开发的实际应用，提供使用 FSx ONTAP构建 MLOps 管道的端到端演练。它包含三个综合示例，指导您通过这个强大的数据管理平台满足您的 MLOps 需求。</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">这些文章重点关注：</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">到本节结束时，您将对如何使用 FSx ONTAP简化 MLOps 流程有深入的了解。</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">这篇文章提供了使用 AWS SageMaker 将 FSx ONTAP配置为私有 S3 存储桶的指南。</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">本节提供了使用 AWS SageMaker 将 FSx ONTAP配置为私有 S3 存储桶的指南。</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">以 SageMaker 为例，本页面提供了将 FSx ONTAP配置为私有 S3 存储桶的指导。</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">视频链接</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">有关 FSx ONTAP的更多信息，请查看此演示文稿（<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">用户指南</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">服务器创建</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">创建 SageMaker Notebook 实例</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">打开 AWS 控制台。在搜索面板中，搜索 SageMaker 并单击服务 *Amazon SageMaker*。</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">打开 AWS 控制台</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">打开 Notebook 选项卡下的 *Notebook 实例*，点击橙色按钮 *创建笔记本实例*。</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">AWS SageMaker Notebook实例控制台</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">在创建页面中，输入*笔记本实例名称*展开*网络*面板保留其他条目的默认值，并选择*VPC*、*子网*和*安全组*。  （此*VPC*和*Subnet*稍后将用于创建 FSx ONTAP文件系统）单击右下角的橙色按钮*创建笔记本实例*。</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">创建笔记本实例</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">创建 FSx ONTAP文件系统</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">打开 AWS 控制台。在搜索面板中，搜索 Fsx 并单击服务 *FSx*。</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">FSx 面板</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">单击*创建文件系统*。</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">创建文件系统</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">选择第一张卡 *FSx ONTAP* 并单击 *下一步*。</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">选择文件系统类型</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">在详细信息配置页面中。</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">选择*标准创建*选项。</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">创建文件系统面板</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">输入*文件系统名称*和*SSD存储容量*。</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">指定文件系统详细信息</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">确保使用与 *SageMaker Notebook* 实例相同的 *VPC* 和 *subnet*。</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">网络和安全配置</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">为您的 SVM（存储虚拟机）输入*存储虚拟机*名称和*指定密码*。</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">默认存储虚拟机配置</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">保留其他条目的默认值，然后单击右下角的橙色按钮“下一步”。</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">确认配置</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">点击审核页面右下角的橙色按钮*创建文件系统*。</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">检查配置并确认创建</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">启动 FSx 文件系统可能需要大约 *20-40 分钟*。</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">检查 FSx 控制台</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">服务器配置</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP 配置</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">打开创建的FSx文件系统。请确保状态为*可用*。</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">等待后端创建</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">选择*管理*选项卡并保留*管理端点 - IP 地址*和* ONTAP管理员用户名*。</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">文件系统详细信息控制台</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">打开创建的*SageMaker Notebook实例*，然后单击*打开JupyterLab*。</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">AWS SageMaker Notebook 实例控制台</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">在 Jupyter Lab 页面中，打开一个新的*终端*。</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Jupyter Lab 欢迎页面</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">输入 ssh 命令 ssh &lt;管理员用户名&gt;@&lt; ONTAP服务器 IP&gt; 登录 FSx ONTAP文件系统。  （用户名和 IP 地址从步骤 2 中检索）请使用创建 *存储虚拟机* 时使用的密码。</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Jupyter Lab 终端</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">按以下顺序执行命令。我们使用 *fsxn-ontap* 作为 *FSx ONTAP私有 S3 存储桶名称* 的名称。请使用*存储虚拟机名称*作为*-vserver* 参数。</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Jupyter Lab 终端输出</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">执行以下命令来检索 FSx ONTAP私有 S3 的端点 IP 和凭据。</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">保留端点 IP 和凭证以供将来使用。</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">客户端配置</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">在 SageMaker Notebook 实例中，创建一个新的 Jupyter 笔记本。</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">打开一个新的 Jupyter 笔记本</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">使用以下代码作为解决方案将文件上传到 FSx ONTAP私有 S3 存储桶。有关全面的代码示例，请参阅此笔记本。<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">这完成了 FSx ONTAP和 SageMaker 实例之间的集成。</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">有用的调试清单</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">确保 SageMaker Notebook 实例和 FSx ONTAP文件系统位于同一个 VPC 中。</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">记得在ONTAP上运行 *set dev* 命令将权限级别设置为 *dev*。</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">常见问题解答（截至 2023 年 9 月 27 日）</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">问：为什么我在将文件上传到 FSx ONTAP时收到错误“*调用 CreateMultipartUpload 操作时发生错误（未实现）：您请求的 s3 命令未实现*”？</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">答：作为私有 S3 存储桶，FSx ONTAP支持上传最大 100MB 的文件。使用S3协议时，大于100MB的文件会被分成100MB的块，并调用‘CreateMultipartUpload’函数。但是，FSx ONTAP私有 S3 的当前实现不支持此功能。</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">问：为什么在将文件上传到 FSx ONTAP时出现错误“*调用 PutObject 操作时发生错误（AccessDenied）：访问被拒绝*”？</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">答：要从 SageMaker Notebook 实例访问 FSx ONTAP私有 S3 存储桶，请将 AWS 凭证切换到 FSx ONTAP凭证。但是，授予实例写入权限需要一种解决方法，即安装存储桶并运行“chmod”shell 命令来更改权限。</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">问：如何将 FSx ONTAP私有 S3 存储桶与其他 SageMaker ML 服务集成？</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">答：遗憾的是，SageMaker 服务 SDK 没有提供指定私有 S3 存储桶端点的方法。因此，FSx ONTAP S3 与 Sagemaker Data Wrangler、Sagemaker Clarify、Sagemaker Glue、Sagemaker Athena、Sagemaker AutoML 等 SageMaker 服务不兼容。</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">本文是关于使用Amazon FSx for NetApp ONTAP (FSx ONTAP) 在 SageMaker 中训练 PyTorch 模型的教程，具体针对轮胎质量分类项目。</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">第 2 部分 - 利用 AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) 作为 SageMaker 模型训练的数据源</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">本文是关于使用Amazon FSx for NetApp ONTAP (FSx ONTAP) 在 SageMaker 中训练 PyTorch 模型的教程，具体针对轮胎质量分类项目。</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">本教程提供了一个计算机视觉分类项目的实际示例，提供了在 SageMaker 环境中利用 FSx ONTAP作为数据源构建 ML 模型的实践经验。该项目专注于使用深度学习框架 PyTorch 根据轮胎图像对轮胎质量进行分类。它强调使用 FSx ONTAP作为 Amazon SageMaker 中的数据源来开发机器学习模型。</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">什么是 FSx ONTAP</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP确实是 AWS 提供的完全托管的存储解决方案。它利用 NetApp 的ONTAP文件系统提供可靠且高性能的存储。通过支持 NFS、SMB 和 iSCSI 等协议，它允许从不同的计算实例和容器进行无缝访问。该服务旨在提供卓越的性能，确保快速高效的数据操作。它还具有高可用性和耐用性，确保您的数据保持可访问和受保护。此外， Amazon FSx ONTAP的存储容量是可扩展的，您可以根据需要轻松调整。</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">网络环境</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">网络环境</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP （Amazon FSx ONTAP）是一项 AWS 存储服务。它包括在NetApp ONTAP系统上运行的文件系统和连接到它的 AWS 管理的系统虚拟机 (SVM)。在提供的图中，AWS 管理的NetApp ONTAP服务器位于 VPC 外部。 SVM作为SageMaker和NetApp ONTAP系统之间的中介，接收来自SageMaker的操作请求并转发到底层存储。要访问 FSx ONTAP，SageMaker 必须放置在与 FSx ONTAP部署相同的 VPC 内。此配置可确保 SageMaker 和 FSx ONTAP之间的通信和数据访问。</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">数据访问</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">在现实场景中，数据科学家通常利用 FSx ONTAP中存储的现有数据来构建他们的机器学习模型。但是，出于演示目的，由于 FSx ONTAP文件系统在创建后最初是空的，因此需要手动上传训练数据。这可以通过将 FSx ONTAP作为卷安装到 SageMaker 来实现。文件系统成功挂载后，您可以将数据集上传到挂载位置，以便在 SageMaker 环境中训练模型。这种方法允许您利用 FSx ONTAP的存储容量和功能，同时与 SageMaker 进行模型开发和训练。</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">第 1 部分 - 将Amazon FSx for NetApp ONTAP (FSx ONTAP) 作为私有 S3 存储桶集成到 AWS SageMaker</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">数据读取过程涉及将 FSx ONTAP配置为私有 S3 存储桶。详细配置说明请参考<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">集成概述</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">训练工作流程</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">使用 FSx ONTAP中的训练数据在 SageMaker 中构建深度学习模型的工作流程可以概括为三个主要步骤：数据加载器定义、模型训练和部署。从高层次来看，这些步骤构成了 MLOps 管道的基础。然而，为了全面实施，每个步骤都涉及几个详细的子步骤。这些子步骤涵盖数据预处理、数据集拆分、模型配置、超参数调整、模型评估和模型部署等各种任务。这些步骤确保在 SageMaker 环境中使用来自 FSx ONTAP的训练数据构建和部署深度学习模型的流程全面有效。</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">逐步集成</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">数据Loader</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">为了使用数据训练 PyTorch 深度学习网络，创建了一个数据加载器以方便数据的输入。数据加载器不仅定义批次大小，还确定读取和预处理批次中每个记录的过程。通过配置数据加载器，我们可以批量处理数据，从而实现深度学习网络的训练。</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">数据加载器由3部分组成。</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">预处理函数</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">上面的代码片段演示了使用 *torchvision.transforms* 模块定义图像预处理转换。在本教程中，创建预处理对象来应用一系列转换。首先，*ToTensor()* 转换将图像转换为张量表示。随后，*Resize((224,224))* 转换将图像调整为固定大小 224x224 像素。最后，*Normalize()* 转换通过减去平均值并除以每个通道的标准差来对张量值进行归一化。用于标准化的平均值和标准差值通常用于预训练的神经网络模型。总的来说，这段代码通过将图像数据转换为张量、调整其大小以及规范化像素值来准备进一步处理或输入到预先训练的模型中。</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">PyTorch 数据集类</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">该类提供获取数据集中记录总数的功能，并定义读取每条记录数据的方法。在 *__getitem__* 函数中，代码利用 boto3 S3 bucket 对象从 FSx ONTAP检索二进制数据。从 FSx ONTAP访问数据的代码样式类似于从 Amazon S3 读取数据。后续讲解深入探讨私有 S3 对象 *bucket* 的创建过程。</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP作为私有 S3 存储库</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">为了从 SageMaker 中的 FSx ONTAP读取数据，需要创建一个使用 S3 协议指向 FSx ONTAP存储的处理程序。这使得 FSx ONTAP可以被视为私有 S3 存储桶。处理程序配置包括指定 FSx ONTAP SVM 的 IP 地址、存储桶名称和必要的凭据。有关获取这些配置项的详细说明，请参阅以下文档：<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">在上面的例子中，bucket对象用于实例化PyTorch数据集对象。数据集对象将在后续章节中进一步解释。</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">PyTorch 数据Loader</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">在提供的示例中，指定批次大小为 64，表示每个批次将包含 64 条记录。通过结合 PyTorch *Dataset* 类、预处理函数和训练批次大小，我们获得了用于训练的数据加载器。该数据加载器有助于在训练阶段分批迭代数据集的过程。</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">模型训练</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">此代码实现了标准的 PyTorch 训练流程。它定义了一个名为*TyreQualityClassifier*的神经网络模型，使用卷积层和线性层来对轮胎质量进行分类。训练循环迭代数据批次，计算损失，并使用反向传播和优化更新模型的参数。此外，它还打印当前时间、纪元、批次和损失以供监控目的。</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">模型部署</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">代码将 PyTorch 模型保存到 *Amazon S3*，因为 SageMaker 要求将模型存储在 S3 中以便部署。通过将模型上传到 *Amazon S3*，SageMaker 就可以访问它，从而允许对已部署的模型进行部署和推理。</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">此代码有助于在 SageMaker 上部署 PyTorch 模型。它定义了一个自定义序列化器 *TyreQualitySerializer*，它将输入数据预处理并序列化为 PyTorch 张量。 *TyreQualityPredictor* 类是一个自定义预测器，它利用定义的序列化器和 *JSONDeserializer*。该代码还创建了一个 *PyTorchModel* 对象来指定模型的 S3 位置、IAM 角色、框架版本和推理的入口点。代码生成时间戳并根据模型和时间戳构建端点名称。最后，使用 deploy 方法部署模型，指定实例数量、实例类型和生成的端点名称。这使得 PyTorch 模型可以在 SageMaker 上部署并进行推理。</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">推理</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">这是使用已部署端点进行推理的示例。</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">本节总结了有关 Apache Spark 的NetApp存储解决方案的文档。</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">结束语</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">在本文档中，我们讨论了 Apache Spark 架构、客户用例以及与大数据、现代分析、AI、ML 和 DL 相关的NetApp存储产品组合。在我们基于行业标准基准测试工具和客户需求的性能验证测试中， NetApp Spark 解决方案表现出了相对于原生 Hadoop 系统的卓越性能。本报告中提供的客户用例和性能结果的组合可以帮助您为您的部署选择合适的 Spark 解决方案。</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">本文档重点介绍 Apache Spark 架构、客户用例以及与大数据分析和人工智能相关的NetApp存储产品组合。它还展示了使用行业标准 AI、机器学习和深度学习工具针对典型 Hadoop 系统进行的各种测试结果，以便您可以选择合适的 Spark 解决方案。</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570：适用于 Apache Spark 的NetApp存储解决方案：架构、用例和性能结果</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang，Karthikeyan Nagalingam， NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">本文档重点介绍 Apache Spark 架构、客户用例以及与大数据分析和人工智能 (AI) 相关的NetApp存储产品组合。它还展示了使用行业标准 AI、机器学习 (ML) 和深度学习 (DL) 工具针对典型 Hadoop 系统进行的各种测试结果，以便您可以选择合适的 Spark 解决方案。首先，您需要一个 Spark 架构、适当的组件和两种部署模式（集群和客户端）。</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">该文档还提供了解决配置问题的客户用例，并讨论了与大数据分析以及 Spark 的 AI、ML 和 DL 相关的NetApp存储产品组合的概述。然后，我们得到来自 Spark 特定用例和NetApp Spark 解决方案组合的测试结果。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">客户挑战</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">本节重点关注零售、数字营销、银行、离散制造、流程制造、政府和专业服务等数据增长行业中客户面临的大数据分析和 AI/ML/DL 挑战。</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">不可预测的表现</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">传统的 Hadoop 部署通常使用商品硬件。为了提高性能，您必须调整网络、操作系统、Hadoop 集群、生态系统组件（如 Spark）和硬件。即使您调整每一层，也很难达到所需的性能水平，因为 Hadoop 运行在并非为您的环境的高性能而设计的商用硬件上。</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">介质和节点故障</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">即使在正常条件下，商品硬件也容易出现故障。如果数据节点上的一个磁盘发生故障，则 Hadoop 主服务器默认认为该节点不健康。然后，它通过网络将该节点上的特定数据从副本复制到健康节点。此过程会减慢任何 Hadoop 作业的网络数据包速度。当不健康的节点恢复健康状态时，集群必须再次复制数据并删除过度复制的数据。</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop供应商锁定</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop 分销商拥有自己的 Hadoop 发行版和版本控制，从而将客户锁定在这些发行版上。然而，许多客户需要内存分析支持，而这种支持不会将客户绑定到特定的 Hadoop 发行版。他们需要自由地改变分布，同时仍然保留他们的分析能力。</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">缺乏对多种语言的支持</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">客户通常需要除了 MapReduce Java 程序之外的多种语言支持来运行他们的作业。  SQL 和脚本等选项为获取答案提供了更大的灵活性，为组织和检索数据提供了更多的选项，以及将数据移动到分析框架的更快的方式。</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">使用难度</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">一段时间以来，人们一直抱怨 Hadoop 难以使用。尽管 Hadoop 的每个新版本都变得更简单、更强大，但这种批评仍然存在。  Hadoop 要求您了解 Java 和 MapReduce 编程模式，这对数据库管理员和具有传统脚本技能的人员来说是一个挑战。</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">复杂的框架和工具</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">企业AI团队面临多重挑战。即使拥有专业的数据科学知识，不同部署生态系统和应用程序的工具和框架也可能无法简单地从一个转换到另一个。数据科学平台应该与基于 Spark 构建的相应大数据平台无缝集成，易于数据移动、可重复使用的模型、开箱即用的代码以及支持原型设计、验证、版本控制、共享、重用和快速将模型部署到生产的最佳实践的工具。</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">为什么选择NetApp？</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp可以通过以下方式改善您的 Spark 体验：</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFS 直接访问（如下图所示）允许客户在其现有或新的 NFSv3 或 NFSv4 数据上运行大数据分析作业，而无需移动或复制数据。它可以防止数据的多次复制，并且无需将数据与源同步。</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">更高效的存储和更少的服务器复制。例如， NetApp E 系列 Hadoop 解决方案需要两个而不是三个数据副本，而FAS Hadoop 解决方案需要一个数据源，但不需要数据复制或副本。  NetApp存储解决方案还能减少服务器之间的流量。</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">驱动器和节点故障期间的 Hadoop 作业和集群行为更好。</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">更好的数据提取性能。</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">替代的 Apache Spark 配置。</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">例如，在金融和医疗保健领域，数据从一个地方移动到另一个地方必须满足法律义务，这不是一件容易的事。在这种情况下， NetApp NFS 直接访问会从原始位置分析财务和医疗保健数据。另一个主要优势是，使用NetApp NFS 直接访问可以通过使用本机 Hadoop 命令简化 Hadoop 数据的保护，并利用NetApp丰富的数据管理产品组合实现数据保护工作流。</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS 直接访问为 Hadoop/Spark 集群提供了两种部署选项：</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">默认情况下，Hadoop 或 Spark 集群使用 Hadoop 分布式文件系统 (HDFS) 进行数据存储和默认文件系统。  NetApp NFS 直接访问可以用 NFS 存储替换默认的 HDFS 作为默认文件系统，从而实现对 NFS 数据的直接分析。</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">在另一个部署选项中， NetApp NFS 直接访问支持在单个 Hadoop 或 Spark 集群中将 NFS 与 HDFS 一起配置为附加存储。在这种情况下，客户可以通过 NFS 导出共享数据，并从同一个集群访问数据以及 HDFS 数据。</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">使用NetApp NFS 直接访问的主要优势包括：</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">从当前位置分析数据，从而避免将分析数据移动到 Hadoop 基础架构（如 HDFS）这一耗时耗能的任务。</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">将副本数量从三个减少到一个。</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">使用户能够分离计算和存储以独立扩展它们。</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">利用ONTAP丰富的数据管理功能提供企业数据保护。</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">通过 Hortonworks 数据平台认证。</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">支持混合数据分析部署。</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">利用动态多线程功能减少备份时间。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657： NetApp混合云数据解决方案 - 基于客户用例的 Spark 和 Hadoop</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">看<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block>用于备份 Hadoop 数据、从云端到本地的备份和灾难恢复、对现有 Hadoop 数据进行 DevTest、数据保护和多云连接以及加速分析工作负载。</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">以下部分介绍了对 Spark 客户来说重要的存储功能。</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">存储分层</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">通过 Hadoop 存储分层，您可以根据存储策略存储具有不同存储类型的文件。存储类型包括<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>，<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ，<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ，<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ，<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> ， 和<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>。</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">我们在NetApp AFF存储控制器和具有不同存储策略的 SSD 和 SAS 驱动器的 E 系列存储控制器上对 Hadoop 存储分层进行了验证。带有AFF-A800 的 Spark 集群有四个计算工作节点，而带有 E 系列的集群有八个。这主要是为了比较固态硬盘 (SSD) 与硬盘 (HDD) 的性能。</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">下图显示了NetApp针对 Hadoop SSD 的解决方案的性能。</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">是时候对 1TB 数据进行排序了。</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 NetApp E系列Hadoop解决方案</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">基线 NL-SAS 配置使用八个计算节点和 96 个 NL-SAS 驱动器。此配置在 4 分 38 秒内生成了 1TB 的数据。看<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block>有关集群和存储配置的详细信息。</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">使用 TeraGen，SSD 配置生成 1TB 数据的速度比 NL-SAS 配置快 15.66 倍。此外，SSD 配置使用了一半数量的计算节点和一半数量的磁盘驱动器（总共 24 个 SSd 驱动器）。根据作业完成时间，它几乎比 NL-SAS 配置快两倍。</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">使用 TeraSort，SSD 配置对 1TB 数据的排序速度比 NL-SAS 配置快 1138.36 倍。此外，SSD 配置使用了一半数量的计算节点和一半数量的磁盘驱动器（总共 24 个 SSd 驱动器）。因此，每个驱动器的速度大约比 NL-SAS 配置快三倍。</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">要点是从旋转磁盘过渡到全闪存可以提高性能。计算节点的数量不是瓶颈。借助 NetApp 的全闪存存储，运行时性能可以很好地扩展。</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">使用 NFS，数据在功能上相当于被集中在一起，这可以根据您的工作负载减少计算节点的数量。  Apache Spark 集群用户在更改计算节点数量时不必手动重新平衡数据。</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">性能扩展 - 横向扩展</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">当您需要从AFF解决方案中的 Hadoop 集群获取更多计算能力时，您可以添加具有适当数量存储控制器的数据节点。  NetApp建议从每个存储控制器阵列 4 个数据节点开始，然后根据工作负载特点将每个存储控制器的数据节点数量增加到 8 个。</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF和FAS非常适合就地分析。根据计算要求，您可以添加节点管理器，并且无中断操作允许您按需添加存储控制器而无需停机。我们提供AFF和FAS的丰富功能，例如 NVME 媒体支持、保证效率、数据减少、QOS、预测分析、云分层、复制、云部署和安全性。为了帮助客户满足他们的需求， NetApp提供了文件系统分析、配额和机上负载平衡等功能，无需额外的许可费用。 NetApp在并发作业数量、更低的延迟、更简单的操作以及更高的每秒千兆字节吞吐量方面比我们的竞争对手表现更佳。此外， NetApp Cloud Volumes ONTAP可在三大云提供商上运行。</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">性能扩展 - 扩大规模</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">当您需要额外的存储容量时，扩展功能允许您将磁盘驱动器添加到AFF、 FAS和 E 系列系统。使用Cloud Volumes ONTAP，将存储扩展到 PB 级别需要结合两个因素：将不常用的数据从块存储分层到对象存储，以及堆叠Cloud Volumes ONTAP许可证而无需额外的计算。</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">多种协议</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp系统支持大多数 Hadoop 部署协议，包括 SAS、iSCSI、FCP、InfiniBand 和 NFS。</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">运营和支持的解决方案</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">认证</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">伙伴</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">本文档中描述的 Hadoop 解决方案由NetApp支持。这些解决方案也经过了主要 Hadoop 分销商的认证。更多信息，请参阅<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block>站点和 Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block>和<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block>站点。</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">本节介绍 Apache Spark 的性质和组件以及它们如何为此解决方案做出贡献。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">解决方案技术</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark 是一种流行的编程框架，用于编写可直接与 Hadoop 分布式文件系统 (HDFS) 协同工作的 Hadoop 应用程序。  Spark 已准备好投入生产，支持流数据处理，并且比 MapReduce 更快。 Spark 具有可配置的内存数据缓存，可实现高效迭代，并且 Spark shell 具有交互性，可用于学习和探索数据。使用 Spark，您可以用 Python、Scala 或 Java 创建应用程序。  Spark 应用程序由一个或多个具有一个或多个任务的作业组成。</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">每个 Spark 应用程序都有一个 Spark 驱动程序。在 YARN-Client 模式下，驱动程序在客户端本地运行。在 YARN-Cluster 模式下，驱动程序在应用程序主机上的集群中运行。在集群模式下，即使客户端断开连接，应用程序仍继续运行。</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">该图显示输入/输出对话框或表示书面内容</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">有三个集群管理器：</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*独立。*该管理器是 Spark 的一部分，可以轻松设置集群。</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">Apache Mesos。这是一个通用集群管理器，也运行 MapReduce 和其他应用程序。</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">Hadoop YARN。这是 Hadoop 3 中的资源管理器。</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">弹性分布式数据集（RDD）是 Spark 的主要组件。  RDD 从集群内存中存储的数据中重新创建丢失和缺失的数据，并存储来自文件或以编程方式创建的初始数据。  RDD 是从文件、内存中的数据或另一个 RDD 创建的。 Spark 编程执行两种操作：转换和操作。转换基于现有 RDD 创建新的 RDD。操作从 RDD 返回一个值。</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">转换和操作也适用于 Spark 数据集和 DataFrames。数据集是分布式数据集合，它兼具 RDD 的优势（强类型、使用 lambda 函数）和 Spark SQL 优化执行引擎的优势。可以从 JVM 对象构建数据集，然后使用功能转换（map、flatMap、filter 等）进行操作。 DataFrame 是按命名列组织起来的数据集。它在概念上等同于关系数据库中的表或 R/Python 中的数据框。  DataFrames 可以从多种来源构建，例如结构化数据文件、Hive/HBase 中的表、本地或云端的外部数据库或现有的 RDD。</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark 应用程序包括一个或多个 Spark 作业。作业在执行器中运行任务，执行器在 YARN 容器中运行。每个执行器都在单个容器中运行，并且执行器在应用程序的整个生命周期中都存在。应用程序启动后，执行器就固定了，YARN 不会调整已分配的容器的大小。执行器可以对内存数据同时运行任务。</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">本节介绍谁可能对该解决方案的内容感兴趣。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">目标受众</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">分析和数据科学领域涉及 IT 和商业的多个学科：</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">数据科学家需要灵活地使用他们选择的工具和库。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">数据工程师需要知道数据如何流动以及位于何处。</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps 工程师需要工具将新的 AI 和 ML 应用程序集成到他们的 CI 和 CD 管道中。</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">云管理员和架构师必须能够设置和管理混合云资源。</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">商业用户希望能够访问分析、AI、ML 和 DL 应用程序。</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">在本技术报告中，我们描述了NetApp AFF、E 系列、 StorageGRID、NFS 直接访问、Apache Spark、Horovod 和 Keras 如何帮助这些角色为企业带来价值。</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">我们使用 TeraGen 基准测试工具中的 TeraSort 和 TeraValidate 脚本来测量 E5760、E5724 和AFF-A800 配置的 Spark 性能验证。此外，还测试了三个主要用例：Spark NLP 管道和 TensorFlow 分布式训练、Horovod 分布式训练以及使用 Keras 进行多工深度学习，通过 DeepFM 进行 CTR 预测。</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">测试结果</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">我们使用 TeraGen 基准测试工具中的 TeraSort 和 TeraValidate 脚本来测量 E5760、E5724 和AFF-A800 配置的 Spark 性能验证。此外，还测试了三个主要用例：Spark NLP 管道和 TensorFlow 分布式训练、Horovod 分布式训练以及使用 Keras 进行 DeepFM CTR 预测的多工深度学习。</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">对于 E 系列和StorageGRID验证，我们使用了 Hadoop 复制因子 2。对于AFF验证，我们仅使用一个数据源。</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">下表列出了 Spark 性能验证的硬件配置。</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">类型</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop 工作节点</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">驱动器类型</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">每个节点的驱动器</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">存储控制器</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">单个高可用性 (HA) 对</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">单个 HA 对</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">下表列出了软件要求。</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">软件</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">版本</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK 运行环境</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64 位服务器虚拟机</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">Git</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">火花</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">PySpark</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">SparkNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">喀拉拉</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">霍罗沃德</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">金融情绪分析</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910：利用NetApp AI 对客户沟通进行情绪分析</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps 工具包</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">道框架</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">我们发表了<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block>，其中使用<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>、 AFF存储和NVIDIA DGX 系统。该管道利用 DataOps Toolkit 执行批量音频信号处理、自动语音识别 (ASR)、迁移学习和情绪分析，<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> ，以及<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>。将情绪分析用例扩展到金融服务行业，我们构建了 SparkNLP 工作流程，为各种 NLP 任务（例如命名实体识别）加载了三个 BERT 模型，并获得了纳斯达克十大公司季度收益电话会议的句子级情绪。</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">以下脚本<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block>使用 FinBERT 模型处理 HDFS 中的转录本，并产生正面、中性和负面情绪计数，如下表所示：</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">下表列出了 2016 年至 2020 年纳斯达克十大公司的收益电话会议句子级情绪分析。</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">情绪计数和百分比</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">全部 10 家公司</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">苹果</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">亚马逊</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">思科</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">谷歌</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">国际贸易中心</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">微软</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">正计数</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">中立计数</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">负数</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">未分类的计数</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">（总数）</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">从百分比来看，首席执行官和首席财务官所说的大多数句子都是事实，因此带有中立的情绪。在收益电话会议期间，分析师提出的问题可能会传达积极或消极的情绪。值得进一步定量研究负面或正面情绪如何影响交易当天或次日的股票价格。</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">下表列出了纳斯达克十大公司的句子级情感分析，以百分比表示。</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">情绪百分比</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">积极的</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">中性的</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">消极的</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">未分类</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">在工作流运行时方面，我们看到了显著的 4.78 倍改进<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>模式到 HDFS 中的分布式环境，并通过利用 NFS 进一步提高 0.14%。</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">如下图所示，数据和模型并行提高了数据处理和分布式 TensorFlow 模型推理的速度。 NFS 中的数据位置产生了稍微更好的运行时间，因为工作流瓶颈是预训练模型的下载。如果我们增加成绩单数据集的大小，NFS 的优势就更加明显。</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Spark NLP 情绪分析端到端工作流运行时。</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovod 性能的分布式训练</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">针对每个主要用例的 Python 脚本</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">以下命令使用单个<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block>具有 160 个执行器的节点，每个执行器都有一个核心。执行器内存限制为 5GB，以避免内存不足错误。请参阅<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block>有关数据处理、模型训练和模型准确率计算的更多详细信息，请参阅<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>。</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">经过 10 个训练周期后，最终的运行时间如下：</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">处理输入数据、训练 DNN 模型、计算准确度以及生成 TensorFlow 检查点和预测结果的 CSV 文件花费了超过 43 分钟。我们将训练周期数限制为 10，在实践中通常设置为 100，以确保令人满意的模型准确率。训练时间通常与训练次数呈线性关系。</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">接下来，我们使用集群中可用的四个工作节点，并在<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>HDFS 中的数据模式：</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">最终的运行时间改进如下：</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">借助 Horovod 模型和 Spark 中的数据并行性，我们看到运行速度提高了 5.29 倍<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>相对<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>具有十个训练阶段的模式。下图中图例显示了这一点<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block>和<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>。如果可用的话，可以使用 GPU 进一步加速底层 TensorFlow DNN 模型训练。我们计划进行此项测试并在未来的技术报告中发布结果。</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">我们的下一个测试比较了 NFS 和 HDFS 中的输入数据的运行时间。 AFF A800上的 NFS 卷已安装在<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block>分布于 Spark 集群的五个节点（一个主节点，四个工作节点）上。我们运行了与之前的测试类似的命令，<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block>参数现在指向 NFS 挂载：</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">使用 NFS 的运行结果如下：</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">速度又提高了 1.43 倍，如下图所示。因此，通过将NetApp全闪存存储连接到其集群，客户可以享受 Horovod Spark 工作流的快速数据传输和分发优势，与在单个节点上运行相比，可实现 7.55 倍的加速。</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark 工作流运行时。</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR预测性能的深度学习模型</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">对于旨在最大化点击率的推荐系统，必须学习用户行为背后复杂的特征交互，这些特征交互可以通过数学方式从低阶到高阶计算。对于良好的深度学习模型来说，低阶和高阶特征交叉应该同等重要，而不应偏向其中任何一方。深度分解机（DeepFM）是一种基于分解机的神经网络，它将用于推荐的分解机和用于特征学习的深度学习结合在一种新的神经网络架构中。</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">广度与深度模型</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">虽然传统的分解机将成对的特征交叉建模为特征之间潜在向量的内积，并且理论上可以捕获高阶信息，但在实践中，机器学习从业者通常只使用二阶特征交叉，因为计算和存储复杂度很高。深度神经网络变体，例如谷歌的<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block>另一方面，通过结合线性宽模型和深度模型，在混合网络结构中学习复杂的特征交互。</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">这个 Wide &amp; Deep 模型有两个输入，一个用于底层的广度模型，另一个用于深度模型，后者仍然需要专家的特征工程，因此该技术不太适用于其他领域。与广度和深度模型不同，DeepFM 可以使用原始特征进行有效训练，而无需任何特征工程，因为它的广度部分和深度部分共享相同的输入和嵌入向量。</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">每个主要用例的 Python 脚本。</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">我们首先处理了 Criteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> （11GB）文件转换为名为<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>存储在 NFS 挂载中<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block>使用<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>来自部分<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>在此脚本中，函数<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block>执行几个字符串方法来删除制表符并插入<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block>作为分隔符和<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block>作为换行符。请注意，您只需处理原始<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block>一次，这样代码块就显示为注释。</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">为了对不同的 DL 模型进行以下测试，我们使用<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>作为输入文件。在后续的测试运行中，输入的 CSV 文件被读入 Spark DataFrame，其模式包含以下字段<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block>，整数密集特征<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>和稀疏特征<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>。下列<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block>命令接受输入 CSV，以 20% 的比例训练 DeepFM 模型进行交叉验证，并在十个训练周期后选出最佳模型来计算测试集上的预测准确率：</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">请注意，由于数据文件<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>超过 11GB，则必须设置足够的<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block>大于数据集大小以避免错误。</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">阿帕奇箭</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">在上述<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block>配置我们还启用了<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>，将 Spark DataFrame 转换为 Pandas DataFrame，<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block>方法。</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">随机分割后，训练数据集中有超过 3600 万行，测试集中有 900 万个样本：</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">由于本技术报告专注于不使用任何 GPU 的 CPU 测试，因此必须使用适当的编译器标志构建 TensorFlow。此步骤避免调用任何 GPU 加速库，并充分利用 TensorFlow 的高级矢量扩展 (AVX) 和 AVX2 指令。这些特征是为线性代数计算而设计的，例如矢量加法、前馈中的矩阵乘法或反向传播 DNN 训练。 AVX2 提供的融合乘加 (FMA) 指令使用 256 位浮点 (FP) 寄存器，非常适合整数代码和数据类型，可实现高达 2 倍的加速。对于 FP 代码和数据类型，AVX2 比 AVX 实现了 8% 的加速。</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">巴泽尔</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">要从源代码构建 TensorFlow， NetApp建议使用<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>。对于我们的环境，我们在 shell 提示符下执行以下命令来安装<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block>，<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> ，以及 Bazel。</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">您必须启用 GCC 5 或更新版本才能在构建过程中使用 C++17 功能，该功能由 RHEL 通过软件集合库 (SCL) 提供。以下命令安装<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block>以及 RHEL 7.9 集群上的 GCC 11.2.1：</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">文章</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">请注意，最后两个命令启用<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>，使用<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block>（GCC 11.2.1）。此外，请确保您的<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>版本高于 1.8.3（随 RHEL 7.9 提供）。参考这个<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block>用于更新<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>至 2.24.1。</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">每个主要用例的 Python 脚本，</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">我们假设您已经克隆了最新的 TensorFlow 主仓库。然后创建一个<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block>目录与<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block>文件使用 AVX、AVX2 和 FMA 从源代码构建 TensorFlow。运行<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block>文件并指定正确的 Python 二进制位置。<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block>由于我们没有使用 GPU，因此在我们的测试中被禁用。一个<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>文件根据您的设置生成。此外，我们编辑了文件并设置<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block>启用 HDFS 支持。参考<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>在本节中<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block>以获得完整的设置和标志列表。</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">使用正确的标志构建 TensorFlow 后，运行以下脚本来处理 Criteo Display Ads 数据集，训练 DeepFM 模型，并根据预测分数计算接收者操作特征曲线下面积 (ROC AUC)。</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">经过十次训练后，我们获得了测试数据集上的 AUC 分数：</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">以与以前的用例类似的方式，我们将 Spark 工作流运行时与位于不同位置的数据进行了比较。下图显示了 Spark 工作流运行时深度学习 CTR 预测的比较。</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">比较 Spark 工作流运行时的深度学习 CTR 预测。</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">本页描述了可以使用该解决方案的不同领域。</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">用例摘要</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">流数据</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark 可以处理流数据，用于流式提取、转换和加载 (ETL) 过程；数据丰富；触发事件检测；以及复杂的会话分析：</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">流式 ETL。*数据在被推送到数据存储之前会被不断地清理和汇总。 Netflix 使用 Kafka 和 Spark 流构建实时在线电影推荐和数据监控解决方案，每天可以处理来自不同数据源的数十亿个事件。然而，用于批处理的传统 ETL 的处理方式有所不同。首先读取该数据，然后将其转换为数据库格式，再写入数据库。</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*数据丰富。* Spark 流使用静态数据丰富实时数据，以实现更实时的数据分析。例如，在线广告商可以根据客户行为信息投放个性化、有针对性的广告。</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*触发事件检测。* Spark 流允许您检测并快速响应可能表明存在严重问题的异常行为。例如，金融机构使用触发器来检测和阻止欺诈交易，医院使用触发器来检测患者生命体征中检测到的危险健康变化。</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*复杂的会话分析。* Spark 流收集用户登录网站或应用程序后的活动等事件，然后对其进行分组和分析。例如，Netflix 使用此功能提供实时电影推荐。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912： NetApp Confluent Kafka 分层存储的最佳实践指南</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">有关流数据配置、Confluent Kafka 验证和性能测试的更多内容，请参阅<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block>。</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">机器学习</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark 集成框架可帮助您使用机器学习库 (MLlib) 对数据集运行重复查询。  MLlib 用于聚类、分类和降维等领域，用于一些常见的大数据功能，例如预测智能、用于营销目的的客户细分和情感分析。 MLlib 用于网络安全，对数据包进行实时检查，以发现恶意活动的迹象。它可以帮助安全提供商了解新的威胁并领先于黑客，同时实时保护他们的客户。</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">深度学习</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow 是业界流行的深度学习框架。 TensorFlow支持在CPU或GPU集群上进行分布式训练。这种分布式训练允许用户在具有大量深层的数据上运行它。</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">直到最近，如果我们想将 TensorFlow 与 Apache Spark 一起使用，我们需要在 PySpark 中为 TensorFlow 执行所有必要的 ETL，然后将数据写入中间存储。然后，该数据将被加载到 TensorFlow 集群上，用于实际的训练过程。此工作流程要求用户维护两个不同的集群，一个用于 ETL，一个用于 TensorFlow 的分布式训练。运行和维护多个集群通常很繁琐且耗时。</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">早期 Spark 版本中的 DataFrames 和 RDD 不太适合深度学习，因为随机访问受到限制。在带有氢项目的 Spark 3.0 中，添加了对深度学习框架的原生支持。这种方法允许在 Spark 集群上进行非基于 MapReduce 的调度。</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">交互式分析</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark 的速度足够快，可以使用 Spark 以外的开发语言（包括 SQL、R 和 Python）执行探索性查询而无需采样。 Spark 使用可视化工具来处理复杂数据并以交互方式进行可视化。具有结构化流的 Spark 对网络分析中的实时数据执行交互式查询，使您能够对网络访问者的当前会话运行交互式查询。</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">推荐系统</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">多年来，随着企业和消费者对网上购物、在线娱乐和许多其他行业的巨大变化做出了反应，推荐系统给我们的生活带来了巨大的变化。事实上，这些系统是人工智能在生产中最明显的成功案例之一。在许多实际用例中，推荐系统与对话式 AI 或与 NLP 后端交互的聊天机器人相结合，以获取相关信息并产生有用的推论。</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">如今，许多零售商正在采用更新的商业模式，例如网上购买、店内取货、路边取货、自助结账、扫描即走等等。这些模式在新冠疫情期间尤为突出，因为它们让消费者的购物更加安全、更加便捷。人工智能对于这些日益增长的数字趋势至关重要，这些趋势受到消费者行为的影响，反之亦然。为了满足消费者日益增长的需求、增强客户体验、提高运营效率和增加收入， NetApp帮助其企业客户和企业使用机器学习和深度学习算法来设计更快、更准确的推荐系统。</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">有几种流行的技术用于提供推荐，包括协同过滤、基于内容的系统、深度学习推荐模型 (DLRM) 和混合技术。客户之前利用 PySpark 实现协同过滤来创建推荐系统。  Spark MLlib 实现了用于协同过滤的交替最小二乘法 (ALS)，这是 DLRM 兴起之前企业中非常流行的算法。</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">自然语言处理</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">对话式人工智能是通过自然语言处理 (NLP) 实现的，它是帮助计算机与人类交流的人工智能的一个分支。 NLP 在每个垂直行业和许多用例中都很普遍，从智能助手和聊天机器人到谷歌搜索和预测文本。根据<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block>预测到2022年，70%的人将每天与对话式人工智能平台进行互动。为了实现人与机器之间的高质量对话，响应必须快速、智能且听起来自然。</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">客户需要大量数据来处理和训练他们的 NLP 和自动语音识别 (ASR) 模型。他们还需要在边缘、核心和云端移动数据，并且需要在几毫秒内进行推理的能力，以与人类建立自然的交流。  NetApp AI 和 Apache Spark 是计算、存储、数据处理、模型训练、微调和部署的理想组合。</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">情感分析是 NLP 中的一个研究领域，它从文本中提取积极、消极或中性情感。情绪分析有多种用例，从确定支持中心员工与呼叫者对话的表现到提供适当的自动聊天机器人响应。它还被用来根据公司代表和季度收益电话会议上的听众之间的互动来预测公司的股价。此外，情绪分析可用于确定客户对品牌提供的产品、服务或支持的看法。</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">Spark NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">约翰·斯诺实验室</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">财经新闻情绪</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">FinBERT</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">我们使用了<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block>来自的图书馆<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block>加载预训练管道和 Transformer (BERT) 模型的双向编码器表示，包括<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block>和<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block>，大规模执行标记化、命名实体识别、模型训练、拟合和情感分析。 Spark NLP 是唯一一个正在生产中的开源 NLP 库，它提供最先进的转换器，例如 BERT、ALBERT、ELECTRA、XLNet、DistilBERT、RoBERTa、DeBERTa、XLM-RoBERTa、Longformer、ELMO、Universal Sentence Encoder、Google T5、MarianMT 和 GPT2。该库不仅适用于 Python 和 R，还可以通过原生扩展 Apache Spark 在 JVM 生态系统（Java、Scala 和 Kotlin）中大规模运行。</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">摘要</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">本文档介绍了如何从大数据分析和高性能计算 (HPC) 系统中移动数据，以便将其用于人工智能 (AI) 工作流程。 AI 通常通过 NFS 导出来处理 NFS 数据。但是，您可能将 AI 数据放在大数据分析和高性能计算 (HPC) 平台中。这可以是 Hadoop 分布式文件系统 (HDFS)、二进制大对象 (Blob)、S3 存储或 IBM 的通用并行文件系统 (GPFS)。在本文档中，我们介绍了如何使用 Hadoop 原生命令、 NetApp就地分析模块 (NIPAM) 和NetApp XCP 将数据从大数据分析平台和 GPFS 移动到 NFS。本文档还讨论了将数据从大数据和 HPC 转移到 AI 所带来的商业利益。</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">在哪里可以找到更多信息</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">要了解有关本文档中描述的信息的更多信息，请查看以下文档和/或网站：</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup卷最佳实践和实施指南</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp产品文档</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">本节介绍此解决方案的业务优势。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">商业利益</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">将数据从大数据分析转移到人工智能有以下好处：</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">能够将数据从不同的 Hadoop 文件系统和 GPFS 提取到统一的 NFS 存储系统</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">一种与 Hadoop 集成的自动化数据传输方式</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">降低从 Hadoop 文件系统移动数据的库开发成本</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">通过使用 NIPAM，通过从单一数据源聚合多个网络接口的吞吐量实现最高性能</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">预定和按需传输数据的方法</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">使用ONTAP数据管理软件实现统一 NFS 数据的存储效率和企业管理能力</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">使用 Hadoop 方法进行数据传输，实现零成本</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">本页讨论了客户在尝试访问大数据分析数据以进行 AI 操作时可能面临的挑战。</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">客户在尝试访问大数据分析数据以进行 AI 操作时可能会面临以下挑战：</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">客户数据位于数据湖存储库中。数据湖可以包含不同类型的数据，例如结构化、非结构化、半结构化、日志和机器对机器数据。所有这些数据类型都必须在人工智能系统中处理。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI 与 Hadoop 文件系统不兼容。典型的 AI 架构无法直接访问 HDFS 和 HCFS 数据，必须将这些数据移动到 AI 可理解的文件系统 (NFS)。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">将数据湖数据迁移至 AI 通常需要专门的流程。数据湖中的数据量可能非常大。客户必须拥有一种高效、高吞吐量且经济实惠的方式将数据移动到 AI 系统。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">正在同步数据。如果客户希望大数据平台和AI之间同步数据，有时候经过AI处理的数据可以和大数据一起进行分析处理。</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">在大数据集群中，数据存储在 HDFS 或 HCFS 中，例如 MapR-FS、Windows Azure Storage Blob、S3 或 Google 文件系统。我们使用 HDFS、MapR-FS 和 S3 作为源进行测试，在 NIPAM 的帮助下，使用源中的 hadoop distcp 命令将数据复制到NetApp ONTAP NFS 导出。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">数据移动器解决方案</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">在大数据集群中，数据存储在 HDFS 或 HCFS 中，例如 MapR-FS、Windows Azure Storage Blob、S3 或 Google 文件系统。我们以 HDFS、MapR-FS 和 S3 作为源，在 NIPAM 的帮助下将数据复制到NetApp ONTAP NFS 导出，使用<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>来自源的命令。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">下图说明了从使用 HDFS 存储运行的 Spark 集群到NetApp ONTAP NFS 卷的典型数据移动，以便NVIDIA可以处理 AI 操作。</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">这<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令使用 MapReduce 程序复制数据。  NIPAM 与 MapReduce 协同工作，在复制数据时充当 Hadoop 集群的驱动程序。 NIPAM 可以将负载分布到单个导出的多个网络接口上。当您将数据从 HDFS 或 HCFS 复制到 NFS 时，此过程通过将数据分布在多个网络接口上来最大化网络吞吐量。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">MapR 不支持或认证 NIPAM。</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">人工智能数据移动器解决方案基于客户处理来自人工智能操作的 Hadoop 数据的需求。 NetApp使用 NIPAM 将数据从 HDFS 移动到 NFS。在一个用例中，客户需要将数据移动到本地的 NFS，而另一个客户需要将数据从 Windows Azure Storage Blob 移动到Google Cloud NetApp Volumes ，以便处理来自云中的 GPU 云实例的数据。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">人工智能数据移动解决方案</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">下图说明了数据移动器解决方案的详细信息。</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">构建数据移动器解决方案需要以下步骤：</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN 提供 HDFS，NAS 通过 NIPAM 将 NFS 卷提供给生产数据湖集群。</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">客户的数据在HDFS和NFS中。  NFS 数据可以是来自其他应用程序的生产数据，用于大数据分析和 AI 操作。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone技术创建生产 NFS 卷的克隆并将其配置到内部的 AI 集群。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">使用 NIPAM 将 HDFS SAN LUN 中的数据复制到 NFS 卷中，并且<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令。 NIPAM 使用多个网络接口的带宽来传输数据。此过程减少了数据复制时间，从而可以传输更多数据。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">两个 NFS 卷均已配置给 AI 集群以进行 AI 操作。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">为了使用云中的 GPU 处理本地 NFS 数据，NFS 卷通过NetApp SnapMirror技术镜像到NetApp私有存储 (NPS)，并安装到 GPU 的云服务提供商。</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">客户希望使用云服务提供商的 GPU 来处理 EC2/EMR、HDInsight 或 DataProc 服务中的数据。  Hadoop 数据移动器使用 NIPAM 将数据从 Hadoop 服务移动到Google Cloud NetApp Volumes，并且<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令。</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Google Cloud NetApp Volumes数据通过 NFS 协议配置给 AI。通过 AI 处理的数据除了可以通过 NIPAM、 SnapMirror和 NPS 发送到NVIDIA集群之外，还可以发送到本地位置进行大数据分析。</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">在这种情况下，客户在远程位置的 NAS 系统中拥有大量文件数数据，这些数据是内部NetApp存储控制器上进行 AI 处理所必需的。在这种情况下，最好使用XCP迁移工具来以更快的速度迁移数据。</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">混合用例客户可以使用BlueXP Copy and Sync 将本地数据从 NFS、CIFS 和 S3 数据迁移到云端，反之亦然，以便使用NVIDIA集群等中的 GPU 进行 AI 处理。  BlueXP Copy and Sync 和 XCP Migration Tool 均用于将 NFS 数据迁移到NetApp ONTAP NFS。</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">在本次验证中，我们使用了四台服务器作为网络共享磁盘（NSD）服务器，为GPFS提供物理磁盘。 GPFS 创建于 NSD 磁盘之上，以将其导出为 NFS 导出，以便 NFS 客户端可以访问它们，如下图所示。我们使用 XCP 将数据从 GPFS 导出的 NFS 复制到NetApp NFS 卷。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS 到NetApp ONTAP NFS</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS 基础知识</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS 中使用以下节点类型：</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*管理节点。*指定一个可选字段，其中包含管理命令用于在节点之间进行通信的节点名称。例如，管理节点<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block>可以将网络检查传递给集群中的所有其他节点。</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*仲裁节点。*确定节点是否包含在派生仲裁的节点池中。您至少需要一个节点作为仲裁节点。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*管理节点*指示节点是否属于节点池的一部分，可以从中选择文件系统管理器和令牌管理器。将多个节点定义为管理节点是一个好主意。您指定为管理器的节点数取决于工作负载和您拥有的 GPFS 服务器许可证数量。如果您正在运行大型并行作业，则可能需要比支持 Web 应用程序的四节点集群更多的管理器节点。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD 服务器。*准备每个物理磁盘以供 GPFS 使用的服务器。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*协议节点。*通过任何安全外壳 (SSH) 协议直接与 NFS 共享 GPFS 数据的节点。此节点需要 GPFS 服务器许可证。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS、NFS 和 XCP 的操作列表</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">本节提供了创建 GPFS、将 GPFS 导出为 NFS 导出以及使用 XCP 传输数据的操作列表。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">创建 GPFS</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">要创建 GPFS，请完成以下步骤：</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">在其中一台服务器上下载并安装 Linux 版本的频谱规模数据访问。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">在所有节点上安装必备包（例如 chef），并在所有节点上禁用安全增强型 Linux（SELinux）。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">设置安装节点并将管理节点和 GPFS 节点添加到集群定义文件中。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">添加管理器节点、仲裁节点、NSD 服务器和 GPFS 节点。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">添加 GUI、管理和 GPFS 节点，并根据需要添加额外的 GUI 服务器。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">添加另一个 GPFS 节点并检查所有节点的列表。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">在集群定义文件中的所有 GPFS 节点上指定集群名称、配置文件、远程 shell 二进制文件、远程文件复制二进制文件和端口范围。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">查看 GPFS 配置设置并添加额外的管理节点。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">禁用数据收集并将数据包上传至 IBM 支持中心。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">启用 NTP 并在安装前预检查配置。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">配置、创建和检查 NSD 磁盘。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">创建 GPFS。</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">挂载 GPFS。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">验证并提供 GPFS 所需的权限。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">通过运行以下命令验证 GPFS 读写<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">将 GPFS 导出到 NFS</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">要将 GPFS 导出到 NFS，请完成以下步骤：</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">通过以下方式将 GPFS 导出为 NFS<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>文件。</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">安装所需的 NFS 服务器包。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">启动 NFS 服务。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">列出 GPFS 中的文件以验证 NFS 客户端。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">配置 NFS 客户端</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">要配置 NFS 客户端，请完成以下步骤：</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">通过<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>文件。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">启动 NFS 客户端服务。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">在NFS客户端上通过NFS协议挂载GPFS。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">验证 NFS 挂载文件夹中的 GPFS 文件列表。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">使用 XCP 将数据从 GPFS 导出的 NFS 移动到NetApp NFS。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">验证 NFS 客户端上的 GPFS 文件。</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">本节提供使用NetApp XCP 配置 GPFS 和将数据移动到 NFS 所需的详细步骤。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS 转 NFS-详细步骤</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">配置 GPFS</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">在其中一台服务器上下载并安装适用于 Linux 的 Spectrum Scale Data Access。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">在所有节点上安装必备包（包括 chef 和内核头）。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">在所有节点上禁用 SELinux。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">设置安装节点。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">将管理节点和 GPFS 节点添加到集群定义文件。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">添加管理器节点和GPFS节点。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">添加仲裁节点和 GPFS 节点。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">添加 NSD 服务器和 GPFS 节点。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">添加 GUI、管理和 GPFS 节点。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">添加另一个 GUI 服务器。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">添加另一个 GPFS 节点。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">验证并列出所有节点。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">在集群定义文件中指定集群名称。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">指定配置文件。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">指定 GPFS 使用的远程 shell 二进制文件；使用<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block>。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">指定 GPFS 使用的远程文件复制二进制文件；使用<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block>。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">指定所有 GPFS 节点上要设置的端口范围；使用<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block>。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">查看 GPFS 配置设置。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">添加管理节点。</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">启用 NTP。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">安装前预先检查配置。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">配置 NSD 磁盘。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">创建 NSD 磁盘。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">检查NSD磁盘状态。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">检查并提供 GPFS 所需的权限。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">通过运行以下命令检查 GPFS 读写<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">要将 GPFS 导出到 NFS，请完成以下步骤：</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">列出 GPFS 中的文件以验证 NFS 客户端。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">配置 NFS 客户端</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">在 NFS 客户端中安装程序包。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">验证 NFS 挂载文件夹中的 GPFS 文件列表。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">使用 XCP 将数据从 GPFS 导出的 NFS 移动到NetApp NFS。</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">对于此解决方案， NetApp验证了从数据湖 (HDFS) 和 MapR 集群数据到ONTAP NFS 的数据迁移。数据驻留在 MapR-FS 和 HDFS 中。  NetApp XCP 引入了一项新功能，可以将数据从分布式文件系统（如 HDFS 和 MapR-FS）直接迁移到ONTAP NFS。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 和 MapR-FS 到ONTAP NFS</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">对于此解决方案， NetApp验证了从数据湖 (HDFS) 和 MapR 集群数据到ONTAP NFS 的数据迁移。数据驻留在 MapR-FS 和 HDFS 中。  NetApp XCP 引入了一项新功能，可以将数据从分布式文件系统（如 HDFS 和 MapR-FS）直接迁移到ONTAP NFS。  XCP 使用异步线程和 HDFS C API 调用来与 MapR-FS 和 HDFS 进行通信并传输数据。</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">下图显示了从数据湖（HDFS）和MapR-FS到ONTAP NFS的数据迁移。有了这个新功能，您不必将源导出为 NFS 共享。</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">为什么客户要从 HDFS 和 MapR-FS 迁移到 NFS？</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">大多数 Hadoop 发行版（例如 Cloudera 和 Hortonworks）都使用 HDFS，而 MapR 发行版则使用自己的文件系统（称为 Mapr-FS）来存储数据。  HDFS 和 MapR-FS 数据为数据科学家提供了宝贵的见解，可用于机器学习 (ML) 和深度学习 (DL)。 HDFS 和 MapR-FS 中的数据不共享，这意味着其他应用程序无法使用它。客户正在寻找共享数据，特别是在银行业，客户的敏感数据被多个应用程序使用。 Hadoop最新版本（3.x以上版本）支持NFS数据源，无需额外的第三方软件即可访问。借助新的NetApp XCP 功能，可以将数据从 HDFS 和 MapR-FS 直接移动到NetApp NFS，以便提供对多个应用程序的访问</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">在 Amazon Web Services (AWS) 中进行了测试，将数据从 MapR-FS 传输到 NFS，以使用 12 个 MAPR 节点和 4 个 NFS 服务器进行初始性能测试。</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">数量</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">大小</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">内存</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">存储</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">网络</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 服务器</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8个7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 节点</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4个7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">根据初步测试，我们获得了 20GBps 的吞吐量，并且每天能够传输 2PB 的数据。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863：TR-4863： NetApp XCP 最佳实践指南 - 数据移动器、文件迁移和分析</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">有关不将 HDFS 导出到 NFS 的 HDFS 数据迁移的更多信息，请参阅<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block>。</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">本文提供了使用NetApp XCP 和 NIPAM 将大数据分析数据和 HPC 数据迁移到 AI 的指南。我们还讨论了将数据从大数据和 HPC 转移到 AI 所带来的商业利益。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732：大数据分析与人工智能</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam， NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">本文档介绍了如何将大数据分析数据和 HPC 数据迁移到 AI。 AI 通过 NFS 导出处理 NFS 数据，而客户通常将其 AI 数据放在大数据分析平台中，例如 HDFS、Blob 或 S3 存储以及 HPC 平台（例如 GPFS）。本文提供了使用NetApp XCP 和 NIPAM 将大数据分析数据和 HPC 数据迁移到 AI 的指南。我们还讨论了将数据从大数据和 HPC 转移到 AI 所带来的商业利益。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念和组件</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">大数据分析存储</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">大数据分析是HDFS的主要存储提供商。客户经常使用与 Hadoop 兼容的文件系统 (HCFS)，例如 Windows Azure Blob Storage、MapR 文件系统 (MapR-FS) 和 S3 对象存储。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">通用并行文件系统</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">IBM 的 GPFS 是一个企业文件系统，它提供了 HDFS 的替代方案。  GPFS 为应用程序提供了灵活性，可以决定块大小和复制布局，从而提供良好的性能和效率。</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetApp就地分析模块</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">NetApp就地分析模块 (NIPAM) 作为 Hadoop 集群访问 NFS 数据的驱动程序。它有四个组件：连接池、NFS 输入流、文件句柄缓存和 NFS 输出流。有关更多信息，请参阅<block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> 。</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop分布式复制</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop分布式复制（DistCp）是一个用于大型集群间和集群内复制任务的分布式复制工具。该工具使用 MapReduce 进行数据分发、错误处理和报告。它扩展文件和目录列表并将它们输入到映射任务中以从源列表复制数据。下图展示了 HDFS 和非 HDFS 中的 DistCp 操作。</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp 无需使用额外的驱动程序即可在两个 HDFS 系统之间移动数据。 NetApp为非 HDFS 系统提供驱动程序。对于 NFS 目标，NIPAM 提供驱动程序来复制数据，Hadoop DistCp 在复制数据时使用该驱动程序与 NFS 目标进行通信。</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes是一种具有极高性能的云原生文件服务。该服务可帮助客户通过快速增加或减少资源以及使用NetApp功能来提高生产力并减少员工停机时间，从而加快产品上市时间。  Google Cloud NetApp Volumes是灾难恢复和备份到云的正确替代方案，因为它减少了整体数据中心的占用空间并消耗了更少的原生公共云存储。</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP 是一款客户端软件，可实现快速可靠的任意到NetApp和NetApp到NetApp数据迁移。该工具旨在将大量非结构化 NAS 数据从任何 NAS 系统复制到NetApp存储控制器。 XCP 迁移工具使用多核、多通道 I/O 流引擎，可以并行处理许多请求，例如数据迁移、文件或目录列表以及空间报告。这是默认的NetApp数据迁移工具。您可以使用 XCP 将数据从 Hadoop 集群和 HPC 复制到NetApp NFS 存储。下图显示了使用 XCP 从 Hadoop 和 HPC 集群到NetApp NFS 卷的数据传输。</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXP复制和同步</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync 是一种混合数据复制软件即服务，可在本地存储和云存储之间无缝安全地传输和同步 NFS、S3 和 CIFS 数据。该软件用于数据迁移、存档、协作、分析等。数据传输完成后， BlueXP Copy and Sync 会在源和目标之间持续同步数据。接下来，它会传输增量。它还可以保护您自己的网络、云端或本地的数据。该软件基于现收现付模式，提供经济高效的解决方案，并为您的数据传输提供监控和报告功能。</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">本节提供使用NetApp XCP 将 MapR-FS 数据移动到ONTAP NFS 所需的详细步骤。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS 到ONTAP NFS</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">为每个 MapR 节点配置三个 LUN，并赋予所有 MapR 节点的 LUN 所有权。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">在安装过程中，为 MapR 集群磁盘选择新添加的用于 MapR-FS 的 LUN。</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">根据 MapR 6.1 文档安装 MapR 集群。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">使用 MapReduce 命令检查基本的 Hadoop 操作，例如<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block>。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">将客户数据保存在 MapR-FS 中。例如，我们使用 Teragen 在 MapR-FS 中生成了大约一兆字节的样本数据。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">将 MapR-FS 配置为 NFS 导出。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">在所有 MapR 节点上禁用 nlockmgr 服务。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">从所有 MapR 节点上的 MapR-FS 导出特定文件夹<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block>文件。导出子文件夹时，请勿导出具有不同权限的父文件夹。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">刷新MapR-FS NFS服务。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">将虚拟 IP 范围分配给 MapR 集群中的特定服务器或一组服务器。然后，MapR 集群为特定服务器分配一个 IP，用于 NFS 数据访问。  IP 可实现高可用性，这意味着，如果具有特定 IP 的服务器或网络出现故障，则 IP 范围中的下一个 IP 可用于 NFS 访问。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">如果您希望从所有 MapR 节点提供 NFS 访问，那么您可以为每个服务器分配一组虚拟 IP，并且可以使用每个 MapR 节点的资源进行 NFS 数据访问。</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">检查每个 MapR 节点上分配的虚拟 IP 并将其用于 NFS 数据访问。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">使用分配的虚拟 IP 挂载 NFS 导出的 MapR-FS 来检查 NFS 操作。但是，使用NetApp XCP 进行数据传输不需要此步骤。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">配置NetApp XCP 以将数据从 MapR-FS NFS 网关传输到ONTAP NFS。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">配置 XCP 的目录位置。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">将许可证文件复制到<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">使用<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block>命令。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">检查 NFS 导出的来源。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">使用 XCP 从多个 MapR 节点从多个源 IP 和多个目标 IP（ONTAP LIF）传输数据。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">检查存储控制器上的负载分布。</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">基于此验证，数据科学家和工程师可以通过NetApp Cloud Volumes ONTAP的 S3 存储桶访问来自 AWS SageMaker Jupyter Notebooks 的 NFS 数据。这种方法可以轻松访问和共享来自 NFS 和 S3 的相同数据，而无需额外的软件。</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">使用 SageMaker BlazingText 进行文本分类</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">ONTAP版本对 S3 对象存储的支持</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">数据可在 NFS 中使用，并可通过 AWS SageMaker 的 S3 访问。</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">数据科学家和其他应用程序的数据二元性</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">技术要求</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">对于数据二元性用例，您需要NetApp BlueXP、 NetApp Cloud Volumes ONTAP和 AWS SageMaker Notebooks。</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">软件要求</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">下表列出了实现用例所需的软件组件。</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker 笔记本</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">部署过程</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">部署数据二元性解决方案涉及以下任务：</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXP连接器</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">机器学习数据</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">通过 Jupyter Notebook 验证机器学习</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXP连接器</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">在本次验证中，我们使用了 AWS。它也适用于 Azure 和 Google Cloud。要在 AWS 中创建BlueXP连接器，请完成以下步骤：</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">我们使用了基于BlueXP中的 mcarl-marketplace-subscription 的凭证。</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">选择适合您环境的区域（例如，us-east-1 [N. Virginia]），并选择身份验证方法（例如，Assume Role 或 AWS keys）。在此验证中，我们使用 AWS 密钥。</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">提供连接器的名称并创建角色。</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">根据您是否需要公共 IP，提供网络详细信息，例如 VPC、子网或密钥对。</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">提供安全组的详细信息，例如来自源类型的 HTTP、HTTPS 或 SSH 访问，例如任何地方和 IP 范围信息。</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">审查并创建BlueXP连接器。</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">验证BlueXP EC2 实例状态是否在 AWS 控制台中运行，并从 *Networking* 选项卡中检查 IP 地址。</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">从BlueXP门户登录连接器用户界面，或者您可以使用 IP 地址从浏览器访问。</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">要在BlueXP中创建Cloud Volumes ONTAP实例，请完成以下步骤：</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">创建一个新的工作环境，选择云提供商，并选择Cloud Volumes ONTAP实例的类型（例如单 CVO、HA 或Amazon FSx ONTAP for ONTAP）。</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">提供详细信息，例如Cloud Volumes ONTAP集群名称和凭据。在此验证中，我们创建了一个Cloud Volumes ONTAP<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>。</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">选择Cloud Volumes ONTAP所需的服务。在这次验证中，我们选择仅监控，因此我们禁用了*数据感知与合规性*和*备份到云服务*。</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">在*位置和连接*部分中，选择 AWS 区域、VPC、子网、安全组、SSH 身份验证方法以及密码或密钥对。</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">选择充电方式。我们使用*专业版*进行此验证。</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">您可以选择预配置的包，例如*POC 和小型工作负载*、*数据库和应用程序数据生产工作负载*、*经济高效的 DR* 或 *最高性能生产工作负载*。在本次验证中，我们选择*Poc 和 Small Workloads*。</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">创建具有特定大小、允许的协议和导出选项的卷。在此验证中，我们创建了一个名为<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">选择配置文件磁盘类型和分层策略。在本次验证中，我们禁用了*存储效率*和*通用 SSD - 动态性能*。</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">最后，检查并创建Cloud Volumes ONTAP实例。然后等待 15-20 分钟让BlueXP创建Cloud Volumes ONTAP工作环境。</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">配置以下参数以启用 Duality 协议。从ONTAP 9 开始支持 Duality 协议 (NFS/S3)。  12.1 及更高版本。</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">在此验证中，我们创建了一个名为<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>和音量<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">验证 SVM 是否支持 NFS 和 S3 协议。如果没有，请修改 SVM 以支持它们。</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">如果需要，创建并安装 CA 证书。</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">创建服务数据策略。</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">检查汇总详细信息。</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">创建用户和组。</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">在 NFS 卷上创建一个存储桶。</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">要从 AWS SageMaker 创建 AWS Notebook，请完成以下步骤：</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">确保创建 Notebook 实例的用户具有 AmazonSageMakerFullAccess IAM 策略或属于具有 AmazonSageMakerFullAccess 权限的现有组的一部分。在此验证中，用户是现有组的一部分。</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">提供以下信息：</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">笔记本实例名称。</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">实例类型。</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">平台标识符。</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">选择具有 AmazonSageMakerFullAccess 权限的 IAM 角色。</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">根访问 – 启用。</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">加密密钥 - 选择无自定义加密。</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">保留其余默认选项。</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">本次验证中，SageMaker实例详情如下：</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">描述该步骤的屏幕截图。</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">启动 AWS Notebook。</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">打开 Jupyter 实验室。</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">登录终端并挂载Cloud Volumes ONTAP卷。</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">使用 AWS CLI 命令检查在Cloud Volumes ONTAP卷上创建的存储桶。</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">在这次验证中，我们使用了来自众包社区努力的 DBpedia 的数据集，从各种维基媒体项目创建的信息中提取结构化内容。</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">从 DBpedia GitHub 位置下载数据并提取。使用与上一节相同的终端。</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">将数据复制到Cloud Volumes ONTAP位置并使用 AWS CLI 从 S3 存储桶中进行检查。</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">执行基本验证以确保读/写功能在 S3 存储桶上正常运行。</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">通过 Jupyter Notebook 验证机器学习</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">以下验证通过使用以下 SageMaker BlazingText 示例通过文本分类提供机器学习构建、训练和部署模型：</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">安装 boto3 和 SageMaker 包。</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">输出：</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">在下一步中，数据<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block>) 从 s3 bucket 下载<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block>到机器学习中使用的 Jupyter Notebook 实例。</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">以下代码创建从整数索引到类标签的映射，用于在推理期间检索实际的类名。</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">输出列出了<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block>存储桶用作 AWS SageMaker 机器学习验证的数据。</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">开始数据预处理阶段，将训练数据预处理为空格分隔的标记化文本格式，BlazingText 算法和 nltk 库可以使用该格式对来自 DBPedia 数据集的输入句子进行标记化。下载 nltk 标记器和其他库。这<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block>并行应用于每个数据实例使用 Python 多处理模块。</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">将格式化和训练数据集上传到 S3，以便 SageMaker 可以使用它来执行训练作业。然后使用 Python SDK 将两个文件上传到存储桶和前缀位置。</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">在加载模型工件的 S3 处设置输出位置，以便工件可以作为算法训练作业的输出。创建一个<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block>对象来启动训练工作。</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">定义 SageMaker<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block>使用资源配置和超参数在 c4.4xlarge 实例上使用监督模式在 DBPedia 数据集上训练文本分类。</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">准备数据通道和算法之间的握手。为此，请创建<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block>来自数据通道的对象，并将它们保存在字典中以供算法使用。</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">作业完成后，将出现“作业完成”消息。训练好的模型可以在设置为<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block>在估算器中。</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">训练完成后，将训练好的模型部署为 Amazon SageMaker 实时托管终端节点以进行预测。</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">默认情况下，模型返回一个概率最高的预测。检索顶部<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>预测，设置<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>在配置文件中。</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">关闭笔记本之前删除端点。</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">数据科学家和工程师经常需要访问以 NFS 格式存储的数据，但直接从 AWS SageMaker 中的 S3 协议访问这些数据可能具有挑战性，因为 AWS 仅支持 S3 存储桶访问。但是， NetApp ONTAP通过为 NFS 和 S3 启用双协议访问提供了解决方案。通过此解决方案，数据科学家和工程师可以通过NetApp Cloud Volumes ONTAP的 S3 存储桶访问来自 AWS SageMaker 笔记本的 NFS 数据。这种方法可以轻松访问和共享来自 NFS 和 S3 的相同数据，而无需额外的软件。</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967：使用NetApp文件对象二元性和 AWS SageMaker 进行云数据管理</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">NFS 和 S3 双协议访问的一个潜在用例是在机器学习和数据科学领域。例如，一个数据科学家团队可能正在使用 AWS SageMaker 开展机器学习项目，这需要访问以 NFS 格式存储的数据。但是，可能还需要通过 S3 存储桶访问和共享数据，以便与其他团队成员协作或与使用 S3 的其他应用程序集成。</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">该解决方案采用以下技术：</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">AWS SageMaker 笔记本。为开发人员和数据科学家提供机器学习功能，以高效地创建、训练和部署高质量的 ML 模型。</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP。*支持在本地以及 AWS、Azure 和 Google Cloud 上发现、部署和操作存储。它提供数据保护，防止数据丢失、网络威胁和意外中断，并优化数据存储和基础设施。</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP。*在 AWS、Azure 和 Google Cloud 上提供具有 NFS、SMB/CIFS、iSCSI 和 S3 协议的企业级存储卷，让用户在访问和管理云中的数据时拥有更大的灵活性。</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">NetApp Cloud Volumes ONTAP由BlueXP创建，用于存储 ML 数据。</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">下图展示了该解决方案的技术组件。</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">该图显示了该解决方案的技术组件。</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">通过利用NetApp Cloud Volumes ONTAP，团队可以将其数据存储在单个位置，并可通过 NFS 和 S3 协议访问。数据科学家可以直接从 AWS SageMaker 访问 NFS 格式的数据，而其他团队成员或应用程序可以通过 S3 存储桶访问相同的数据。</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">这种方法可以轻松高效地访问和共享数据，而无需额外的软件或不同存储解决方案之间的数据迁移。它还允许团队成员之间更简化的工作流程和协作，从而更快、更有效地开发机器学习模型。</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">本文档提供了将 Kafka 与NetApp存储结合使用的最佳实践指南，包括 Confluent Kafka 认证测试、性能结果、调整、Kafka 连接器和自我重新平衡功能。</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">本文档提供了将 Confluent 分层存储与NetApp存储结合使用的最佳实践指南，包括验证测试、分层存储性能结果、调整、Confluent S3 连接器和自平衡功能。考虑到 ILM 策略、经过多项性能测试验证的 Confluent 性能以及行业标准的 S3 API， NetApp StorageGRID对象存储是 Confluent 分层存储的最佳选择。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">什么是 Apache Kafka</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-sink 参数详情</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">阿帕奇卡夫卡</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent 平台中的无限存储</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent 分层存储 - 最佳实践和规模</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent 平台的 Amazon S3 接收器连接器</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka 大小</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID大小调整</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka 用例</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Confluence 平台 6.0 中的自平衡 Kafka 集群</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">本文档介绍了在NetApp存储控制器上使用 Kafka 的最佳实践指南。</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam、Joseph Kandatilparambil、 NetApp Rankesh Kumar、Confluence</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka 是一个社区分布式事件流平台，每天能够处理数万亿个事件。 Kafka 最初被认为是一个消息队列，基于分布式提交日志的抽象。自 2011 年由 LinkedIn 创建并开源以来，Kafka 已经从一个消息队列发展成为一个成熟的事件流平台。  Confluent 通过 Confluent 平台提供 Apache Kafka 的分发。  Confluent 平台为 Kafka 提供了额外的社区和商业功能，旨在增强大规模生产中运营商和开发人员的流媒体体验。</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">本文档通过提供以下内容描述了在 NetApp 对象存储产品上使用 Confluent 分层存储的最佳实践指南：</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">使用NetApp对象存储进行汇合验证 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">分层存储性能测试</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetApp存储系统上 Confluent 的最佳实践指南</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">为什么选择 Confluent 分层存储？</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">本文由 Confluent 撰写</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent 已成为许多应用程序的默认实时流媒体平台，尤其是对于大数据、分析和流媒体工作负载。分层存储使用户能够在 Confluent 平台中将计算与存储分开。它使存储数据更具成本效益，使您能够存储几乎无限量的数据并按需扩大（或缩小）工作负载，并使数据和租户重新平衡等管理任务更加容易。 S3 兼容存储系统可以利用所有这些功能，将所有事件集中在一个地方，实现数据民主化，从而无需复杂的数据工程。有关为什么应该为 Kafka 使用分层存储的更多信息，请查看<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">为什么选择NetApp StorageGRID进行分层存储？</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID是NetApp推出的业界领先的对象存储平台。  StorageGRID是一种软件定义的基于对象的存储解决方案，支持行业标准对象 API，包括 Amazon Simple Storage Service (S3) API。 StorageGRID大规模存储和管理非结构化数据，以提供安全、持久的对象存储。内容被放置在正确的位置、正确的时间和正确的存储层，从而优化工作流程并降低全球分布的富媒体的成本。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID最大的区别在于其信息生命周期管理 (ILM) 策略引擎，它支持策略驱动的数据生命周期管理。策略引擎可以使用元数据来管理数据在其整个生命周期内的存储方式，以便最初优化性能，并随着数据老化自动优化成本和耐用性。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">启用 Confluent 分层存储</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">分层存储的基本思想是将数据存储任务与数据处理任务分离。通过这种分离，数据存储层和数据处理层可以更轻松地独立扩展。</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Confluent 的分层存储解决方案必须应对两个因素。首先，它必须解决或避免常见的对象存储一致性和可用性属性，例如 LIST 操作中的不一致和偶尔的对象不可用。其次，它必须正确处理分层存储与 Kafka 的复制和容错模型之间的交互，包括僵尸领导者继续分层偏移范围的可能性。  NetApp对象存储提供一致的对象可用性和 HA 模型，使分层存储可用于层偏移范围。  NetApp对象存储提供一致的对象可用性和 HA 模型，使分层存储可用于层偏移范围。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">通过分层存储，您可以使用高性能平台在流数据尾部附近进行低延迟读写，还可以使用更便宜、可扩展的对象存储（如NetApp StorageGRID）进行高吞吐量历史读取。我们还为带有 netapp 存储控制器的 Spark 提供了技术解决方案，详细信息请见此处。下图显示了 Kafka 如何融入实时分析管道。</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">下图描述了NetApp StorageGRID如何作为 Confluent Kafka 的对象存储层。</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">本节介绍 Confluent 认证所使用的硬件和软件。此信息适用于使用NetApp存储的 Kafka 部署。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">浆纱</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka 大小调整可以通过四种配置模式进行：简单、粒度、反向和分区。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">简单的</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">简单模式适合首次使用 Apache Kafka 的用户或早期使用案例。对于此模式，您可以提供吞吐量 MBps、读取扇出、保留和资源利用率百分比（默认值为 60%）等要求。您还可以进入环境，例如本地（裸机、VMware、Kubernetes 或 OpenStack）或云。根据这些信息，Kafka 集群的大小提供了代理、zookeeper、Apache Kafka 连接工作器、模式注册表、REST 代理、ksqlDB 和 Confluent 控制中心所需的服务器数量。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">对于分层存储，请考虑使用粒度配置模式来确定 Kafka 集群的大小。粒度模式适合经验丰富的 Apache Kafka 用户或定义明确的用例。本节介绍生产者、流处理器和消费者的大小。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">生产者</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">要描述 Apache Kafka 的生产者（例如本机客户端、REST 代理或 Kafka 连接器），请提供以下信息：</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*姓名。*火花。</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*生产者类型。*应用程序或服务、代理（REST、MQTT、其他）和现有数据库（RDBMS、NOSQL、其他）。您也可以选择“我不知道”。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*平均吞吐量。*以每秒事件数计算（例如 1,000,000）。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*峰值吞吐量。*以每秒事件数计算（例如 4,000,000）。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*平均消息大小。*以字节为单位，未压缩（最大 1MB；例如 1000）。</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*消息格式。*选项包括 Avro、JSON、协议缓冲区、二进制、文本、“我不知道”和其他。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*复制因子。*选项为 1、2、3（Confluent 建议）、4、5 或 6。</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*保留时间。*有一天（例如）。您希望将数据存储在 Apache Kafka 中多长时间？输入 -1 和任意单位可表示无限时间。计算器假设无限保留的保留时间为 10 年。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">选中“启用分层存储以减少代理数量并允许无限存储？”复选框。</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">启用分层存储后，保留字段控制在代理本地存储的热数据集。档案保留字段控制数据在档案对象存储中的存储时间。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*档案存储保留。*一年（例如）。您希望将数据保存在档案存储中多长时间？输入 -1 和任意单位可获得无限持续时间。计算器假设无限保留的保留时间为 10 年。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*增长乘数。* 1（例如）。如果此参数的值基于当前吞吐量，则将其设置为 1。要根据额外增长确定大小，请将此参数设置为增长乘数。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">生产者实例的数量。 10（例如）。将运行多少个生产者实例？此输入需要将 CPU 负载纳入到尺寸计算中。空白值表示 CPU 负载未纳入计算。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">根据此示例输入，尺寸对生产者有以下影响：</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">未压缩字节的平均吞吐量：1GBps。未压缩字节的峰值吞吐量：4GBps。压缩字节的平均吞吐量：400MBps。压缩字节的峰值吞吐量：1.6GBps。这是基于默认的 60% 压缩率（您可以更改此值）。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">所需的代理热集存储总量：31,104TB，包括复制和压缩。所需的总代理外存档存储：378,432TB（压缩）。使用<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block>用于StorageGRID大小调整。</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">流处理器必须描述从 Apache Kafka 使用数据并返回到 Apache Kafka 的应用程序或服务。大多数情况下，这些都是在 ksqlDB 或 Kafka Streams 中构建的。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*姓名。*火花飘带。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*处理时间。*该处理器处理一条消息需要多长时间？</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 毫秒（简单、无状态转换）[示例]，10 毫秒（有状态的内存操作）。</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms（有状态网络或磁盘操作），1000ms（第三方 REST 调用）。</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">我已经对这个参数进行了基准测试，并且确切地知道需要多长时间。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*输出保留。* 1天（示例）。流处理器将其输出返回给 Apache Kafka。您希望这些输出数据在 Apache Kafka 中存储多长时间？输入 -1 和任意单位可获得无限持续时间。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">选中复选框“启用分层存储以减少代理数量并允许无限存储？”</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*档案存储保留。* 1年（例如）。您希望将数据保存在档案存储中多长时间？输入 -1 和任意单位可获得无限持续时间。计算器假设无限保留的保留时间为 10 年。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*输出直通百分比。* 100（例如）。流处理器将其输出返回给 Apache Kafka。入站吞吐量的百分比将输出回 Apache Kafka？例如，如果入站吞吐量为 20MBps，且该值为 10，则输出吞吐量将为 2MBps。</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">这是从哪些应用程序读取的？选择“Spark”，这是基于生产者类型的大小调整中使用的名称。根据以上输入，您可以预期流处理器实例和主题分区估计的大小会产生以下影响：</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">该流处理器应用程序需要以下数量的实例。传入的主题可能也需要这么多的分区。联系 Confluent 确认此参数。</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">1,000 表示平均吞吐量，无增长乘数</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">峰值吞吐量为 4,000，无增长乘数</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">1,000 表示平均吞吐量，并带有增长乘数</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">峰值吞吐量为 4,000，并带有增长乘数</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">消费者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">描述使用来自 Apache Kafka 的数据但不返回到 Apache Kafka 的应用程序或服务；例如，本机客户端或 Kafka 连接器。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*姓名。*激发消费者。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*处理时间。*该消费者需要多长时间来处理一条消息？</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1ms（例如，像日志记录这样的简单且无状态的任务）</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10ms（快速写入数据存储）</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 毫秒（数据存储写入速度慢）</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ms（第三方 REST 调用）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">一些其他已知持续时间的基准测试过程。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*消费者类型。*应用程序、代理或接收器至现有数据存储（RDBMS、NoSQL 等）。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">这是从哪些应用程序读取的？将此参数与之前确定的生产者和流大小连接起来。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">根据以上输入，您必须确定消费者实例的大小和主题分区估计。消费者应用程序需要以下数量的实例。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">平均吞吐量为 2,000，无增长乘数</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">峰值吞吐量为 8,000，无增长乘数</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">平均吞吐量为 2,000，包括增长乘数</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">峰值吞吐量为 8,000，包括增长乘数</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">传入的主题可能也需要这个数量的分区。联系 Confluent 进行确认。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">除了对生产者、流处理器和消费者的要求之外，您还必须提供以下额外要求：</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*重建时间。*例如4小时。如果 Apache Kafka 代理主机发生故障，其数据丢失，并且需要配置新主机来替换故障主机，那么这个新主机必须多快重建自身？如果值未知，请将此参数留空。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*资源利用率目标（百分比）。*例如，60。您希望您的主机在平均吞吐量期间的利用率如何？  Confluent 建议利用率为 60%，除非您使用 Confluent 自平衡集群，在这种情况下利用率可能会更高。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">描述你的环境</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*您的集群将在什么环境中运行？*亚马逊网络服务、微软 Azure、谷歌云平台、本地裸机、本地 VMware、本地 OpenStack 还是本地 Kubernates？</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*主人详细信息。*核心数：例如48个，网卡类型（10GbE、40GbE、16GbE、1GbE或其他类型）。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*存储卷。*主持人：12（例如）。每个主机支持多少个硬盘或 SSD？  Confluent 建议每个主机配备 12 个硬盘。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*存储容量/卷（以 GB 为单位）。* 1000（例如）。单个卷可以存储多少 GB 的存储空间？  Confluent 建议使用 1TB 磁盘。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">存储配置。存储卷如何配置？ Confluent 建议使用 RAID10 来充分利用 Confluent 的所有功能。还支持 JBOD、SAN、RAID 1、RAID 0、RAID 5 和其他类型。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*单卷吞吐量（MBps）。* 125（例如）。单个存储卷每秒的读取或写入速度是多少兆字节？  Confluent 推荐使用标准硬盘，其吞吐量通常为 125MBps。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*内存容量（GB）。*  64（例如）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">确定环境变量后，选择“Size my Cluster”。根据上面指出的示例参数，我们确定了 Confluent Kafka 的以下大小：</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka。*经纪人数量：22。您的集群受存储限制。考虑启用分层存储以减少主机数量并允许无限存储。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">Apache ZooKeeper。数量：5；Apache Kafka Connect Workers：数量：2；Schema Registry：数量：2；REST Proxy：数量：2；ksqlDB：数量：2；Confluent Control Center：数量：1。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">对于平台团队，请使用反向模式，无需考虑用例。使用分区模式来计算单个主题需要多少个分区。看<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block>根据反向和分区模式进行大小调整。</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">解决方案架构细节</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">本节介绍用于 Confluent 验证的硬件和软件。此信息适用于使用NetApp存储的 Confluent Platform 部署。下表涵盖了经过测试的解决方案架构和基本组件。</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">解决方案组件</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">详细信息</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 版本 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">三位动物园管理员</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">五台经纪商服务器</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">五款工具服务器</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">一个 Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">一个控制中心</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux（Ubuntu 18.04）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">所有服务器</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">NetApp StorageGRID用于分层存储</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID软件</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000（负载均衡器）</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 个 SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 协议</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE（代理和StorageGRID实例之间的网络连接）</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15台富士通PRIMERGY RX2540服务器</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">每个配备：* 2 个 CPU，共 16 个物理核心 * Intel Xeon * 256GB 物理内存 * 100GbE 双端口</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">本文档提供了将 Dremio 与NetApp存储结合使用的最佳实践指南，包括 TPCDS 认证测试、调整和客户用例详细信息。</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">总之，本技术报告提供了混合 Iceberg Lakehouse 与 Dremio 结合使用以及来自NetApp存储控制器的各种数据源（包括ONTAP S3、NAS 和StorageGRID）的全面部署详细信息。部署过程成功执行，并利用 TPC-DS 基准测试工具跨不同数据源执行了 99 个 SQL 查询。该报告还探讨了NetApp内部的客户使用案例，展示了 Dremio 在满足多样化业务需求方面的多功能性和有效性。此外，还研究了涉及汽车零部件销售客户的具体用例，强调了利用 Dremio 进行数据分析和洞察的实际应用和好处。</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">总体而言，本文档是了解 Dremio 与NetApp存储控制器的部署和使用的宝贵资源，展示了其在推动各个行业数据驱动决策和优化的能力和潜力。</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Zookeeper 安装</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">德雷米奥</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">使用 storageGRID 配置 Dremio</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">NetApp用例</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">我们已经通过 Dremio 平台认证并在NetApp对象存储中进行了 Lakehouse 验证。</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">部署流程</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">该图展示了采用NetApp存储控制器的 dremio 架构</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">在此参考架构验证中，我们使用了由一个协调器和四个执行器组成的 Dremio 配置<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">NetApp设置</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">存储系统初始化</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">存储虚拟机 (SVM) 创建</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">逻辑网络接口的分配</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS、S3 配置和许可</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">对于 NFS（网络文件系统），请按照以下步骤操作：1.为 NFSv4 或 NFSv3 创建 Flex Group 卷。在我们为此次验证设置的设置中，我们使用了 48 个 SSD，其中 1 个 SSD 专用于控制器的根卷，另外 47 个 SSD 分布在 NFSv4]]。验证 Flex Group 卷的 NFS 导出策略是否对 Dremio 服务器网络具有读/写权限。</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">在所有 Dremio 服务器上，创建一个文件夹，并通过每个 Dremio 服务器上的逻辑接口 (LIF) 将 Flex Group 卷挂载到该文件夹上。</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">对于 S3（简单存储服务），请按照以下步骤操作：</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">使用“vserver object-store-server create”命令设置一个启用 HTTP 的对象存储服务器，并将管理状态设置为“up”。您可以选择启用 HTTPS 并设置自定义侦听器端口。</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">使用“vserver object-store-server user create -user &lt;username&gt;”命令创建 object-store-server 用户。</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">要获取访问密钥和密钥，可以运行以下命令：“set diag; vserver object-store-server user show -user &lt;username&gt;”。但是，今后这些密钥将在用户创建过程中提供，或者可以使用 REST API 调用来检索。</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">使用步骤 2 中创建的用户建立对象存储服务器组并授予访问权限。在这个例子中，我们提供了“FullAccess”。</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">通过将其类型设置为“S3”来创建两个 S3 存储桶。一个用于 Dremio 配置，一个用于客户数据。</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Zookeeper 设置</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">您可以使用 Dremio 提供的 zookeeper 配置。在此验证中，我们使用了单独的 Zookeeper。我们遵循了此网页链接中提到的步骤<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Dremio 设置</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">我们按照此网页链接通过 tar ball 安装 Dremio。</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">创建一个 Dremio 群组。</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">创建一个 dremio 用户。</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">创建 Dremio 目录。</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">下载 tar 文件<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">将 Dremio 解压到 /opt/dremio 目录中。</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">为配置文件夹创建符号链接。</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">设置您的服务配置（SystemD 设置）。</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">将 dremio 守护进程的单元文件从 /opt/dremio/share/dremio.service 复制到 /etc/systemd/system/dremio.service。</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">重启系统</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">启用 dremio 在启动时启动。</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">在协调器上配置 Dremio。有关更多信息，请参阅 Dremio 配置</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">核心站点.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">Dremio 配置存储在NetApp对象存储中。在我们的验证中，“dremioconf”存储桶位于 ontap S3 存储桶中。下图显示了“dremioconf”S3存储桶的“scratch”和“uploads”文件夹的一些详细信息。</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">该图显示了 dremio 与NetApp对象存储</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">在执行器上配置 Dremio。在我们的设置中，我们有 3 个执行者。</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – 与协调器配置相同。</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp推荐使用StorageGRID作为 Datalake 和 Lakehouse 环境的主要对象存储解决方案。此外， NetApp ONTAP还用于实现文件/对象二元性。在本文档中，我们根据客户要求对ONTAP S3 进行了测试，并且它成功地充当了数据源。</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">多源设置</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">在 Dremio 中将ONTAP S3 和 storageGRID 配置为 s3 源。</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dremio 仪表板 -&gt; 数据集 -&gt; 来源 -&gt; 添加来源。</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">在常规部分，请更新 AWS 访问权限和密钥</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">在高级选项中，启用兼容模式，使用以下详细信息更新连接属性。来自NetApp存储控制器的端点 IP/名称，来自 ontap S3 或 storageGRID。</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">尽可能启用本地缓存，尽可能使用的总可用缓存的最大百分比 = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">该图显示了NetApp对象存储中的文件列表</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">然后查看NetApp对象存储的存储桶列表。<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">storageGRID 存储桶详细信息的示例视图<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">在 Dremio 中将 NAS（特别是 NFS）配置为源。</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">在常规部分中，输入名称和 NFS 挂载路径。请确保 NFS 挂载路径安装在 Dremio 集群中所有节点的同一个文件夹中。</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">本文档介绍了在NetApp存储控制器上使用 Dremio 的最佳实践指南。</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">NetApp和 Dremio 的下一代混合 Iceberg Lakehouse 解决方案</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">在本文档中，我们讨论了 Dremio 与来自NetApp存储控制器的不同数据源的部署细节，包括ONTAP S3、NAS 和StorageGRID。在部署期间，我们使用 TPC-DS 基准测试工具跨各种来源执行 99 个 SQL 查询。该文档还探讨了NetApp内部的客户用例，以及涉及汽车零部件销售客户的用例。</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">本节介绍用于 dremio 认证的硬件和软件。此信息适用于使用NetApp存储的 dremio 部署。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">解决方案概述</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">混合 Iceberg Lakehouse 解决方案提供了独特的优势，以解决数据湖客户面临的客户挑战。通过利用 Dremio Unified Lakehouse 平台和NetApp ONTAP、 StorageGRID和NetApp Cloud 解决方案，公司可以为其业务运营增加显著的价值。该解决方案不仅可以访问包括NetApp源在内的多个数据源，还可以提高整体分析性能并帮助公司获得业务洞察力，从而促进业务增长。</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp概述</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">NetApp 的产品（例如ONTAP和StorageGRID）可实现存储和计算的分离，从而根据特定需求实现最佳资源利用率。这种灵活性使客户能够使用NetApp存储解决方案独立扩展其存储</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">通过利用 NetApp 的存储控制器，客户可以使用 NFS 和 S3 协议高效地向其矢量数据库提供数据。这些协议方便了客户数据存储和管理矢量数据库索引，从而无需通过文件和对象方法访问多个数据副本。</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP为 AWS、Azure 和 Google Cloud 等领先的云服务提供商提供对 NAS 和对象存储的原生支持。这种广泛的兼容性确保了无缝集成，实现了客户数据移动性、全球可访问性、灾难恢复、动态可扩展性和高性能。</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">我们行业领先的对象存储 storageGRID 提供了强大的策略引擎，用于自动放置数据、灵活的部署选项以及通过分层擦除编码实现的无与伦比的耐用性。它具有可扩展的架构，可在单个命名空间中支持数十亿个对象和 PB 级数据。该解决方案支持混合云集成，允许数据分层到主要云平台。它在 2019 年 IDC Marketscape 全球基于对象的供应商评估中被评为领导者。</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">此外，storageGRID 还擅长通过软件定义的对象存储、地理冗余和多站点功能大规模管理非结构化数据。它采用基于策略的信息生命周期管理，并提供镜像和搜索等云集成功能。它拥有多项认证，包括通用标准、NF203 数字安全组件、ISO/IEC 25051、毕马威和科哈塞特合规评估。</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">总之， NetApp storageGRID 提供强大的功能、可扩展性、混合云集成和合规性认证，可高效管理大规模非结构化数据。</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP是一款强大的存储解决方案，可提供广泛的企业功能。它包括快照，可提供应用程序一致且防篡改的即时备份。 SnapRestore支持按需近乎即时地恢复备份，而SnapMirror提供集成的远程备份和灾难恢复功能。该解决方案还采用了自主勒索软件保护 (ARP)，通过多管理员验证、具有 FIPS 认证的静态数据加密、传输中数据加密、多因素身份验证 (MFA) 和基于角色的访问控制 (RBAC) 等功能确保数据安全。全面的日志记录、审计、板载和外部密钥管理、安全清除以及多租户安全管理进一步增强了数据安全性和合规性。</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP还具有SnapLock功能，它以较低的总拥有成本提供符合法规的数据保留，具有高水平的完整性、性能和保留。它与NetApp ONTAP 9 完全集成，并提供针对恶意行为、恶意管理员和勒索软件的保护。</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">该解决方案包括用于动态数据和静态数据加密的 NSE/NVE 加密、多因素管理访问和多管理验证。 Active IQ提供基于 AI 的预测分析和纠正措施，而 QoS 确保服务质量工作负载控制。通过 SysMgr/GUI/CLI/API 可以直观地实现管理和自动化集成。  FabricPool支持自动数据分层，该解决方案通过内联数据压缩、重复数据删除和压缩提供效率。  NetApp保证满足工作负载效率目标，且客户无需承担任何费用。</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP支持各种协议，包括 NVMe/FC、FC、NVMe/TCP、iSCSI、NFS、SMB 和 S3，使其成为统一的存储解决方案。总体而言， NetApp ONTAP提供广泛的企业功能、强大的安全性、合规性、效率和多功能性，以满足多样化的存储需求。</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Dremio 概述</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio 是用于自助分析和人工智能的统一 Lakehouse 平台。  Dremio 统一分析平台凭借 Lakehouse 的灵活性、可扩展性和性能，让用户更接近数据，而成本仅为传统数据仓库解决方案的一小部分。  Dremio 支持“左移”分析，以消除复杂且昂贵的数据集成和 ETL，提供无需数据移动的无缝企业级分析。  Dremio 还具有以下特点：</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">通过通用语义层和紧密集成的高性能 SQL 查询引擎实现易于使用的自助服务分析，从而更轻松地连接、管理和分析云端和本地的所有数据。</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Dremio 的 Apache Iceberg 原生 Lakehouse 管理功能简化了数据发现，并自动化了数据优化，通过受 Git 启发的数据版本控制提供高性能分析。</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Dremio 建立在开源和开放标准的基础之上，帮助企业避免锁定并保持创新优势。企业公司信赖 Dremio，认为它是最易于使用的 Lakehouse 平台，在所有工作负载下都具有最佳的性价比。</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Dremio 和NetApp混合 Iceberg Lakehouse 解决方案为客户带来什么价值？</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*改进的数据管理和可访问性*：Dremio 以其数据湖平台而闻名，该平台使组织能够直接从其数据湖中高速查询数据。另一方面， NetApp是云数据服务和数据存储解决方案的领先提供商。该联合产品为客户提供了一套全面的解决方案，用于高效地存储、管理、访问和分析其企业的数据。</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*性能优化*：凭借 NetApp 在数据存储方面的专业知识以及 Dremio 在数据处理和数据优化方面的能力，该合作伙伴关系提供了一种解决方案，可以提高数据操作的性能，减少延迟，并提高业务洞察的速度。  Dremio 甚至为 NetApp 自己的内部 IT 分析基础设施带来了性能优势。</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*可扩展性*：Dremio 和NetApp都提供了可扩展的解决方案。该联合解决方案为客户提供高度可扩展的数据存储、数据管理和分析环境。在混合 Iceberg Lakehouse 环境中，Dremio SQL 查询引擎与NetApp StorageGRID配对，提供无与伦比的可扩展性、并发性和查询性能，能够满足任何业务的分析需求。</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*数据安全和治理*：两家公司都非常重视数据安全和治理。它们共同提供强大的安全和数据治理功能，确保数据受到保护并且满足数据治理要求。基于角色和细粒度的访问控制、全面审计、端到端数据沿袭、统一身份管理以及具有广泛合规性和安全框架的 SSO 等功能可确保公司的分析数据环境安全且受到管理。</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*成本效益*：通过将 Dremio 的数据湖引擎与 NetApp 的存储解决方案相结合，客户可以降低与数据管理和数据移动相关的成本。组织还能够从传统的数据湖环境迁移到由NetApp和 Dremio 组成的更现代的 Lakehouse 解决方案。该混合 Iceberg Lakehouse 解决方案提供高速查询性能和市场领先的查询并发性，可降低 TCO 并缩短业务洞察时间。</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">本节介绍此解决方案所使用的技术。</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">技术要求</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">下面概述的硬件和软件配置用于本文档中执行的验证。这些配置可作为帮助您设置环境的指南，但请注意，具体组件可能会因个别客户的要求而异。</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">硬件要求</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">硬件</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">NetApp AFF存储阵列 HA 对</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48个3.49TB SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">两个 S3 存储桶：Dremio 元数据和客户数据。</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">4台富士通PRIMERGY RX2540 M4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64 个 CPU</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">英特尔至强金牌 6142 CPU @ 2.60GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM 物理内存</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 个 100GbE 网络端口</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">网络连接</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100 GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100、3xSGF6024 * 3 x 24 x 7.68TB * 两个 S3 存储桶：Dremio 元数据和客户数据。</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">版本 - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">企业版</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">本地部署</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">5节点Dremio集群</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1 个主协调员和 4 个执行员</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">本节介绍 Dremio 与 NetApp 对象存储的客户用例详细信息。</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">客户用例</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">NetApp ActiveIQ 用例</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">ActiveIQ旧架构</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*挑战*：NetApp 自己的内部Active IQ解决方案最初设计用于支持众多用例，现已发展成为面向内部用户和客户的综合产品。然而，由于数据的快速增长和对高效数据访问的需求，基于 Hadoop/MapR 的底层后端基础设施在成本和性能方面带来了挑战。扩展存储意味着添加不必要的计算资源，从而导致成本增加。</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">此外，管理 Hadoop 集群非常耗时，并且需要专业知识。数据性能和管理问题进一步使情况复杂化，查询平均需要 45 分钟，并且由于配置错误导致资源匮乏。为了应对这些挑战， NetApp寻求现有传统 Hadoop 环境的替代方案，并确定基于 Dremio 构建的新型现代解决方案可以降低成本、分离存储和计算、提高性能、简化数据管理、提供细粒度控制并提供灾难恢复功能。</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">ActiveIQ 与 Dremio 的新架构</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*解决方案*：<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio 使NetApp能够分阶段实现其基于 Hadoop 的数据基础架构的现代化，为统一分析提供路线图。与其他需要对数据处理进行重大更改的供应商不同，Dremio 与现有管道无缝集成，从而节省了迁移期间的时间和费用。通过过渡到完全容器化的环境， NetApp降低了管理开销、提高了安全性并增强了弹性。  Dremio 采用 Apache Iceberg 和 Arrow 等开放生态系统，确保了面向未来性、透明度和可扩展性。</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">作为 Hadoop/Hive 基础设施的替代品，Dremio 通过语义层提供了二级用例的功能。虽然现有的基于 Spark 的 ETL 和数据提取机制仍然存在，但 Dremio 提供了统一的访问层，以便更轻松地发现和探索数据，而无需重复。这种方法显著减少了数据复制因素，并分离了存储和计算。</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*好处*：借助 Dremio， NetApp通过最大限度地减少数据环境中的计算消耗和磁盘空间要求，实现了显著的成本削减。新的Active IQ数据湖由 8,900 个表组成，包含 3PB 的数据，而之前的基础架构包含超过 7PB 的数据。迁移到 Dremio 还涉及从 33 个微集群和 4,000 个核心过渡到 Kubernetes 集群上的 16 个执行器节点。即使计算资源大幅减少， NetApp 的性能仍得到显著提升。通过 Dremio 直接访问数据，查询运行时间从 45 分钟减少到 2 分钟，从而使预测性维护和优化的洞察时间提高了 95%。迁移还使计算成本降低了 60% 以上，查询速度提高了 20 倍以上，并且总拥有成本 (TCO) 节省了 30% 以上。</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">汽车零部件销售客户用例。</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*挑战*：在这家全球汽车零部件销售公司中，高管和企业财务规划和分析小组无法获得销售报告的综合视图，而被迫阅读单独的业务线销售指标报告并尝试合并它们。这导致客户根据至少一天前的数据做出决策。获得新的分析见解的准备时间通常需要四周以上的时间。排除数据管道故障需要更多时间，在本来就很长的时间表上再增加三天或更长时间。缓慢的报告开发过程以及报告性能迫使分析师群体不断等待数据处理或加载，而不是让他们发现新的业务见解并推动新的业务行为。这些问题环境由不同业务线的众多不同数据库组成，从而导致出现大量数据孤岛。缓慢而分散的环境使数据治理变得复杂，因为分析师有太多方法可以得出自己的事实版本，而不是单一的事实来源。该方法的数据平台和人力成本超过 190 万美元。维护遗留平台和填写数据请求每年需要七名现场技术工程师 (FTE)。随着数据请求的增长，数据智能团队无法扩展旧环境以满足未来的需求</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*解决方案*：在NetApp对象存储中经济高效地存储和管理大型 Iceberg 表。使用 Dremio 的语义层构建数据域，让业务用户轻松创建、搜索和共享数据产品。</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*客户受益*：• 改进并优化现有数据架构，将洞察时间从四周缩短至数小时 • 将故障排除时间从三天缩短至数小时 • 降低数据平台和管理成本超过 380,000 美元 • 每年节省 (2) 个 FTE 数据智能工作量</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">我们使用NetApp对象存储（例如ONTAP和 storagegrid）对五个节点的 sql 工作负载执行了 tpc-ds 测试。</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">解决方案验证概述</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">在本节中，我们从多个来源执行了 SQL 测试查询来验证功能、测试并验证对NetApp存储的溢出。</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">对象存储上的 SQL 查询</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">在 dremio.env 中将每台服务器的内存设置为 250GB</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">检查 dremio.conf 文件中的溢出位置 (${DREMIO_HOME}"/dremiocache) 和存储详细信息。</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">将 Dremio 溢出位置指向NetApp NFS 存储</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">选择上下文。在我们的测试中，我们对位于ONTAP S3 中的 TPCDS 生成的 parquet 文件进行了测试。  Dremio 仪表板 -&gt; SQL 运行器 -&gt; 上下文 -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">将上下文设置为 ontaps3 parquet 文件夹</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">从 Dremio 仪表板运行 TPC-DS query67</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">运行查询 67，它是 TPC-DS 中的 99 个查询之一</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">检查作业是否在所有执行器上运行。  Dremio 仪表板 -&gt; 作业 -&gt; &lt;jobid&gt; -&gt; 原始配置文件 -&gt; 选择 EXTERNAL_SORT -&gt; 主机名</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">Q67 查询中的节点列表</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">当 SQL 查询运行时，您可以检查NetApp存储控制器中用于数据缓存的拆分文件夹。</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">查询 67 完成时溢出详细信息</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">SQL 查询已完成并溢出<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">已完成查询的作业摘要 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">工作完成情况总结。<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">查询结果中的 splleddata 详细信息</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">检查溢出数据的大小<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">相同的程序适用于 NAS 和StorageGRID对象存储。</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">本节概述了NetApp为满足各种 Hadoop 数据保护要求而提供的用例和解决方案。</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">本节概述了NetApp为满足各种 Hadoop 数据保护要求而提供的用例和解决方案。通过使用由NetApp提供支持的数据结构，客户可以：</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">利用 NetApp 丰富的数据管理功能以及与 Hadoop 原生工作流的集成，可以灵活地选择正确的数据保护解决方案。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">将其 Hadoop 集群备份窗口时间减少近 70%。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">消除 Hadoop 集群备份造成的任何性能影响。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">同时为单一分析数据源提供来自不同云提供商的多云数据保护和数据访问。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">使用FlexClone技术创建快速且节省空间的 Hadoop 集群副本。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">要了解有关本文档中描述的信息的更多信息，请参阅以下文档和/或网站：</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp大数据分析解决方案</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">使用NetApp存储的 Apache Spark 工作负载</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">适用于 Apache Spark 的NetApp存储解决方案</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp支持的数据结构上的 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">致谢</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland， NetApp澳新银行维多利亚区销售部销售代表</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">NetApp业务发展经理 Hoseb Dermanilian</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">NetApp MPSG 总监 Lee Dorrier</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">NetApp澳新银行维多利亚区 SE 系统工程师 David Thiessen</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">版本历史</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">日期</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">文档版本历史</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">1.0 版</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018年1月</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初始版本</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">2.0 版</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">更新用例 #5：加速分析工作负载</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">3.0 版</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">2023年11月</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">删除了 NIPAM 详细信息</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetApp提供支持的数据结构简化并集成了跨云和本地环境的数据管理，从而加速数字化转型。  NetApp提供支持的数据结构可提供一致且集成的数据管理服务和应用程序（构建块），以实现数据可见性和洞察、数据访问和控制以及数据保护和安全。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">由NetApp提供支持的适用于大数据架构的数据结构</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetApp提供支持的数据结构简化并集成了跨云和本地环境的数据管理，从而加速数字化转型。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp提供支持的数据结构为数据可见性和洞察、数据访问和控制以及数据保护和安全提供了一致且集成的数据管理服务和应用程序（构建块），如下图所示。</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">经过验证的数据结构客户用例</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetApp支持的数据结构为客户提供了以下九种经过验证的用例：</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">加速分析工作负载</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">加速 DevOps 转型</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">构建云托管基础设施</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">集成云数据服务</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">保护和保障数据安全</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">优化非结构化数据</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">提高数据中心效率</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">提供数据洞察和控制</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">简化和自动化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">本文档涵盖九个用例中的两个（及其解决方案）：</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 直接访问</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS 允许客户在其现有或新的 NFSv3 或 NFSv4 数据上运行大数据分析作业，而无需移动或复制数据。它可以防止数据的多次复制，并且无需将数据与源同步。例如，在金融领域，数据从一个地方移动到另一个地方必须满足法律义务，这不是一件容易的事。在这种情况下， NetApp NFS 直接访问会从原始位置分析财务数据。另一个主要优势是，使用NetApp NFS 直接访问可以通过使用本机 Hadoop 命令简化 Hadoop 数据的保护，并利用 NetApp 丰富的数据管理产品组合实现数据保护工作流程。</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 直接访问为 Hadoop/Spark 集群提供了两种部署选项：</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">默认情况下，Hadoop/Spark集群使用Hadoop分布式文件系统（HDFS）作为数据存储和默认文件系统。  NetApp NFS 直接访问可以用 NFS 存储替换默认的 HDFS 作为默认文件系统，从而实现对 NFS 数据的直接分析操作。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">在另一个部署选项中， NetApp NFS 直接访问支持在单个 Hadoop/Spark 集群中将 NFS 与 HDFS 一起配置为附加存储。在这种情况下，客户可以通过 NFS 导出共享数据，并从同一个集群访问数据以及 HDFS 数据。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">使用NetApp NFS 直接访问的主要优势包括：</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">从当前位置分析数据，从而避免将分析数据移动到 Hadoop 基础架构（如 HDFS）这一耗时耗能的任务。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">将副本数量从三个减少到一个。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">使用户能够分离计算和存储以独立扩展它们。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">利用ONTAP丰富的数据管理功能提供企业数据保护。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">已通过 Hortonworks 数据平台认证。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">支持混合数据分析部署。</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">利用动态多线程功能减少备份时间。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">大数据的构建模块</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetApp提供支持的数据结构集成了数据管理服务和应用程序（构建块），用于数据访问、控制、保护和安全，如下图所示。</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上图中的构建块包括：</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 直接访问。*为最新的 Hadoop 和 Spark 集群提供对NetApp NFS 卷的直接访问，无需额外的软件或驱动程序要求。</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP和Google Cloud NetApp Volumes 。*基于在 Amazon Web Services (AWS) 或 Microsoft Azure 云服务中的Azure NetApp Files (ANF) 中运行的ONTAP的软件定义连接存储。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror技术*。在本地和ONTAP Cloud 或 NPS 实例之间提供数据保护功能。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*云服务提供商。*这些提供商包括 AWS、Microsoft Azure、Google Cloud 和 IBM Cloud。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*平台即服务 (PaaS)。*基于云的分析服务，例如 AWS 中的 Amazon Elastic MapReduce (EMR) 和 Databricks 以及 Microsoft Azure HDInsight 和 Azure Databricks。</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp 是一个用于大型集群间和集群内复制的本机工具。  Hadoop DistCp 基本流程是一个典型的备份工作流，使用 Hadoop 原生工具（如 MapReduce）将 Hadoop 数据从 HDFS 源复制到相应的目标。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 数据保护和NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp 是一个用于大型集群间和集群内复制的本机工具。下图所示的 Hadoop DistCp 基本流程是一个典型的备份工作流，使用 MapReduce 等 Hadoop 原生工具将 Hadoop 数据从 HDFS 源复制到相应的目标。</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">NetApp NFS 直接访问使客户能够将 NFS 设置为 Hadoop DistCp 工具的目标位置，以便通过 MapReduce 将数据从 HDFS 源复制到 NFS 共享中。  NetApp NFS 直接访问充当 DistCp 工具的 NFS 驱动程序。</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">本文档介绍了使用NetApp AFF和FAS存储系统、 NetApp Cloud Volumes ONTAP、 NetApp互联存储以及适用于 Spark 和 Hadoop 的NetApp FlexClone技术的混合云数据解决方案。这些解决方案架构允许客户为其环境选择合适的数据保护解决方案。  NetApp根据与客户及其业务用例的互动设计了这些解决方案。</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam 和 Sathish Thyagarajan， NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">本文档介绍了使用NetApp AFF和FAS存储系统、 NetApp Cloud Volumes ONTAP、 NetApp互联存储以及适用于 Spark 和 Hadoop 的NetApp FlexClone技术的混合云数据解决方案。这些解决方案架构允许客户为其环境选择合适的数据保护解决方案。 NetApp根据与客户及其业务用例的互动设计了这些解决方案。本文档提供以下详细信息：</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">为什么我们需要为 Spark 和 Hadoop 环境提供数据保护以及客户面临的挑战。</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">由NetApp愿景及其构建块和服务提供支持的数据结构。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">如何使用这些构建块来构建灵活的数据保护工作流程。</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">根据实际客户使用案例分析几种架构的优缺点。每个用例提供以下组件：</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">客户场景</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">要求和挑战</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">解决方案</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">解决方案总结</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">为什么要进行 Hadoop 数据保护？</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">在 Hadoop 和 Spark 环境中，必须解决以下问题：</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*软件或人为故障。*在执行 Hadoop 数据操作时，软件更新中的人为错误可能会导致错误行为，从而导致工作出现意外结果。在这种情况下，我们需要保护数据以避免失败或不合理的结果。例如，由于交通信号分析应用程序的软件更新执行不力，导致新功能无法正确分析纯文本形式的交通信号数据。该软件仍然分析JSON和其他非文本文件格式，导致实时交通管制分析系统产生缺少数据点的预测结果。这种情况可能会导致错误输出，从而引发交通信号事故。数据保护可以通过提供快速回滚到以前工作应用程序版本的功能来解决此问题。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*尺寸和规模。*由于数据源数量和数据量的不断增加，分析数据的大小也日益增长。社交媒体、移动应用、数据分析和云计算平台是当前大数据市场的主要数据来源，这些数据增长非常迅速，因此需要对数据进行保护，以确保数据操作的准确性。</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Hadoop 的原生数据保护。* Hadoop 有一个原生命令来保护数据，但是该命令在备份期间不提供数据的一致性。它仅支持目录级备份。  Hadoop 创建的快照是只读的，不能直接用于重复使用备份数据。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 和 Spark 客户面临的数据保护挑战</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 和 Spark 客户面临的一个共同挑战是减少备份时间并提高备份可靠性，同时又不会在数据保护期间对生产集群的性能产生负面影响。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">客户还需要最大限度地减少恢复点目标 (RPO) 和恢复时间目标 (RTO) 停机时间，并控制其内部部署和基于云的灾难恢复站点，以实现最佳业务连续性。这种控制通常来自于企业级管理工具。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop 和 Spark 环境非常复杂，因为不仅数据量巨大且不断增长，而且数据到达的速度也在加快。这种情况使得从源数据快速创建高效、最新的 DevTest 和 QA 环境变得困难。  NetApp认识到这些挑战并提供了本文中介绍的解决方案。</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">在此场景中，一家大型金融服务和投资银行的分析平台使用NetApp NFS 存储解决方案进行了现代化改造，从而显著提高了其资产管理和量化业务部门的投资风险和衍生品分析能力。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">用例 5：加速分析工作负载</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">场景</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">在客户现有的环境中，用于分析平台的 Hadoop 基础架构利用了 Hadoop 服务器的内部存储。由于 JBOD 环境的专有性，组织内的许多内部客户无法利用他们的蒙特卡罗定量模型，该模型是一种依赖于实时数据重复样本的模拟。对市场走势不确定性的影响的理解能力不足，对量化资产管理业务部门不利。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">该银行的定量业务部门需要一种有效的预测方法来实现准确、及时的预测。为此，团队认识到需要实现基础设施现代化，减少现有的 I/O 等待时间，并提高 Hadoop 和 Spark 等分析应用程序的性能，以有效模拟投资模型、衡量潜在收益和分析风险。</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解决方案</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">客户现有的 Spark 解决方案已配备 JBOD。然后利用NetApp ONTAP、 NetApp StorageGRID和 MinIO Gateway to NFS 来减少银行量化金融小组的 I/O 等待时间，该小组对评估潜在收益和风险的投资模型进行模拟和分析。此图显示了采用NetApp存储的 Spark 解决方案。</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">如上图所示，部署了AFF A800、A700 系统和StorageGRID ，以便在六节点 Hadoop 集群中通过 NFS 和 S3 协议访问 parquet 文件，并使用 Spark、YARN 和 Hive 元数据服务进行数据分析操作。</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">客户旧环境中的直接连接存储 (DAS) 解决方案的缺点是无法独立扩展计算和存储。借助NetApp ONTAP Spark 解决方案，该银行的财务分析业务部门能够将存储与计算分离，并根据需要更有效地无缝地提供基础设施资源。</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">通过使用带有 NFS 的ONTAP ，计算服务器 CPU 几乎完全用于 Spark SQL 作业，并且 I/O 等待时间减少了近 70%，从而为 Spark 工作负载提供了更好的计算能力和性能提升。随后，提高 CPU 利用率还使客户能够利用 GPU（例如 GPUDirect）进一步实现平台现代化。此外， StorageGRID为 Spark 工作负载提供了低成本的存储选项，而 MinIO Gateway 通过 S3 协议提供对 NFS 数据的安全访问。对于云中的数据， NetApp推荐使用Cloud Volumes ONTAP、 Azure NetApp Files和Google Cloud NetApp Volumes。</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">此用例基于需要将基于云的分析数据备份到其内部数据中心的广播客户。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">用例 2：从云到本地的备份和灾难恢复</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">此用例基于一个广播客户，该客户需要将基于云的分析数据备份到其内部数据中心，如下图所示。</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">在这种情况下，物联网传感器数据被引入云中，并使用 AWS 内的开源 Apache Spark 集群进行分析。要求是将处理后的数据从云端备份到本地。</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">此用例的主要要求和挑战包括：</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">启用数据保护不会对云中的生产 Spark/Hadoop 集群造成任何性能影响。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">需要以高效、安全的方式将云传感器数据移动并保护到本地。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">在不同条件下灵活地将数据从云端传输到本地，例如按需、即时以及低集群负载时间期间。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">客户使用 AWS Elastic Block Store (EBS) 作为其 Spark 集群 HDFS 存储，以通过 Kafka 接收和提取来自远程传感器的数据。因此，HDFS 存储充当备份数据的来源。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">为了满足这些要求， NetApp ONTAP Cloud 部署在 AWS 中，并创建了一个 NFS 共享作为 Spark/Hadoop 集群的备份目标。</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">创建 NFS 共享后，将数据从 HDFS EBS 存储复制到ONTAP NFS 共享。当数据驻留在ONTAP Cloud 中的 NFS 中时，可以根据需要使用SnapMirror技术以安全高效的方式将数据从云端镜像到本地存储中。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">此图显示了从云到本地解决方案的备份和灾难恢复。</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">在这种情况下，客户拥有一个大型的内部部署 Hadoop 存储库，并希望将其备份以用于灾难恢复目的。然而，客户当前的备份解决方案成本高昂，并且备份窗口长达 24 小时以上。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">用例 1：备份 Hadoop 数据</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">软件向后兼容性：</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">所提出的替代备份解决方案应与生产 Hadoop 集群中当前运行的软件版本兼容。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">为了满足承诺的 SLA，建议的替代解决方案应该实现非常低的 RPO 和 RTO。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp备份解决方案创建的备份可用于在数据中心本地构建的 Hadoop 集群以及在远程站点的灾难恢复位置运行的 Hadoop 集群。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">所提出的解决方案必须具有成本效益。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">所提出的解决方案必须减少备份期间对当前正在运行的生产分析作业的性能影响。</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">客户现有的备份解决方案x</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">下图是原有的Hadoop原生备份方案。</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">生产数据通过中间备份集群保护到磁带上：</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">通过运行以下命令将 HDFS1 数据复制到 HDFS2<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block>命令。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">备份集群充当NFS网关，通过Linux手动将数据复制到磁带<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block>通过磁带库命令。</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">Hadoop原生备份方案的优势包括：</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">该解决方案基于 Hadoop 原生命令，使用户无需学习新的程序。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">该解决方案利用行业标准架构和硬件。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">原有Hadoop原生备份方案的缺点包括：</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">备份窗口时间过长超过24小时，导致生产数据容易受到攻击。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">备份期间集群性能明显下降。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">复制到磁带是一个手动过程。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">就所需硬件和手动流程所需的人力而言，备份解决方案的成本很高。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">备份解决方案</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">基于这些挑战和要求，并考虑到现有的备份系统，提出了三种可能的备份解决方案。以下小节分别描述这三种不同的备份解决方案，标记为解决方案 A 到解决方案 C。</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解决方案 A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">在解决方案 A 中，备份 Hadoop 集群将二级备份发送到NetApp NFS 存储系统，从而无需磁带，如下图所示。</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">解决方案A的详细任务包括：</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">生产 Hadoop 集群在需要保护的 HDFS 中拥有客户的分析数据。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">带有 HDFS 的备份 Hadoop 集群充当数据的中间位置。只需一组磁盘（JBOD）即可为生产和备份 Hadoop 集群中的 HDFS 提供存储。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">通过运行<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block>命令。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop快照用于保护从生产到备份Hadoop集群的数据。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP存储控制器提供 NFS 导出卷，该卷配置给备份 Hadoop 集群。</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">通过运行<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block>命令利用 MapReduce 和多个映射器，分析数据从备份 Hadoop 集群到 NFS 受到保护。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">将数据存储在NetApp存储系统上的 NFS 中后，根据需要使用NetApp Snapshot、 SnapRestore和FlexClone技术备份、恢复和复制 Hadoop 数据。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">通过使用SnapMirror技术，Hadoop 数据可以受到保护，保存到云端以及灾难恢复位置。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">解决方案A的优点包括：</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 生产数据受到备份集群的保护。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 数据通过 NFS 进行保护，从而实现对云和灾难恢复位置的保护。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">通过将备份操作卸载到备份集群来提高性能。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">消除手动磁带操作</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">允许通过NetApp工具实现企业管理功能。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">只需对现有环境进行最少的改变。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">是一种经济有效的解决方案。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">该解决方案的缺点是它需要备份集群和额外的映射器来提高性能。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">客户最近部署了解决方案 A，因为它简单、成本低且整体性能好。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">在此解决方案中，可以使用ONTAP的 SAN 磁盘代替 JBOD。此选项将备份集群存储负载转移至ONTAP；但缺点是需要 SAN 结构交换机。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解决方案 B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">解决方案B将NFS卷添加到生产Hadoop集群，从而无需备份Hadoop集群，如下图所示。</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">解决方案B的详细任务包括：</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP存储控制器将 NFS 导出配置到生产 Hadoop 集群。</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Hadoop 原生<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>命令将 Hadoop 数据从生产集群 HDFS 保护到 NFS。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">将数据存储在NetApp存储系统的NFS中后，根据需要使用Snapshot、 SnapRestore、 FlexClone技术对Hadoop数据进行备份、恢复、复制。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">解决方案B的优点包括：</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">生产集群针对备份解决方案进行了轻微修改，简化了实施并降低了额外的基础设施成本。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">备份操作不需要备份集群。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 生产数据在转换为 NFS 数据时受到保护。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">该解决方案允许通过NetApp工具实现企业管理功能。</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">该解决方案的缺点是它是在生产集群中实现的，这会在生产集群中增加额外的管理员任务。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解决方案 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">在解决方案 C 中， NetApp SAN 卷直接配置到 Hadoop 生产集群用于 HDFS 存储，如下图所示。</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">解决方案C的详细步骤包括：</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 存储在生产 Hadoop 集群中配置用于 HDFS 数据存储。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 和SnapMirror技术用于备份生产 Hadoop 集群的 HDFS 数据。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">由于备份位于存储层，因此 Snapshot 复制备份过程中不会对 Hadoop/Spark 集群的生产性能产生影响。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">快照技术可提供在几秒钟内完成的备份，无论数据大小如何。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">解决方案C的优点包括：</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">可以使用快照技术创建节省空间的备份。</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">在这种用例中，客户的要求是基于现有的 Hadoop 集群快速高效地构建新的 Hadoop/Spark 集群，该集群包含大量用于同一数据中心和远程位置的开发测试和报告目的的分析数据。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">用例 3：在现有 Hadoop 数据上启用 DevTest</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">在这种情况下，从本地以及灾难恢复位置的大型 Hadoop 数据湖实现构建多个 Spark/Hadoop 集群。</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">为 DevTest、QA 或任何其他需要访问相同生产数据的目的创建多个 Hadoop 集群。这里的挑战是以非常节省空间的方式瞬间多次克隆一个非常大的 Hadoop 集群。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">将 Hadoop 数据同步到 DevTest 和报告团队以提高运营效率。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">在生产和新集群中使用相同的凭据分发 Hadoop 数据。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">使用调度策略高效地创建QA集群，而不影响生产集群。</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone技术用于满足刚才描述的要求。 FlexClone技术是 Snapshot 副本的读/写副本。它从父 Snapshot 副本数据中读取数据，并且仅为新/修改的块消耗额外的空间。它速度快并且节省空间。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">首先，使用NetApp一致性组创建现有集群的 Snapshot 副本。</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">NetApp系统管理器或存储管理提示中的快照副本。一致性组Snapshot副本是应用程序一致性组Snapshot副本， FlexClone卷是基于一致性组Snapshot副本创建的。值得一提的是， FlexClone卷继承了父卷的 NFS 导出策略。创建 Snapshot 副本后，必须安装一个新的 Hadoop 集群以用于 DevTest 和报告目的，如下图所示。来自新 Hadoop 集群的克隆 NFS 卷访问 NFS 数据。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">此图显示了 DevTest 的 Hadoop 集群。</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">此用例与负责为客户的大数据分析数据提供多云连接的云服务合作伙伴相关。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">用例 4：数据保护和多云连接</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">在这种情况下，AWS 从不同来源接收的物联网数据存储在 NPS 的中心位置。  NPS 存储连接到位于 AWS 和 Azure 的 Spark/Hadoop 集群，使在多个云中运行的大数据分析应用程序能够访问相同的数据。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">客户希望使用多个云对相同数据运行分析作业。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">必须通过不同的传感器和集线器从不同来源（例如本地和云端）接收数据。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">该解决方案必须高效且具有成本效益。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主要挑战是构建一个经济高效的解决方案，在本地和不同云之间提供混合分析服务。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">此图说明了数据保护和多云连接解决方案。</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">如上图所示，来自传感器的数据通过 Kafka 流式传输并输入到 AWS Spark 集群中。数据存储在 NPS 中的 NFS 共享中，NPS 位于 Equinix 数据中心内的云提供商之外。由于NetApp NPS 分别通过 Direct Connect 和 Express Route 连接连接到 Amazon AWS 和 Microsoft Azure，因此客户可以从 Amazon 和 AWS 分析集群访问 NFS 数据。这种方法解决了跨多个超大规模器的云分析问题。</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">因此，由于内部部署和 NPS 存储都运行ONTAP软件， SnapMirror可以将 NPS 数据镜像到内部部署集群中，从而提供跨内部部署和多个云的混合云分析。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">为了获得最佳性能， NetApp通常建议使用多个网络接口和直接连接/快速路由来访问云实例的数据。</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">本节对数据保护用例进行了高层描述，这是本文的重点。其余部分为每个用例提供了更多详细信息，例如客户问题（场景）、要求和挑战以及解决方案。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 数据保护用例概述</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">对于此用例， NetApp NFS 卷帮助一家大型金融机构将长备份窗口时间从 24 多个小时缩短至几个小时。</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">通过使用NetApp提供支持的数据结构作为构建模块，一家大型广播公司能够根据不同的数据传输模式（例如按需、即时或基于 Hadoop/Spark 集群负载）满足将云数据备份到其内部数据中心的需求。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp解决方案帮助一家在线音乐分销商在不同分支机构快速构建多个节省空间的 Hadoop 集群，以创建报告并通过使用计划策略运行日常 DevTest 任务。</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">一家大型服务提供商使用由NetApp提供支持的数据结构从不同的云实例为其客户提供多云分析。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">一家最大的金融服务和投资银行使用NetApp网络附加存储解决方案来减少 I/O 等待时间并加速其定量金融分析平台。</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">本节介绍了从此次认证中获得的经验教训。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">最佳实践指南</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">根据我们的验证，S3 对象存储最适合 Confluent 保存数据。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">我们可以使用高吞吐量 SAN（特别是 FC）来保存代理热数据或本地磁盘，因为在 Confluent 分层存储配置中，代理数据目录中保存的数据大小取决于数据移动到对象存储时的段大小和保留时间。</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">当segment.bytes较高时，对象存储提供更好的性能；我们测试了512MB。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">在 Kafka 中，主题中生成的每个记录的键或值的长度（以字节为单位）由<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>范围。对于StorageGRID，S3 对象提取和检索性能提升到更高的值。例如，512 字节提供 5.8GBps 的检索，1024 字节提供 7.5GBps 的 s3 检索，而 2048 字节提供接近 10GBps 的检索。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">下图展示了基于<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>。</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">Kafka 调优。为了提高分层存储的性能，可以增加 TierFetcherNumThreads 和 TierArchiverNumThreads。作为一般准则，您需要增加 TierFetcherNumThreads 以匹配物理 CPU 核心的数量，并将 TierArchiverNumThreads 增加到 CPU 核心数量的一半。例如，在服务器属性中，如果您有一台具有八个物理核心的机器，请设置 confluent.tier.fetcher.num.threads = 8 和 confluent.tier.archiver.num.threads = 4。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*主题删除的时间间隔。*当主题被删除时，对象存储中的日志段文件的删除不会立即开始。相反，在删除这些文件之前有一个默认值为 3 小时的时间间隔。您可以修改配置 confluent.tier.topic.delete.check.interval.ms 来更改此间隔的值。如果删除主题或集群，您还可以手动删除相应存储桶中的对象。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*分层存储内部主题的 ACL。*对于内部部署，建议的最佳实践是在用于分层存储的内部主题上启用 ACL 授权器。设置 ACL 规则以限制只有代理用户才能访问此数据。这可以保护内部主题并防止未经授权访问分层存储数据和元数据。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">替换用户<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block>与您部署中的实际代理主体一起。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">例如，命令<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block>设置内部主题的 ACL 以进行分层存储。目前，只有一个与分层存储相关的内部主题。该示例创建了一个 ACL，为内部主题上的所有操作提供主要的 Kafka 权限。</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">我们已经对带有 Kafka 的 Confluent Platform 进行了认证，用于NetApp StorageGRID中的分层存储。</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">汇合验证</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">我们使用NetApp StorageGRID中的 Confluent Platform 6.2 Tiered Storage 进行了验证。  NetApp和 Confluent 团队共同进行了此次验证，并运行了验证所需的测试用例。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent 平台设置</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">我们使用以下设置进行验证。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">为了验证，我们使用了三个 zookeeper、五个 broker、五个测试脚本执行服务器、命名工具服务器（配备 256GB RAM 和 16 个 CPU）。对于NetApp存储，我们使用了带有四个 SGF6024 的 SG1000 负载均衡器的StorageGRID 。存储和代理通过 100GbE 连接进行连接。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">下图显示了用于 Confluent 验证的配置的网络拓扑。</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">工具服务器充当向 Confluent 节点发送请求的应用程序客户端。</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent 分层存储配置</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">分层存储配置在Kafka中需要以下参数：</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">为了验证，我们使用了带有 HTTP 协议的StorageGRID ，但 HTTPS 也可以使用。访问密钥和密钥存储在<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>范围。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp对象存储 - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">我们在StorageGRID中配置了单站点配置以进行验证。</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">验证测试</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">我们完成了以下五个测试用例进行验证。这些测试在 Trogdor 框架上执行。前两个是功能测试，其余三个是性能测试。</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">对象存储正确性测试</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">此测试确定对象存储 API 上的所有基本操作（例如，获取/放置/删除）是否根据分层存储的需求正常运行。这是每个对象存储服务都应该在后续测试之前通过的基本测试。这是一个要么通过要么失败的断言测试。</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">分层功能正确性测试</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">该测试通过或失败的断言测试来确定端到端分层存储功能是否运行良好。该测试创建了一个测试主题，该主题默认配置为启用分层，并且热集大小大大减少。它为新创建的测试主题生成一个事件流，等待代理将段存档到对象存储，然后使用事件流并验证所消耗的流是否与生成的流匹配。向事件流生成的消息数量是可配置的，这使得用户可以根据测试的需要生成足够大的工作量。减少的热集大小可确保活动段之外的消费者提取仅从对象存储中提供；这有助于测试对象存储读取的正确性。我们已经在有和没有对象存储故障注入的情况下执行了此测试。我们通过停止StorageGRID中某个节点的服务管理器服务来模拟节点故障，并验证端到端功能是否与对象存储兼容。</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">层级获取基准</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">该测试验证了分层对象存储的读取性能，并检查了基准测试生成的段在高负载下的范围提取读取请求。在这个基准测试中，Confluent 开发了自定义客户端来满足层级获取请求。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">生产-消费工作负载基准测试</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">该测试通过段归档间接生成对象存储上的写入工作负载。当消费者群体获取段时，从对象存储中生成读取工作负载（读取的段）。该工作负载由测试脚本生成。该测试检查了并行线程对对象存储的读写性能。我们对分层功能正确性测试进行了测试，测试了有和没有对象存储故障注入的情况。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保留工作量基准</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">该测试检查了对象存储在繁重的主题保留工作负载下的删除性能。保留工作负载是使用测试脚本生成的，该脚本与测试主题并行生成许多消息。测试主题是使用基于大小和基于时间的激进保留设置进行配置，这会导致事件流不断从对象存储中清除。然后将这些片段存档。这导致代理在对象存储中执行大量删除操作，并收集对象存储删除操作的性能。</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">什么是 Apache Kafka？</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">什么是愚蠢的重命名？</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP 用于流媒体应用程序。</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp产品文档</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">什么是 NFS？</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">什么是 Kafka 分区重新分配？</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">什么是 OpenMessaging 基准？</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">如何迁移 Kafka 代理？</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">如何使用 Prometheus 监控 Kafka 代理？</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Apache Kafka 托管平台</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">支持 Apache Kafka</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Apache Kafka 咨询服务</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">NetApp针对愚蠢重命名问题的解决方案为以前与 NFS 不兼容的工作负载提供了一种简单、廉价且集中管理的存储形式。</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">这种新模式使客户能够创建更易于管理的 Kafka 集群，这些集群更易于迁移和镜像，以实现灾难恢复和数据保护。我们还看到 NFS 提供了其他好处，例如降低 CPU 利用率和加快恢复时间、显著提高存储效率以及通过NetApp ONTAP实现更好的性能。</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">本文档描述了以下主题：愚蠢的重命名问题和解决方案验证、降低 CPU 利用率以减少 I/O 等待时间、加快 Kafka 代理恢复时间以及云端和本地的性能。</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947：使用NetApp NFS 存储的 Apache Kafka 工作负载 - 功能验证和性能</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole、Karthikeyan Nagalingam 和 Joe Scott， NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka 是一个分布式发布-订阅消息系统，具有强大的队列，可以接受大量消息数据。使用 Kafka，应用程序可以非常快速地向主题写入和读取数据。由于其容错性和可扩展性，Kafka 通常被用在大数据领域，作为一种可靠的方式来快速提取和移动大量数据流。用例包括流处理、网站活动跟踪、指标收集和监控、日志聚合、实时分析等。</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">此处</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">尽管 NFS 上的正常 Kafka 操作运行良好，但在 NFS 上运行的 Kafka 集群调整大小或重新分区期间，愚蠢的重命名问题会导致应用程序崩溃。这是一个重大问题，因为必须调整 Kafka 集群的大小或重新分区以实现负载平衡或维护目的。您可以找到更多详细信息<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>。</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">本文档描述了以下主题：</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">愚蠢的重命名问题和解决方案验证</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">降低 CPU 利用率以减少 I/O 等待时间</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">更快的 Kafka 代理恢复时间</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">云端和本地的性能</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">为什么使用 NFS 存储来存储 Kafka 工作负载？</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">生产应用程序中的 Kafka 工作负载可以在应用程序之间传输大量数据。这些数据保存并存储在 Kafka 集群中的 Kafka 代理节点中。 Kafka 还以可用性和并行性而闻名，它通过将主题分成多个分区，然后在整个集群中复制这些分区来实现。这最终意味着流经 Kafka 集群的大量数据通常会成倍增加。随着代理数量的变化，NFS 可以非常快速和轻松地重新平衡数据。对于大型环境，当代理数量发生变化时，跨 DAS 重新平衡数据非常耗时，并且在大多数 Kafka 环境中，代理数量经常发生变化。</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">其他好处包括：</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*到期。*  NFS 是一种成熟的协议，这意味着它的实现、保护和使用的大多数方面都已被很好地理解。</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*打开。*  NFS 是一个开放协议，其持续发展在互联网规范中被记录为一个自由开放的网络协议。</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*具有成本效益。*  NFS 是一种低成本的网络文件共享解决方案，由于它使用现有的网络基础设施，因此易于设置。</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*集中管理。*  NFS 的集中管理减少了单个用户系统上添加软件和磁盘空间的需要。</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*分布式。*  NFS 可以用作分布式文件系统，减少对可移动介质存储设备的需求。</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">为什么选择NetApp来处理 Kafka 工作负载？</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">NetApp NFS 实施被认为是该协议的黄金标准，并被应用于无数企业 NAS 环境中。除了NetApp的信誉之外，它还提供以下优势：</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">可靠性和效率</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">可扩展性和性能</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">高可用性（ NetApp ONTAP集群中的 HA 合作伙伴）</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">数据保护</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">灾难恢复（NetApp SnapMirror）。*您的网站瘫痪了，或者您想从另一个网站开始并从上次中断的地方继续。</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">存储系统的可管理性（使用NetApp OnCommand进行管理）。</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*负载平衡。*该集群允许您从托管在不同节点上的数据 LIF 访问不同的卷。</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*无中断运行。*  LIF 或卷移动对于 NFS 客户端来说是透明的。</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">在本地，我们使用带有ONTAP 9.12.1RC1 的NetApp AFF A900存储控制器来验证 Kafka 集群的性能和扩展。我们使用了与之前的ONTAP和AFF分层存储最佳实践相同的测试平台。</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">本地AFF A900的性能概述和验证</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">在本地，我们使用带有ONTAP 9.12.1RC1 的NetApp AFF A900存储控制器来验证 Kafka 集群的性能和扩展性。我们使用了与之前的ONTAP和AFF分层存储最佳实践相同的测试平台。</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">我们使用 Confluent Kafka 6.2.0 来评估AFF A900。该集群有八个代理节点和三个 zookeeper 节点。为了进行性能测试，我们使用了五个 OMB 工作节点。</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">存储配置</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">我们使用NetApp FlexGroups 实例为日志目录提供单一命名空间，从而简化恢复和配置。我们使用 NFSv4.1 和 pNFS 来提供对日志段数据的直接路径访问。</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">客户端调优</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">每个客户端使用以下命令挂载FlexGroup实例。</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">此外，我们增加了<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block>从默认<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block>到<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>。这与ONTAP中的默认会话槽限制相匹配。</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Kafka 代理调优</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">为了最大限度地提高测试系统的吞吐量，我们显著增加了某些关键线程池的默认参数。对于大多数配置，我们建议遵循 Confluent Kafka 最佳实践。此调整用于最大化存储的未完成 I/O 的并发性。这些参数可以进行调整以匹配您的代理的计算资源和存储属性。</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">工作负载生成器测试方法</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">我们对吞吐量驱动程序和主题配置使用了与云测试相同的 OMB 配置。</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">使用 Ansible 在AFF集群上配置了FlexGroup实例。</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">ONTAP SVM 上已启用 pNFS。</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">工作负载由吞吐量驱动程序触发，使用与Cloud Volumes ONTAP相同的工作负载配置。请参阅“<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> “ 以下。工作负载使用的复制因子为 3，这意味着在 NFS 中维护了三个日志段副本。</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">最后，我们使用积压完成了测量，以衡量消费者赶上最新消息的能力。 OMB 通过在测量开始时暂停消费者来构建积压。这会产生三个不同的阶段：积压创建（仅生产者的流量）、积压消耗（消费者密集的阶段，其中消费者追赶主题中错过的事件）和稳定状态。请参阅“<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> ”了解更多信息。</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">稳态性能</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">我们使用 OpenMessaging Benchmark 评估了AFF A900 ，以提供与 AWS 中的Cloud Volumes ONTAP和 AWS 中的 DAS 类似的比较。所有性能值代表生产者和消费者级别的 Kafka 集群吞吐量。</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Confluent Kafka 和AFF A900的稳定状态性能为生产者和消费者实现了超过 3.4GBps 的平均吞吐量。 Kafka 集群中的消息超过 340 万条。通过以每秒字节数为单位可视化 BrokerTopicMetrics 的持续吞吐量，我们可以看到AFF A900支持的出色稳定状态性能和流量。</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">该图显示了代理网络吞吐量。</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">这与按主题传递的消息的视图非常一致。下图提供了按主题的细分情况。在测试的配置中，我们看到四个主题中每个主题有近 90 万条消息。</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">极致性能和探索存储极限</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">对于AFF，我们还使用积压功能对 OMB 进行了测试。当 Kafka 集群中积累了大量事件积压时，积压功能会暂停消费者订阅。在此阶段，仅发生生产者流量，从而生成提交到日志的事件。这最接近地模拟了批处理或离线分析工作流程；在这些工作流程中，消费者订阅已启动，并且必须读取已从代理缓存中逐出的历史数据。</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">为了了解此配置中存储对消费者吞吐量的限制，我们测量了仅生产者阶段，以了解 A900 可以吸收多少写入流量。请参阅下一节“<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> “来了解如何利用这些数据。</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">在本次测量的仅生产者部分，我们看到了高峰值吞吐量，突破了 A900 性能的极限（当其他代理资源未饱和地为生产者和消费者流量提供服务时）。</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">我们将此测量的消息大小增加到 16k，以限制每个消息的开销并最大限度地提高 NFS 挂载点的存储吞吐量。</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Confluent Kafka 集群实现了 4.03GBps 的峰值生产者吞吐量。</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">OMB 完成填充事件积压日志后，消费者流量重新启动。在积压工作消耗的测量过程中，我们观察到所有主题的峰值消费者吞吐量超过 20GBps。存储 OMB 日志数据的 NFS 卷的组合吞吐量接近 ~30GBps。</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">尺寸指南</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">尺码指南</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">亚马逊网络服务提供<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block>用于 Kafka 集群大小调整和扩展。</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">此大小提供了一个有用的公式来确定 Kafka 集群的存储吞吐量要求：</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">对于复制因子为 r 的 tcluster 集群产生的聚合吞吐量，代理存储收到的吞吐量如下：</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">这可以进一步简化：</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">使用此公式，您可以根据 Kafka 热层需求选择合适的ONTAP平台。</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">下表解释了具有不同复制因子的 A900 的预期生产者吞吐量：</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">复制因子</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">生产者吞吐量 (GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3（测量）</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">在NetApp NFS 上安装存储层的 Kafka 集群在 AWS 云中进行了性能基准测试。基准测试示例在以下章节中描述。</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">AWS FSx ONTAP中的性能概述和验证</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">在NetApp NFS 上安装存储层的 Kafka 集群在 AWS FSx ONTAP中进行了性能基准测试。基准测试示例在以下章节中描述。</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">AWS FSx ONTAP中的 Apache Kafka</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">网络文件系统 (NFS) 是一种广泛用于存储大量数据的网络文件系统。在大多数组织中，数据越来越多地由 Apache Kafka 等流应用程序生成。这些工作负载需要可扩展性、低延迟以及具有现代存储功能的强大数据提取架构。为了实现实时分析并提供可操作的见解，需要精心设计且高性能的基础设施。</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka 在设计上与 POSIX 兼容的文件系统协同工作，并依赖该文件系统来处理文件操作，但是在 NFSv3 文件系统上存储数据时，Kafka 代理 NFS 客户端可以以不同于 XFS 或 Ext4 等本地文件系统的方式解释文件操作。一个常见的例子是 NFS Silly 重命名，它导致 Kafka 代理在扩展集群和重新分配分区时失败。为了应对这一挑战， NetApp更新了开源 Linux NFS 客户端，这些更改现在已在 RHEL8.7、RHEL9.1 中普遍可用，并且从当前 FSx ONTAP版本ONTAP 9.12.1 开始受支持。</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP在云中提供完全托管、可扩展且高性能的 NFS 文件系统。  FSx ONTAP上的 Kafka 数据可以扩展以处理大量数据并确保容错能力。  NFS 为关键和敏感数据集提供集中存储管理和数据保护。</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">这些增强功能使 AWS 客户能够在 AWS 计算服务上运行 Kafka 工作负载时利用 FSx ONTAP 。这些好处是：* 降低 CPU 利用率以减少 I/O 等待时间* 更快的 Kafka 代理恢复时间。  * 可靠性和效率。  * 可扩展性和性能。  * 多可用区域可用性。  * 数据保护。</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">AWS FSx ONTAP中的 Kafka</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">使用 AWS FSx ONTAP 的Kafka 集群在 AWS 云中进行了性能基准测试。以下章节描述了此基准测试。</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">建筑设置</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">下表显示了使用 AWS FSx ONTAP 的Kafka 集群的环境配置。</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">平台组件</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">环境配置</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">卡夫卡 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 名动物园管理员 – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3 个代理服务器 – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x 生产者/消费者 -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">所有节点上的操作系统</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">多可用区，吞吐量 4GB/秒，IOPS 160000</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">NetApp FSx ONTAP设置</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">在我们的初步测试中，我们创建了一个容量为 2TB、IOP 为 40000 的 FSx ONTAP文件系统，吞吐量为 2GB/秒。</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">在我们的示例中，我们通过 AWS CLI 部署 FSx ONTAP 。您将需要根据需要在您的环境中进一步自定义命令。  FSx ONTAP还可以通过 AWS 控制台进行部署和管理，从而通过更少的命令行输入获得更轻松、更简化的部署体验。</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">文档在 FSx ONTAP中，我们测试区域（US-East-1）中 2GB/秒吞吐量文件系统可实现的最大 IOPS 为 80,000 iops。  FSx ONTAP文件系统的最大总 iops 为 160,000 iops，需要 4GB/秒的吞吐量部署才能实现，我们将在本文档的后面进行演示。</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">有关 FSx ONTAP性能规格的更多信息，请随时访问此处的 AWS FSx ONTAP文档：<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> 。</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">FSx“create-file-system”的详细命令行语法可以在这里找到：<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">例如，您可以指定特定的 KMS 密钥，而不是在未指定 KMS 密钥时使用的默认 AWS FSx 主密钥。</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">在创建 FSx ONTAP文件系统时，请按照如下方式描述您的文件系统，等待 JSON 返回中的“LifeCycle”状态变为“AVAILABLE”：</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">通过使用 fsxadmin 用户登录 FSx ONTAP SSH 来验证凭据：Fsxadmin 是 FSx ONTAP文件系统创建时的默认管理员帐户。  fsxadmin 的密码是首次在 AWS 控制台或使用 AWS CLI 创建文件系统时配置的密码，如我们在步骤 1 中完成的那样。</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">验证您的凭据后，在 FSx ONTAP文件系统上创建存储虚拟机</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">存储虚拟机 (SVM) 是一个独立的文件服务器，具有自己的管理凭据和端点，用于管理和访问 FSx ONTAP卷中的数据，并提供 FSx ONTAP多租户。</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">配置好主存储虚拟机后，通过 SSH 进入新创建的 FSx ONTAP文件系统，并使用以下示例命令在存储虚拟机中创建卷，同样，我们为此验证创建 6 个卷。根据我们的验证，保留默认成分（8）或更少的成分将为 kafka 提供更好的性能。</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">我们的测试需要额外的容量。将卷的大小扩展至 2TB 并安装在连接路径上。</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">在 FSx ONTAP中，卷可以进行精简配置。在我们的示例中，扩展卷的总容量超过了文件系统的总容量，因此我们需要扩展文件系统的总容量以解锁额外的预配置卷容量，我们将在下一步中演示这一点。</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">接下来，为了提高性能和容量，我们将 FSx ONTAP吞吐容量从 2GB/秒扩展到 4GB/秒，IOPS 扩展到 160000，容量扩展到 5 TB</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">FSx“update-file-system”的详细命令行语法可以在这里找到：<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">FSx ONTAP卷通过 nconnect 和 Kafka 代理中的默认选项进行挂载</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">下图展示了我们基于 FSx ONTAP 的Kafka 集群的最终架构：</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">此图显示了基于 FSx ONTAP的 Kafka 集群的架构。</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">计算。我们使用了三节点 Kafka 集群，并在专用服务器上运行三节点 zookeeper 集合。每个代理有六个 NFS 挂载点，分别指向 FSx ONTAP实例上的六个卷。</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">监控。我们使用两个节点来实现 Prometheus-Grafana 组合。为了生成工作负载，我们使用了一个单独的三节点集群，该集群可以为该 Kafka 集群生产和消费。</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">贮存。我们使用了安装了六个 2TB 卷的 FSx ONTAP 。然后将该卷导出到具有 NFS 挂载的 Kafka 代理。FSx ONTAP卷在 Kafka 代理中安装了 16 个 nconnect 会话和默认选项。</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage 基准测试配置。</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">我们使用了与NetApp Cloud Volumes ONTAP相同的配置，其详细信息请参见此处 - link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">测试方法</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">根据上面描述的规范，使用 terraform 和 ansible 配置了 Kafka 集群。  Terraform 用于使用 AWS 实例为 Kafka 集群构建基础设施，并且 ansible 在其上构建 Kafka 集群。</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">使用上面描述的工作负载配置和同步驱动程序触发了 OMB 工作负载。</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">使用具有相同工作负载配置的吞吐量驱动程序触发了另一个工作负载。</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">观察结果</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">使用两种不同类型的驱动程序来生成工作负载，以对在 NFS 上运行的 Kafka 实例的性能进行基准测试。驱动程序之间的区别在于日志刷新属性。</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">对于 Kafka 复制因子 1 和 FSx ONTAP：</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">同步驱动程序持续产生的总吞吐量：~ 3218 MBps，峰值性能约为 3652 MBps。</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">吞吐量驱动程序持续产生的总吞吐量：~ 3679 MBps，峰值性能为 ~ 3908 MBps。</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">对于复制因子为 3 且具有 FSx ONTAP 的Kafka：</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">同步驱动程序持续产生的总吞吐量：~ 1252 MBps，峰值性能约为 1382 MBps。</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">吞吐量驱动程序持续产生的总吞吐量：~ 1218 MBps，峰值性能约为 1328 MBps。</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">在 Kafka 复制因子 3 中，读写操作在 FSx ONTAP上发生了三次，在 Kafka 复制因子 1 中，读写操作在 FSx ONTAP上发生了一次，因此在两种验证中，我们都能够达到 4GB/秒的最大吞吐量。</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">由于日志会立即刷新到磁盘，因此同步驱动程序可以生成一致的吞吐量，而由于日志会批量提交到磁盘，因此吞吐量驱动程序会产生突发性的吞吐量。</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">这些吞吐量数字是针对给定的 AWS 配置生成的。对于更高的性能要求，可以扩大实例类型并进一步调整以获得更好的吞吐量数字。总吞吐量或总速率是生产者和消费者速率的组合。</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">此图显示了 Kafka 与 RF1 和 RF3 的性能</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">下图显示了 Kafka 复制因子 3 的 2GB/秒 FSx ONTAP和 4GB/秒性能。复制因子 3 在 FSx ONTAP存储上执行三次读写操作。吞吐量驱动程序的总速率为 881 MB/秒，在 2GB/秒 FSx ONTAP文件系统上以大约 2.64 GB/秒的速度读取和写入 Kafka 操作，吞吐量驱动程序的总速率为 1328 MB/秒，以大约 3.98 GB/秒的速度读取和写入 kafka 操作。  Kafka 性能是线性的，并且基于 FSx ONTAP吞吐量可扩展。</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">此图显示了 2GB/秒和 4GB/秒的扩展性能。</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">下图显示了 EC2 实例与 FSx ONTAP之间的性能（Kafka 复制因子：3）</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">此图显示了 EC2 与 FSx ONTAP在 RF3 中的性能比较。</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">AWS 中的性能概述和验证</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">AWS 云中的 Kafka 与NetApp Cloud Volumes ONTAP （高可用性对和单节点）</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">对带有NetApp Cloud Volumes ONTAP （HA 对）的 Kafka 集群在 AWS 云中进行了性能基准测试。以下章节描述了此基准测试。</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">下表展示了使用NAS的Kafka集群的环境配置。</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAP实例</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HA 对实例 – m5dn.12xLarge x 2node 单节点实例 - m5dn.12xLarge x 1 节点</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetApp集群卷ONTAP设置</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">对于Cloud Volumes ONTAP HA 对，我们创建了两个聚合，每个存储控制器上的每个聚合上有三个卷。对于单个Cloud Volumes ONTAP节点，我们在一个聚合中创建六个卷。</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">该图描绘了 aggr3 和 aggr22 的属性。</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">该图描绘了 aggr2 的属性。</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">为了实现更好的网络性能，我们为 HA 对和单个节点都启用了高速网络。</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">此图显示了如何实现高速网络。</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">我们注意到ONTAP NVRAM具有更多的 IOPS，因此我们将Cloud Volumes ONTAP根卷的 IOPS 更改为 2350。 Cloud Volumes ONTAP中的根卷磁盘大小为 47GB。以下ONTAP命令适用于 HA 对，相同步骤也适用于单个节点。</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">此图显示了如何修改卷属性。</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">下图是基于NAS的Kafka集群架构图。</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*计算。*我们使用了三节点 Kafka 集群，并在专用服务器上运行三节点 zookeeper 集合。每个代理通过专用 LIF 拥有两个指向Cloud Volumes ONTAP实例上的单个卷的 NFS 挂载点。</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*监控*我们使用两个节点来实现 Prometheus-Grafana 组合。为了生成工作负载，我们使用了一个单独的三节点集群，该集群可以为该 Kafka 集群生产和消费。</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*贮存。*我们使用了 HA 对 Cloud Volumes ONTAP实例，并在该实例上安装了一个 6TB GP3 AWS-EBS 卷。然后通过 NFS 挂载将该卷导出到 Kafka 代理。</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">该图描绘了基于 NAS 的 Kafka 集群的架构。</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessage 基准测试配置</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">为了获得更好的 NFS 性能，我们需要在 NFS 服务器和 NFS 客户端之间建立更多的网络连接，可以使用 nconnect 创建。通过运行以下命令，使用 nconnect 选项将 NFS 卷挂载到代理节点上：</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">检查Cloud Volumes ONTAP中的网络连接。以下ONTAP命令从单个Cloud Volumes ONTAP节点使用。相同的步骤适用于Cloud Volumes ONTAP HA 对。</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">我们使用以下 Kafka<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>在Cloud Volumes ONTAP HA 对的所有 Kafka 代理中。这<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>属性对于每个经纪人来说是不同的，其余属性对于经纪人来说是共同的。对于 broker1 来说，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">对于 broker2，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>属性值如下：</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">对于 broker3，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>属性值如下：</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">对于单个Cloud Volumes ONTAP节点，Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block>与Cloud Volumes ONTAP HA 对相同，但<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>财产。</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">对于 broker1 来说，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">对于 broker2，<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>值如下：</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">OMB 中的工作负载配置有以下属性：<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> 。</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">这<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block>根据每个用例可能会有所不同。在我们的性能测试中，我们使用了 3K。</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">我们使用了来自 OMB 的两个不同的驱动程序（Sync 或 Throughput）来在 Kafka 集群上生成工作负载。</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">用于同步驱动程序属性的 yaml 文件如下<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block>：</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">用于吞吐量驱动程序属性的 yaml 文件如下<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block>：</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">根据上面描述的规范，使用 Terraform 和 Ansible 配置了 Kafka 集群。  Terraform 用于使用 AWS 实例为 Kafka 集群构建基础设施，Ansible 在其上构建 Kafka 集群。</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">对于Cloud Volumes ONTAP HA 对：</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">同步驱动程序持续产生的总吞吐量：~1236 MBps。</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">吞吐量驱动程序产生的总吞吐量：峰值~1412 MBps。</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">对于单个Cloud Volumes ONTAP节点：</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">同步驱动程序持续产生的总吞吐量：~ 1962MBps。</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">吞吐量驱动程序产生的总吞吐量：峰值~1660MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">这里展示了四种不同的图表。  CVO-HA 对吞吐量驱动程序。  CVO-HA 对同步驱动器。  CVO-单节点吞吐量驱动器。  CVO-单节点同步驱动器。</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">在执行吞吐量或同步驱动程序基准测试时，请务必检查存储吞吐量。</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">该图显示了延迟、IOPS 和吞吐量的性能。</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">本节描述了愚蠢的重命名问题以及 NFS 服务器和 NFS 客户端为解决该问题所需的更改。</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NetApp针对 NFS 到 Kafka 工作负载重命名问题的解决方案</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka 的构建假设底层文件系统符合 POSIX 标准：例如 XFS 或 Ext4。当应用程序仍在使用文件时，Kafka 资源重新平衡会删除这些文件。符合 POSIX 标准的文件系统允许取消链接继续进行。但是，只有在对该文件的所有引用都消失后，它才会删除该文件。如果底层文件系统是网络连接的，那么 NFS 客户端会拦截取消链接调用并管理工作流程。由于正在取消链接的文件上有待打开的文件，因此 NFS 客户端会向 NFS 服务器发送重命名请求，并在最后一次关闭取消链接的文件时，对重命名的文件发出删除操作。此行为通常称为 NFS 愚蠢重命名，由 NFS 客户端精心策划。</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">由于这种行为，任何使用 NFSv3 服务器存储的 Kafka 代理都会遇到问题。但是，NFSv4.x 协议具有解决此问题的功能，它允许服务器负责打开的未链接的文件。支持此可选功能的 NFS 服务器在打开文件时将所有权能力传达给 NFS 客户端。当有待处理的打开操作时，NFS 客户端将停止取消链接管理，并允许服务器管理流程。尽管 NFSv4 规范提供了实施指南，但到目前为止，还没有任何已知的 NFS 服务器实施支持此可选功能。</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">为了解决这个愚蠢的重命名问题，需要对 NFS 服务器和 NFS 客户端进行以下更改：</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*对 NFS 客户端 (Linux) 的更改。*在打开文件时，NFS 服务器会响应一个标志，表明有能力处理打开文件的取消链接。  NFS 客户端的更改允许 NFS 服务器在存在标志的情况下处理取消链接。 NetApp已根据这些更改更新了开源 Linux NFS 客户端。更新后的 NFS 客户端现已在 RHEL8.7 和 RHEL9.1 中普遍可用。</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*对 NFS 服务器的更改。* NFS 服务器跟踪打开的情况。现在，服务器管理对现有打开文件的取消链接以匹配 POSIX 语义。当最后一个打开的文件关闭时，NFS 服务器将启动文件的实际删除，从而避免愚蠢的重命名过程。  ONTAP NFS 服务器在其最新版本ONTAP 9.12.1 中实现了此功能。</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">通过对 NFS 客户端和服务器进行上述更改，Kafka 可以安全地获得网络附加 NFS 存储的所有好处。</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">对于功能验证，我们表明，使用 NFSv3 挂载存储的 Kafka 集群无法执行分区重新分配等 Kafka 操作，而使用修复程序挂载在 NFSv4 上的另一个集群可以执行相同的操作而不会出现任何中断。</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">功能验证 - 愚蠢的重命名修复</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">验证设置</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">该设置在 AWS 上运行。下表显示了用于验证的不同平台组件和环境配置。</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent 平台版本 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 个动物园管理员 – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 个代理服务器 – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x 控制中心 – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x 生产者/消费者</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7或更高版本</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">单节点实例 – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">下图显示了该解决方案的架构配置。</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">此图显示了 AWS 拓扑，其中包含一个 VPC，该 VPC 包含三个私有子网，分别带有一个生产者群、Kafka 集群和 CVO 实例。</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">建筑流程</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*计算。*我们使用了四节点 Kafka 集群，并在专用服务器上运行三节点 zookeeper 集合。</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*监控*我们使用两个节点来实现 Prometheus-Grafana 组合。</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*工作量*为了生成工作负载，我们使用了一个单独的三节点集群，该集群可以从该 Kafka 集群中生产和消费。</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*贮存。*我们使用了单节点NetApp Cloud Volumes ONTAP实例，该实例连接了两个 500GB GP2 AWS-EBS 卷。然后，这些卷通过 LIF 作为单个 NFSv4.1 卷公开给 Kafka 集群。</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">所有服务器都选择了 Kafka 的默认属性。对动物园管理员群也做了同样的事情。</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">更新<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block>到kafka卷，如下：</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">创建了两个类似的 Kafka 集群，但有以下区别：</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*集群 1.*运行生产就绪ONTAP版本 9.12.1 的后端 NFS v4.1 服务器由NetApp CVO 实例托管。代理上安装了 RHEL 8.7/RHEL 9.1。</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*集群 2.*后端 NFS 服务器是手动创建的通用 Linux NFSv3 服务器。</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">在两个 Kafka 集群上都创建了一个演示主题。</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">集群 1：</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">此屏幕截图显示了在集群 1 上创建的演示主题。</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">集群 2：</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">此屏幕截图显示了在 Cluster 2 上创建的演示主题。</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">数据被加载到这两个集群新创建的主题中。这是使用默认 Kafka 包中的生产者性能测试工具包完成的：</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">使用 telnet 对每个集群的 broker-1 执行健康检查：</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">远程登录<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">远程登录<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">下图显示了两个集群上的代理的成功健康检查：</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">此屏幕截图显示了两个代理成功进行健康检查的读数。</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">为了触发导致使用 NFSv3 存储卷的 Kafka 集群崩溃的故障条件，我们在两个集群上启动了分区重新分配过程。分区重新分配是使用<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block>。具体过程如下：</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">为了重新分配 Kafka 集群中主题的分区，我们生成了建议的重新分配配置 JSON（对两个集群都执行了此操作）。</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">生成的重新分配 JSON 随后保存在<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block>。</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">实际的分区重新分配过程由以下命令触发：</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">重新分配完成后几分钟，对代理进行的另一次健康检查显示，使用 NFSv3 存储卷的集群遇到了一个愚蠢的重命名问题并崩溃了，而使用已修复的NetApp ONTAP NFSv4.1 存储卷的集群 1 继续运行而没有任何中断。</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">此屏幕截图显示了崩溃的代理的输出。</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 处于活动状态。</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 已死亡。</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">检查 Kafka 日志目录后，很明显，使用已修复的NetApp ONTAP NFSv4.1 存储卷的集群 1 具有干净的分区分配，而使用通用 NFSv3 存储的集群 2 由于愚蠢的重命名问题而没有，从而导致崩溃。下图显示了集群 2 的分区重新平衡，这导致了 NFSv3 存储上出现了一个愚蠢的重命名问题。</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">此屏幕截图显示了 Cluster 2 崩溃的日志输出。</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">下图显示了使用NetApp NFSv4.1 存储对集群 1 进行干净的分区重新平衡。</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">此屏幕截图显示了成功为 Cluster 1 分配干净分区的日志输出，而</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">既然有了针对 Kafka 的 NFS 存储中愚蠢重命名问题的解决方案，您就可以创建利用NetApp ONTAP存储来处理 Kafka 工作负载的强大部署。这不仅显著降低了运营开销，还为您的 Kafka 集群带来以下好处。</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">为什么选择NetApp NFS 来支持 Kafka 工作负载？</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">既然有了针对 Kafka 的 NFS 存储中愚蠢重命名问题的解决方案，您就可以创建利用NetApp ONTAP存储来处理 Kafka 工作负载的强大部署。这不仅显著降低了运营开销，还为您的 Kafka 集群带来以下好处：</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*降低 Kafka 代理的 CPU 利用率。*使用分解的NetApp ONTAP存储将磁盘 I/O 操作与代理分离，从而减少其 CPU 占用。</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*更快的经纪人恢复时间。*由于分解的NetApp ONTAP存储在 Kafka 代理节点之间共享，因此与传统的 Kafka 部署相比，新的计算实例可以在很短的时间内随时替换损坏的代理，而无需重建数据。</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*存储效率。*由于应用程序的存储层现在是通过NetApp ONTAP进行配置的，因此客户可以利用ONTAP带来的所有存储效率优势，例如线内数据压缩、重复数据删除和压缩。</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">这些好处在本节我们将详细讨论的测试案例中得到了测试和验证。</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">降低 Kafka 代理的 CPU 利用率</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">我们发现，当我们在两个技术规格相同但存储技术不同的独立 Kafka 集群上运行类似的工作负载时，整体 CPU 利用率低于其 DAS 对应集群。当 Kafka 集群使用ONTAP存储时，不仅整体 CPU 利用率较低，而且 CPU 利用率的增加比基于 DAS 的 Kafka 集群表现出更平缓的梯度。</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">下表显示了用于演示降低 CPU 利用率的环境配置。</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 基准测试工具：OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x 生产者/消费者 - c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 或更高版本</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">单节点实例 – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">基准测试工具</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">开放消息传递</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">本测试用例中使用的基准测试工具是<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block>框架。 OpenMessaging 与供应商无关且与语言无关；它为金融、电子商务、物联网和大数据提供行业指南；并有助于开发跨异构系统和平台的消息传递和流媒体应用程序。下图描述了 OpenMessaging 客户端与 Kafka 集群的交互。</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">该图描述了 OpenMessaging 客户端与 Kafka 集群的交互。</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*计算。*我们使用了三节点 Kafka 集群，并在专用服务器上运行三节点 zookeeper 集合。每个代理通过专用 LIF 拥有两个 NFSv4.1 挂载点，指向NetApp CVO 实例上的单个卷。</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*监控*我们使用两个节点来实现 Prometheus-Grafana 组合。为了生成工作负载，我们有一个单独的三节点集群，可以从该 Kafka 集群中生产和消费。</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*贮存。*我们使用了单节点NetApp Cloud Volumes ONTAP实例，该实例上安装了六个 250GB GP2 AWS-EBS 卷。然后，这些卷通过专用 LIF 作为六个 NFSv4.1 卷公开给 Kafka 集群。</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*配置。*该测试用例中的两个可配置元素是 Kafka 代理和 OpenMessaging 工作负载。</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*经纪人配置*为 Kafka 代理选择了以下规格。我们对所有测量使用了 3 的重复因子，如下所示。</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">该图描述了为 Kafka 代理选择的规格。</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">OpenMessaging 基准 (OMB) 工作负载配置。*提供了以下规格。我们指定了目标生产率，如下所示。</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">该图描述了为 OpenMessaging 基准工作负载配置选择的规格。</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">创建了两个类似的集群，每个集群都有自己的一组基准集群群。</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*集群 1.*基于NFS的Kafka集群。</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*集群 2.*基于DAS的Kafka集群。</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">使用 OpenMessaging 命令，每个集群上都会触发类似的工作负载。</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">生产率配置在四次迭代中增加，并使用 Grafana 记录 CPU 利用率。生产率设定为以下水平：</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">将NetApp NFS 存储与 Kafka 结合使用有两个主要好处：</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*您可以将 CPU 使用率降低近三分之一。*与 DAS SSD 相比，相似工作负载下 NFS 的总体 CPU 使用率较低；节省范围从较低生产率的 5% 到较高生产率的 32%。</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*在更高的生产率下，CPU 利用率漂移减少了三倍。*正如预期的那样，随着生产率的提高，CPU 利用率呈上升趋势。然而，使用 DAS 的 Kafka 代理的 CPU 利用率从较低生产率时的 31% 上升到较高生产率时的 70%，增幅为 39%。然而，有了 NFS 存储后端，CPU 利用率从 26% 上升到 38%，增加了 12%。</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">该图描述了基于 DAS 的集群的行为。</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">该图描述了基于 NFS 的集群的行为。</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">此外，在 100,000 条消息时，DAS 显示的 CPU 利用率比 NFS 集群更高。</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">该图描述了基于 DAS 的集群在 100,000 条消息时的行为。</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">该图描述了基于 NFS 的集群在 100,000 条消息时的行为。</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">更快的经纪人恢复</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">我们发现，当 Kafka 代理使用共享NetApp NFS 存储时，恢复速度更快。当 Kafka 集群中某个 Broker 崩溃时，可以用具有相同 Broker ID 的健康 Broker 替代该 Broker。在执行此测试用例时，我们发现，对于基于 DAS 的 Kafka 集群，集群会在新添加的健康 Broker 上重建数据，这非常耗时。对于基于NetApp NFS 的 Kafka 集群，替换代理将继续从以前的日志目录读取数据，并且恢复速度更快。</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x 生产者/消费者 - c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x 备份 Kafka 节点 – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 或更高版本</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*计算。*一个三节点 Kafka 集群，带有一个三节点 zookeeper 集合，在专用服务器上运行。每个代理通过专用 LIF 拥有两个指向NetApp CVO 实例上的单个卷的 NFS 挂载点。</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*监控* Prometheus-Grafana 组合的两个节点。为了生成工作负载，我们使用一个单独的三节点集群，该集群可以为该 Kafka 集群生产和消费。</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*贮存。*单节点NetApp Cloud Volumes ONTAP实例，实例上安装了六个 250GB GP2 AWS-EBS 卷。然后，这些卷通过专用 LIF 作为六个 NFS 卷公开给 Kafka 集群。</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*经纪人配置。*此测试用例中一个可配置元素是 Kafka 代理。为 Kafka 代理选择了以下规格。这<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block>设置为较高的值，因为这决定了特定节点从 ISR 列表中取出的速度。当您在坏节点和健康节点之间切换时，您不希望该代理 ID 被排除在 ISR 列表中。</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">此图显示了为 Kafka 代理选择的规格。</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">创建了两个类似的集群：</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">基于 EC2 的汇合集群。</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">基于NetApp NFS 的汇合集群。</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">创建了一个备用 Kafka 节点，其配置与原始 Kafka 集群中的节点相同。</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">在每个集群上，都创建了一个示例主题，并且在每个代理上填充了大约 110GB 的数据。</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*基于 EC2 的集群。*  Kafka 代理数据目录映射到<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block>（下图中 cluster1 的 Broker-1[左侧终端]）。</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">*基于NetApp NFS 的集群。*  Kafka 代理数据目录安装在 NFS 点上<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block>（下图中 cluster2 的 Broker-1【右侧终端】）。</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">此图显示了两个终端屏幕。</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">在每个集群中，Broker-1 被终止以触发失败的代理恢复过程。</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">代理终止后，代理 IP 地址被分配作为备用代理的辅助 IP。这是必要的，因为 Kafka 集群中的代理通过以下方式标识：</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*IP 地址。*通过将发生故障的代理 IP 重新分配给备用代理来进行分配。</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*经纪人ID*这是在备用代理中配置的<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>。</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">分配 IP 后，备用代理上启动了 Kafka 服务。</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">过了一会儿，拉取服务器日志来检查在集群中的替换节点上构建数据所花费的时间。</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Kafka 代理的恢复速度几乎提高了 9 倍。与在 Kafka 集群中使用 DAS SSD 相比，使用NetApp NFS 共享存储时恢复故障代理节点所需的时间明显更快。对于 1TB 的主题数据，基于 DAS 的集群的恢复时间为 48 分钟，而基于NetApp-NFS 的 Kafka 集群的恢复时间则不到 5 分钟。</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">我们观察到基于 EC2 的集群花费 10 分钟在新代理节点上重建 110GB 数据，而基于 NFS 的集群在 3 分钟内完成恢复。我们还在日志中观察到，EC2 分区的消费者偏移量为 0，而在 NFS 集群上，消费者偏移量是从前一个代理获取的。</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">基于DAS的集群</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">备份节点于 08:55:53,730 启动。</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">此图显示基于 DAS 的集群的日志输出。</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">数据重建过程于 09:05:24,860 结束。处理 110GB 的数据大约需要 10 分钟。</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">基于NFS的集群</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">备份节点于 09:39:17,213 启动。下面突出显示了起始日志条目。</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">此图显示基于 NFS 的集群的日志输出。</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">数据重建过程于 09:42:29,115 结束。处理 110GB 的数据大约需要 3 分钟。</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">对包含约 1TB 数据的代理重复了测试，对于 DAS 大约需要 48 分钟，对于 NFS 大约需要 3 分钟。结果如下图所示。</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">此图显示了代理恢复所需的时间，具体取决于基于 DAS 的集群或基于 NFS 的集群的代理上加载的数据量。</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">存储效率</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">由于 Kafka 集群的存储层是通过NetApp ONTAP配置的，因此我们获得了ONTAP的所有存储效率功能。这是通过在Cloud Volumes ONTAP上配置 NFS 存储的 Kafka 集群上生成大量数据进行的测试。我们可以看到，由于ONTAP功能，空间显著减少。</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">单节点实例 – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*计算。*我们使用了三节点 Kafka 集群，并在专用服务器上运行三节点 zookeeper 集合。每个代理通过专用 LIF 拥有两个指向NetApp CVO 实例上的单个卷的 NFS 挂载点。</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*贮存。*我们使用了单节点NetApp Cloud Volumes ONTAP实例，该实例上安装了六个 250GB GP2 AWS-EBS 卷。然后，这些卷通过专用 LIF 作为六个 NFS 卷公开给 Kafka 集群。</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*配置。*该测试用例中的可配置元素是 Kafka 代理。</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">生产者端的压缩被关闭，从而使生产者能够产生高吞吐量。存储效率由计算层处理。</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">已按照上述规格配置了 Kafka 集群。</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">在集群上，使用 OpenMessaging Benchmarking 工具产生了大约 350GB 的数据。</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">工作负载完成后，使用ONTAP系统管理器和 CLI 收集存储效率统计数据。</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">对于使用 OMB 工具生成的数据，我们发现空间节省了约 33%，存储效率比为 1.70:1。如下图所示，产生的数据所使用的逻辑空间为420.3GB，用于保存数据的物理空间为281.7GB。</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">此图展示了 VMDISK 中的空间节省情况。</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">截屏</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">本文档概述了使用分层存储基准测试套件对NetApp ONTAP上的 Confluent 平台进行的性能基准测试。</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941：与NetApp ONTAP存储控制器融合</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam、Joe Scott、 NetApp Rankesh Kumar、Confluence</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">为了使 Confluent 平台更具可扩展性和弹性，它必须能够非常快速地扩展和平衡工作负载。分层存储通过减少这种操作负担，使得在 Confluent 中存储大量数据变得易于管理。</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">其基本思想是将数据存储与数据处理分开，这使得独立扩展变得更加容易。</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">NetApp ONTAP数据管理软件搭载业界领先的创新技术，无论数据位于何处，都能为 Confluent 带来诸多优势。</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">我们使用NetApp StorageGRID设置对三到四个节点的生产和消费者工作负载进行了分层存储测试。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">具有可扩展性的性能测试</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">我们使用NetApp StorageGRID设置对三到四个节点的生产者和消费者工作负载进行了分层存储测试。根据我们的测试，完成时间和性能结果与StorageGRID节点的数量成正比。  StorageGRID设置至少需要三个节点。</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">当存储节点数量增加时，完成生产和消费操作的时间呈线性减少。</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 检索操作的性能根据StorageGRID节点的数量线性增加。  StorageGRID最多支持 200 个 StorgeGRID 节点。</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">该测试基于自平衡集群功能，该功能可根据集群拓扑变化或不均匀负载自动重新平衡。</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">融合自平衡集群</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">如果您以前管理过 Kafka 集群，那么您可能熟悉手动将分区重新分配给不同代理以确保整个集群的工作负载平衡所带来的挑战。对于部署大量 Kafka 的组织来说，重新整理大量数据可能是一项艰巨、繁琐且有风险的任务，尤其是在集群之上构建关键任务应用程序时。然而，即使对于最小的 Kafka 用例，该过程也很耗时并且容易出现人为错误。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">在我们的实验室中，我们测试了 Confluent 自平衡集群功能，该功能可以根据集群拓扑变化或不均匀负载自动重新平衡。 Confluent 重新平衡测试有助于测量当节点发生故障或扩展节点需要在代理之间重新平衡数据时添加新代理的时间。在经典的 Kafka 配置中，需要重新平衡的数据量会随着集群的增长而增长，但是在分层存储中，重新平衡仅限于少量数据。根据我们的验证，在经典的 Kafka 架构中，分层存储中的重新平衡需要几秒或几分钟，并且随着集群的增长而线性增长。</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">在自平衡集群中，分区重新平衡完全自动化，以优化 Kafka 的吞吐量，加速代理扩展，并减少运行大型集群的运营负担。在稳定状态下，自平衡集群监控代理之间的数据偏差，并不断重新分配分区以优化集群性能。当扩大或缩小平台规模时，自平衡集群会自动识别新代理的存在或旧代理的删除，并触发后续分区重新分配。这使您能够轻松地添加和停用代理，从而使您的 Kafka 集群从根本上更加有弹性。这些好处不需要任何人工干预、复杂的数学运算或分区重新分配通常带来的人为错误风险。因此，数据重新平衡可以在更短的时间内完成，您可以自由地专注于更高价值的事件流项目，而不需要不断监督您的集群。</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">在此设置中，我们向您展示如何使用 Kafka s3 接收器连接器直接从 Kafka 读取和写入对象存储中的主题。对于此测试，我们使用了独立的 Confluent 集群，但此设置适用于分布式集群。</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3连接器</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink 连接器将数据从 Apache Kafka 主题导出到 Avro、JSON 或 Bytes 格式的 S3 对象。 Amazon S3 接收器连接器定期从 Kafka 轮询数据，然后将其上传到 S3。分区器用于将每个 Kafka 分区的数据分成块。每个数据块都表示为一个 S3 对象。键名对主题、Kafka 分区和该数据块的起始偏移量进行编码。</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">从 Confluent 网站下载 Confluent Kafka。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">将软件包解压到服务器上的文件夹中。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">导出两个变量。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">对于独立的 Confluent Kafka 设置，集群会在<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>。它还创建 Zookeeper、Kafka、模式注册表、连接、ksql-server 和控制中心文件夹，并从复制它们各自的配置文件<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block>。请参见以下示例：</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">配置 Zookeeper。如果使用默认参数，则无需更改任何内容。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">在上面的配置中，我们更新了<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block>财产。默认情况下，您需要三个 Zookeeper 来选择 Kafka 领导者。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">我们在<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block>具有唯一 ID：</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">我们将最后一个 IP 地址数字用于 myid 文件。我们对 Kafka、connect、control-center、Kafka、Kafka-rest、ksql-server 和 schema-registry 配置使用了默认值。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">启动 Kafka 服务。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">每个配置都有一个日志文件夹，有助于解决问题。在某些情况下，服务需要更多时间才能启动。确保所有服务均已启动并正在运行。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">使用以下方式安装 Kafka connect<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> 。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">您还可以使用以下方式安装特定版本<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block>。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">默认情况下，<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>安装在<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">使用新的<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">停止 Confluent 服务并重新启动它们。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">在<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block>文件。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">验证存储桶是否可访问。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">为 s3 和 bucket 配置配置 s3-sink 属性文件。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">将一些记录导入到 s3 存储桶。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">加载 s3-sink 连接器。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">检查 s3-sink 状态。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">检查日志以确保 s3-sink 已准备好接受主题。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">检查 Kafka 中的主题。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">检查 s3 存储桶中的对象。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">要验证内容，请运行以下命令将每个文件从 S3 复制到本地文件系统：</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apache 档案</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">要打印记录，请使用 avro-tools-1.11.0.1.jar（可在<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>）。</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">本页介绍了提高此解决方案性能的最佳实践。</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">性能最佳实践指南</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">对于ONTAP，如果可能，请使用 &gt;=1MB 的 GET 大小。</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">增加<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>和<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>在<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>在代理节点上，您可以将增加的分层活动推送到 S3 层。这些结果与<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>和<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>设置为 32。</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3 存储桶应该针对每个成员聚合的八个组成部分。</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">驱动 S3 流量的以太网链路在存储和客户端上都应尽可能使用 9k 的 MTU。</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">此次验证测试在配备NetApp ONTAP存储控制器的 Confluent 上达到了 31.74GBps 的分层吞吐量。</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">此次验证测试在配备NetApp ONTAP存储控制器的 Confluent 上达到了 31.74GBps 的分层吞吐量。</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">什么是 Confluent？</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAP中的 S3 最佳实践</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3 对象存储管理</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">本页描述了 Confluent 在该解决方案参数范围内的性能验证。</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent 性能验证</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">我们已经使用 Confluent Platform 对NetApp ONTAP上的分层存储进行了验证。  NetApp和 Confluent 团队共同进行了此次验证，并运行了所需的测试用例。</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Confluent 设置</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">在设置中，我们使用了三个 Zookeeper、五个代理和五个测试服务器，配备 256GB RAM 和 16 个 CPU。对于NetApp存储，我们使用了带有AFF A900 HA 对的ONTAP 。存储和代理通过 100GbE 连接进行连接。</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">下图为分层存储验证配置的网络拓扑图。</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">该图显示了用于分层存储验证的配置的网络拓扑。</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">工具服务器充当应用程序客户端，向 Confluent 节点发送事件或从 Confluent 节点接收事件。</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">我们使用了以下测试参数：</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">为了验证，我们使用了带有 HTTP 协议的ONTAP ，但 HTTPS 也可以运行。访问密钥和密钥存储在<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>范围。</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp存储控制器 – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">我们在ONTAP中配置了单个 HA 对配置以进行验证。</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">该图描述了如何将环境配置为单个 HA 对以进行验证。</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">验证结果</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">我们完成了以下五个测试用例进行验证。前两个是功能测试，其余三个是性能测试。</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">此测试使用 API 调用对用于分层存储的对象存储执行获取、放置和删除等基本操作。</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">此测试检查对象存储的端到端功能。它创建一个主题，为新创建的主题生成一个事件流，等待代理将段存档到对象存储，使用事件流，并验证使用的流是否与生成的流匹配。我们已经在有和没有对象存储故障注入的情况下执行了此测试。我们通过停止ONTAP中某个节点的服务管理器服务来模拟节点故障，并验证端到端功能是否与对象存储兼容。</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">生产-消费工作负载生成器</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">该测试通过段的归档间接在对象存储上生成写入工作负载。当消费者群体获取段时，从对象存储中生成读取工作负载（读取的段）。此工作负载由 TOCC 脚本生成。该测试检查了并行线程对对象存储的读写性能。我们对分层功能正确性测试进行了测试，测试了有和没有对象存储故障注入的情况。</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">保留工作量生成器</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">该测试检查了对象存储在高主题保留工作负载下的删除性能。保留工作负载是使用 TOCC 脚本生成的，该脚本与测试主题并行生成许多消息。测试主题是使用基于大小和基于时间的激进保留设置进行配置，这会导致事件流不断从对象存储中清除。然后将这些片段存档。这导致代理在对象存储中进行多次删除，并收集对象存储删除操作的性能。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">汇合</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">有关验证详细信息，请参阅<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block>网站。</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">我们在生产-消费工作负载期间使用一个AFF A900 HA 对NetApp存储控制器对五个或八个代理节点执行了分层存储测试。根据我们的测试，完成时间和性能结果随着代理节点的数量而变化，直到AFF A900资源利用率达到百分之百。  ONTAP存储控制器设置至少需要一个 HA 对。</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">使用生产-消费工作负载生成器进行性能测试</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3 检索操作的性能随着 Confluent 代理节点的数量而线性增加。  ONTAP存储控制器在单个部署中最多支持 12 个 HA 对。</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">下图显示了具有五个或八个代理节点的组合 S3 分层流量。我们最大限度地提高了AFF A900单 HA 对的性能。</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">该数据图显示了具有五个或八个代理节点的组合 S3 分层流量。</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">下图显示 Kafka 吞吐量约为 31.74GBps。</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">该数据图显示 Kafka 吞吐量约为 31.74GBps。</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">我们还观察到ONTAP存储控制器的吞吐量类似<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block>报告。</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">本节介绍使用NetApp ONTAP进行分层存储的 Confluent Platform 部署中用于性能验证的硬件和软件。下表涵盖了解决方案架构和基本组件。</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent 和由ONTAP提供支持的NetApp AFF A900存储控制器是专为数据流设计的分布式系统。两者都具有水平可扩展性和容错性，并且在负载下提供出色的性能。它们在分布式数据流和流处理方面相互补充，通过数据缩减技术最大限度地减少数据占用空间，从而降低存储成本。 AFF A900存储控制器提供出色的性能，同时允许计算和数据存储资源分离。这简化了系统管理并允许独立扩展资源。</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">描述解决方案概览的图像。</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent 平台版本 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">3名动物园管理员</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8 个经纪服务器</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 个工具服务器</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 个 Grafana</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x 控制中心</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">NetApp ONTAP用于热存储桶</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 个AFF A900高可用性 (HA) 对</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2 个 CPU；总共 16 个物理核心</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">英特尔至强</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GB物理内存</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE 双端口</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">本页介绍了此解决方案中使用的技术。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">技术概述</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP存储控制器</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP是一款高性能企业级存储操作系统。</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 引入了对 Amazon Simple Storage Service (S3) API 的支持。  ONTAP支持 Amazon Web Services (AWS) S3 API 操作的子集，并允许将数据表示为跨云提供商（AWS、Azure 和 GCP）和本地的基于ONTAP的系统中的对象。</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID软件是NetApp 的旗舰对象存储解决方案。  ONTAP通过在边缘提供摄取和预处理点、扩展由NetApp支持的对象数据数据结构以及增加NetApp产品组合的价值来补充StorageGRID 。</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">通过授权用户和客户端应用程序可以访问 S3 存储桶。下图显示了应用程序访问 S3 存储桶的情况。</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">此图显示了访问 S3 存储桶的应用程序。</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">主要用例</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">支持 S3 API 的主要目的是提供ONTAP上的对象访问。  ONTAP统一存储架构现在支持文件（NFS 和 SMB）、块（FC 和 iSCSI）和对象（S3）。</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">原生 S3 应用程序</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">越来越多的应用程序能够利用ONTAP支持通过 S3 进行对象访问。尽管非常适合高容量存档工作负载，但对原生 S3 应用程序的高性能需求正在快速增长，包括：</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">分析</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">人工智能</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">从边缘到核心的采集</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">客户现在可以使用熟悉的管理工具（例如ONTAP系统管理器）来快速配置用于ONTAP中的开发和操作的高性能对象存储，同时充分利用ONTAP存储的效率和安全性。</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool端点</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">从ONTAP 9.8 开始， FabricPool支持对ONTAP中的存储桶进行分层，从而允许ONTAP到ONTAP分层。对于希望将现有FAS基础设施重新用作对象存储端点的客户来说，这是一个绝佳的选择。</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool通过两种方式支持分层到ONTAP ：</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">本地集群分层。使用集群 LIF 将非活动数据分层到位于本地集群上的存储桶中。</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">远程集群分层。非活动数据以类似于传统FabricPool云层的方式分层到位于远程集群上的存储桶中，使用FabricPool客户端上的 IC LIF 和ONTAP对象存储上的数据 LIF。</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">如果您希望在现有集群上使用 S3 功能而无需额外的硬件和管理，则ONTAP S3 是合适的。对于大于 300TB 的部署， NetApp StorageGRID软件仍然是NetApp对象存储的旗舰解决方案。使用ONTAP或StorageGRID作为云层时不需要FabricPool许可证。</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">NetApp ONTAP for Confluent 分层存储</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">每个数据中心都需要保持关键业务应用程序的运行以及重要数据的可用和安全。全新NetApp AFF A900系统采用ONTAP Enterprise Edition 软件和高弹性设计。我们全新的闪电般快速的 NVMe 存储系统可消除对关键任务操作的中断、最大限度地减少性能调整并保护您的数据免受勒索软件攻击。</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">从初始部署到扩展 Confluent 集群，您的环境需要快速适应对您的关键业务应用程序无干扰的变化。  ONTAP企业数据管理、服务质量 (QoS) 和性能使您能够规划和适应您的环境。</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">将NetApp ONTAP与 Confluent 分层存储结合使用，可以利用ONTAP作为横向扩展存储目标，从而简化 Apache Kafka 集群的管理，并支持 Confluent 计算和存储资源的独立扩展。</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3 服务器建立在ONTAP成熟的横向扩展存储功能之上。通过扩展 S3 存储桶以使用新添加到ONTAP集群的节点，可以无缝地扩展ONTAP集群。</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">使用ONTAP系统管理器进行简单管理</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP系统管理器是一个基于浏览器的图形界面，可让您在单一管理平台中配置、管理和监控全球分布位置的ONTAP存储控制器。</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">此图显示了ONTAP系统管理器工作区。</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">您可以使用系统管理器和ONTAP CLI 配置和管理ONTAP S3。当您使用系统管理器启用 S3 并创建存储桶时， ONTAP会提供最佳实践默认设置以简化配置。如果您从 CLI 配置 S3 服务器和存储桶，您仍然可以根据需要使用系统管理器管理它们，反之亦然。</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">当您使用系统管理器创建 S3 存储桶时， ONTAP会配置系统上可用的最高默认性能服务级别。例如，在AFF系统上，默认设置是 Extreme。性能服务级别是预定义的自适应 QoS 策略组。您可以指定自定义 QoS 策略组或不指定策略组，而不是指定默认服务级别之一。</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">预定义的自适应 QoS 策略组包括以下内容：</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*极端。*用于需要最低延迟和最高性能的应用程序。</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*表现。*适用于具有中等性能需求和延迟的应用程序。</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*价值。*用于吞吐量和容量比延迟更重要的应用程序。</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*风俗。*指定自定义 QoS 策略或不指定 QoS 策略。</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">如果选择“用于分层”，则不会选择任何性能服务级别，系统会尝试为分层数据选择具有最佳性能的低成本媒体。</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP尝试在具有最合适磁盘的本地层上配置此存储桶，以满足所选的服务级别。但是，如果您需要指定要包含在存储桶中的磁盘，请考虑通过指定本地层（聚合）从 CLI 配置 S3 对象存储。如果您从 CLI 配置 S3 服务器，您仍然可以根据需要使用系统管理器进行管理。</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">如果您希望能够指定用于存储桶的聚合，则只能使用 CLI 来实现。</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent 平台是一个全方位的数据流平台，使您能够轻松地以连续的实时流形式访问、存储和管理数据。 Confluent 由 Apache Kafka 的原始创建者构建，它通过企业级功能扩展了 Kafka 的优势，同时消除了 Kafka 管理或监控的负担。如今，财富 100 强企业中超过 80% 都采用数据流技术，其中大多数都使用 Confluent。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">为什么选择 Confluent？</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">通过将历史数据和实时数据集成到单一的中央事实来源，Confluent 可以轻松构建全新类别的现代事件驱动应用程序，获得通用数据管道，并解锁具有完全可扩展性、性能和可靠性的强大新用例。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Confluent 的用途是什么？</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent 平台让您专注于如何从数据中获取商业价值，而不必担心底层机制，例如如何在不同的系统之间传输或集成数据。具体来说，Confluent Platform 简化了数据源与 Kafka 的连接、流应用程序的构建以及 Kafka 基础设施的保护、监控和管理。如今，Confluent 平台已广泛应用于众多行业，从金融服务、全渠道零售、自动驾驶汽车到欺诈检测、微服务和物联网。</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">下图展示了 Confluent Platform 的组件。</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">该图显示了 Confluent 平台的组件。</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent 事件流技术概述</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">卡夫卡</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent 平台的核心是<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>，最受欢迎的开源分布式流媒体平台。  Kafka 的主要功能包括：</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">发布和订阅记录流。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">以容错的方式存储记录流。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">处理记录流。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">开箱即用的 Confluent Platform 还包括 Schema Registry、REST Proxy、总共 100 多个预构建的 Kafka 连接器和 ksqlDB。</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent 平台企业功能概述</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*汇合控制中心。*用于管理和监控 Kafka 的基于 UI 的系统。它允许您轻松管理 Kafka Connect 以及创建、编辑和管理与其他系统的连接。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*适用于 Kubernetes 的 Confluent。*  Confluent for Kubernetes 是一个 Kubernetes 操作员。 Kubernetes 操作员通过为特定平台应用程序提供独特的功能和要求来扩展 Kubernetes 的编排功能。对于 Confluent 平台，这包括大大简化 Kafka 在 Kubernetes 上的部署过程，并自动执行典型的基础设施生命周期任务。</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">Kafka Connect 连接器。连接器使用 Kafka Connect API 将 Kafka 连接到其他系统，例如数据库、键值存储、搜索索引和文件系统。 Confluent Hub 具有适用于最流行的数据源和接收器的可下载连接器，包括使用 Confluent Platform 对这些连接器进行全面测试和支持的版本。更多详情请见<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*自平衡集群。*提供自动负载平衡、故障检测和自我修复。它还支持根据需要添加或停用代理，无需手动调整。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*汇合簇连接。*直接将集群连接在一起，并通过链接桥将主题从一个集群镜像到另一个集群。集群链接简化了多数据中心、多集群和混合云部署的设置。</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*汇合自动数据平衡器。*监控集群中的代理数量、分区大小、分区数量以及集群内的领导者数量。它允许您转移数据以在整个集群中创建均匀的工作负载，同时限制重新平衡流量以最大限度地减少重新平衡时对生产工作负载的影响。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*汇合复制器。*使得在多个数据中心维护多个 Kafka 集群变得比以往更加简单。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*分层存储。*提供使用您最喜欢的云提供商存储大量 Kafka 数据的选项，从而减少运营负担和成本。通过分层存储，您可以将数据保存在经济高效的对象存储中，并且仅在需要更多计算资源时才扩展代理。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">Confluent JMS 客户端。 Confluent Platform 包含一个与 JMS 兼容的 Kafka 客户端。该 Kafka 客户端实现了 JMS 1.1 标准 API，使用 Kafka 代理作为后端。如果您有使用 JMS 的遗留应用程序并且想要用 Kafka 替换现有的 JMS 消息代理，这将非常有用。</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT 代理。*提供一种从 MQTT 设备和网关直接向 Kafka 发布数据的方法，无需中间的 MQTT 代理。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent 安全插件。* Confluent 安全插件用于为各种 Confluent 平台工具和产品添加安全功能。目前，有一个可用于 Confluent REST 代理的插件，可帮助验证传入的请求并将经过验证的主体传播到对 Kafka 的请求。这使得 Confluent REST 代理客户端能够利用 Kafka 代理的多租户安全功能。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetAppStorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID是一个高性能、经济高效的对象存储平台。通过使用分层存储，Confluent Kafka 上存储在本地存储或代理的 SAN 存储中的大部分数据都被卸载到远程对象存储。此配置可减少重新平衡、扩展或收缩集群或更换故障代理的时间和成本，从而显著改善操作。对象存储在管理驻留在对象存储层的数据方面发挥着重要作用，因此选择正确的对象存储非常重要。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID使用分布式、基于节点的网格架构提供智能、策略驱动的全局数据管理。它通过其无处不在的全局对象命名空间与复杂的数据管理功能相结合，简化了 PB 级非结构化数据和数十亿个对象的管理。单次调用对象访问可跨站点扩展，并简化高可用性架构，同时确保持续的对象访问，无论站点或基础设施是否中断。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">多租户允许在同一网格内安全地为多个非结构化云和企业数据应用程序提供服务，从而提高NetApp StorageGRID的投资回报率和用例。您可以使用元数据驱动的对象生命周期策略创建多个服务级别，从而优化跨多个地区的耐用性、保护性、性能和位置性。用户可以调整数据管理策略并监控和应用流量限制，以便在不断变化的 IT 环境中随着需求的变化而无中断地重新调整数据格局。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">使用网格管理器进行简单管理</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager 是一个基于浏览器的图形界面，允许您在单一玻璃窗格中配置、管理和监控全球分布位置的StorageGRID系统。</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">您可以使用StorageGRID Grid Manager 界面执行以下任务：</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">管理全球分布的 PB 级对象存储库，例如图像、视频和记录。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">监控网格节点和服务以确保对象可用性。</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">使用信息生命周期管理 (ILM) 规则来管理对象数据随时间推移的放置。这些规则控制着对象数据被摄取后会发生什么、如何防止数据丢失、对象数据存储在何处以及存储多长时间。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">监控系统内的交易、性能和操作。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">信息生命周期管理政策</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID具有灵活的数据管理策略，包括保留对象的副本以及使用 EC（擦除编码）方案（例如 2+1 和 4+2 等）来存储对象，具体取决于特定的性能和数据保护要求。由于工作负载和需求随时间而变化，ILM 策略通常也必须随时间而变化。修改 ILM 策略是一项核心功能，允许StorageGRID客户快速轻松地适应不断变化的环境。</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">性能</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712、SG5760、SG6060 或 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID通过添加更多存储节点来扩展性能，这些存储节点可以是虚拟机、裸机或专用设备，例如<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>。在我们的测试中，我们使用 SGF6024 设备以最小尺寸的三节点网格超越了 Apache Kafka 的关键性能要求。当客户使用额外的代理扩展他们的 Kafka 集群时，他们可以添加更多的存储节点来提高性能和容量。</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">负载均衡器和端点配置</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID中的管理节点提供网格管理器 UI（用户界面）和 REST API 端点来查看、配置和管理您的StorageGRID系统，以及审计日志来跟踪系统活动。为了为 Confluent Kafka 分层存储提供高可用性 S3 端点，我们实现了StorageGRID负载均衡器，它作为管理节点和网关节点上的服务运行。此外，负载均衡器还管理本地流量并与 GSLB（全局服务器负载均衡）对话以帮助进行灾难恢复。</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">为了进一步增强端点配置， StorageGRID提供了内置于管理节点的流量分类策略，让您监控工作负载流量，并对您的工作负载应用各种服务质量 (QoS) 限制。流量分类策略应用于网关节点和管理节点的StorageGRID负载均衡器服务上的端点。这些策略可以帮助流量整形和监控。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID中的流量分类</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID具有内置 QoS 功能。流量分类策略可以帮助监控来自客户端应用程序的不同类型的 S3 流量。然后，您可以创建并应用策略来根据输入/输出带宽、读/写并发请求数或读/写请求率限制此流量。</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka 是一个用 Java 和 Scala 编写的使用流处理的软件总线的框架实现。其目的是提供一个统一、高吞吐量、低延迟的平台来处理实时数据馈送。  Kafka可以通过Kafka Connect连接外部系统进行数据导出和导入，并提供Java流处理库Kafka Streams。 Kafka 使用基于 TCP 的二进制协议，该协议针对效率进行了优化，并依赖于“消息集”抽象，该抽象自然地将消息组合在一起，以减少网络往返的开销。这使得更大的顺序磁盘操作、更大的网络数据包和连续的内存块成为可能，从而使 Kafka 能够将突发的随机消息写入流转换为线性写入。下图描述了Apache Kafka的基本数据流。</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka 存储来自任意数量的进程（称为生产者）的键值消息。数据可以划分到不同主题内的不同分区中。在分区内，消息严格按照其偏移量（消息在分区内的位置）排序，并与时间戳一起索引和存储。其他称为消费者的进程可以从分区读取消息。对于流处理，Kafka 提供了 Streams API，允许编写 Java 应用程序使用来自 Kafka 的数据并将结果写回 Kafka。  Apache Kafka 还可以与外部流处理系统（如 Apache Apex、Apache Flink、Apache Spark、Apache Storm 和 Apache NiFi）协同工作。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka 在一个或多个服务器（称为代理）的集群上运行，所有主题的分区分布在集群节点上。此外，分区被复制到多个代理。这种架构允许 Kafka 以容错方式传递大量消息流，并允许它取代一些传统的消息传递系统，如 Java 消息服务 (JMS)、高级消息队列协议 (AMQP) 等。自 0.11.0.0 版本以来，Kafka 提供事务写入功能，可使用 Streams API 提供一次流处理。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka 支持两种类型的主题：常规主题和压缩主题。常规主题可以配置保留时间或空间界限。如果有记录超过指定的保留时间或超出了分区的空间限制，则允许 Kafka 删除旧数据以释放存储空间。默认情况下，主题的保留时间配置为 7 天，但也可以无限期地存储数据。对于压缩主题，记录不会根据时间或空间界限而过期。相反，Kafka 将后续消息视为具有相同密钥的旧消息的更新，并保证永远不会删除每个密钥的最新消息。用户可以通过写入具有特定键的空值的所谓墓碑消息来彻底删除消息。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka 中有五个主要 API：</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">生产者 API。允许应用程序发布记录流。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*消费者 API。*允许应用程序订阅主题并处理记录流。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">连接器 API。执行可重用的生产者和消费者 API，将主题链接到现有应用程序。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">流 API。该 API 将输入流转换为输出并产生结果。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*管理 API。*用于管理 Kafka 主题、代理和其他 Kafka 对象。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">消费者和生产者 API 建立在 Kafka 消息传递协议之上，并为 Java 中的 Kafka 消费者和生产者客户端提供参考实现。底层消息传递协议是一种二进制协议，开发人员可以使用任何编程语言编写自己的消费者或生产者客户端。这使得 Kafka 从 Java 虚拟机 (JVM) 生态系统中解放出来。  Apache Kafka wiki 中维护了可用的非 Java 客户端列表。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 用例</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka 最受欢迎的用途是消息传递、网站活动跟踪、指标、日志聚合、流处理、事件源和提交日志记录。</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka 提高了吞吐量、内置分区、复制和容错能力，使其成为大规模消息处理应用程序的良好解决方案。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka 可以将跟踪管道中的用户活动（页面浏览量、搜索量）重建为一组实时发布-订阅源。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka 经常用于运营监控数据。这涉及汇总来自分布式应用程序的统计数据以生成集中的操作数据。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">许多人使用 Kafka 来替代日志聚合解决方案。日志聚合通常从服务器上收集物理日志文件并将它们放在一个中心位置（例如，文件服务器或 HDFS）进行处理。 Kafka 抽象文件细节并将日志或事件数据以消息流的形式提供更清晰的抽象。这允许更低延迟的处理并且更容易支持多个数据源和分布式数据消费。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">许多 Kafka 用户在由多个阶段组成的处理管道中处理数据，其中从 Kafka 主题中使用原始输入数据，然后聚合、丰富或以其他方式转换为新主题以供进一步使用或后续处理。例如，用于推荐新闻文章的处理管道可能会从 RSS 提要中抓取文章内容并将其发布到“文章”主题。进一步的处理可能会规范化或重复化该内容，并将清理后的文章内容发布到新主题，最后的处理阶段可能会尝试将该内容推荐给用户。这样的处理管道根据各个主题创建实时数据流图。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">事件溯源是一种应用程序设计风格，其中状态变化被记录为按时间顺序排列的记录序列。  Kafka 对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的优秀后端。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka 可以作为分布式系统的一种外部提交日志。日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。  Kafka 中的日志压缩功能有助于支持这种用例。</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent 平台是一个企业级平台，它为 Kafka 提供了先进的功能，旨在帮助加速应用程序开发和连接、通过流处理实现转换、简化企业大规模运营并满足严格的架构要求。 Confluent 由 Apache Kafka 的原始创建者构建，它通过企业级功能扩展了 Kafka 的优势，同时消除了 Kafka 管理或监控的负担。如今，财富 100 强企业中有超过 80% 都采用数据流技术，其中大多数都使用 Confluent。</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent 平台让您专注于如何从数据中获取商业价值，而不必担心底层机制，例如如何在不同的系统之间传输或集成数据。具体来说，Confluent Platform 简化了数据源与 Kafka 的连接、流应用程序的构建以及 Kafka 基础设施的保护、监控和管理。如今，Confluent 平台已广泛应用于众多行业，从金融服务、全渠道零售、自动驾驶汽车到欺诈检测、微服务和物联网。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">下图显示了 Confluent Kafka 平台组件。</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Confluent 事件流技术概述</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent 平台的核心是<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>，最受欢迎的开源分布式流媒体平台。  Kafka 的主要功能如下：</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Confluent 平台企业功能概述</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*汇合控制中心。*用于管理和监控 Kafka 的基于 GUI 的系统。它允许您轻松管理 Kafka Connect 以及创建、编辑和管理与其他系统的连接。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*汇合连接器至 Kafka。*连接器使用 Kafka Connect API 将 Kafka 连接到其他系统，例如数据库、键值存储、搜索索引和文件系统。 Confluent Hub 具有适用于最流行的数据源和接收器的可下载连接器，包括使用 Confluent Platform 对这些连接器进行全面测试和支持的版本。更多详情请见<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*自平衡集群。*提供自动负载平衡、故障检测和自我修复。它支持根据需要添加或停用代理，无需手动调整。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*汇合自动数据平衡器。*监控集群中的代理数量、分区大小、分区数量以及集群内的领导者数量。它允许您转移数据以在整个集群中创建均匀的工作负载，同时限制重新平衡流量以最大限度地减少重新平衡时对生产工作负载的影响。</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY：采用NetApp存储解决方案的 Apache Spark 工作负载</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY 描述了 Apache Spark SQL 在NetApp NFS AFF存储系统上的性能和功能验证。它回顾了基于各种场景的配置、架构和性能测试，以及将 Spark 与NetApp ONTAP数据管理软件结合使用的建议。它还涵盖了基于一组磁盘（JBOD）与NetApp AFF A800存储控制器的测试结果。</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">现代数据分析——针对不同分析策略的不同解决方案</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">本白皮书介绍了NetApp现代数据分析解决方案策略。它包括有关业务成果、客户挑战、技术趋势、竞争遗留架构、现代工作流程、用例、行业、云、技术合作伙伴、数据移动器、 NetApp Active IQ Digital Advisor （也称为Digital Advisor）、 NetApp DataOps Toolkit、Hadoop to Spark、使用NetApp Trident Protect 的软件定义存储、容器、企业数据管理、归档和分层的详细信息，以实现 AI 和分析的目标，以及NetApp和客户如何共同实现其数据架构的现代化。</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">本 TR 中使用了以下参考文献：</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark 架构和组件</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Spark 用例</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">BERT</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">用于广告点击预测的深度和交叉网络</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">简化 ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">NetApp E系列Hadoop解决方案</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">NetApp现代数据分析解决方案</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">数据分析解决方案</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP复制和同步</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps 工具包</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">本页更详细地描述了主要的 AI、ML 和 DL 用例和架构。</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">主要的 AI、ML 和 DL 用例和架构</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">主要的 AI、ML 和 DL 用例和方法可分为以下几部分：</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLP 管道和 TensorFlow 分布式推理</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">以下列表包含数据科学界在不同发展水平下采用的最流行的开源 NLP 库：</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">自然语言工具包（NLTK）</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> 。所有 NLP 技术的完整工具包。它自 21 世纪初以来一直得到维护。</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">文本块</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> 。基于 NLTK 和 Pattern 构建的易于使用的 NLP 工具 Python API。</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">斯坦福核心 NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> 。斯坦福 NLP 小组开发的 Java NLP 服务和包。</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">Gensim</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> 。人类主题建模最初是捷克数字数学图书馆项目的 Python 脚本集合。</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">SpaCy</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> 。使用 Python 和 Cython 实现端到端工业 NLP 工作流程，并为 Transformer 提供 GPU 加速。</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">快文</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> 。Facebook 的 AI 研究 (FAIR) 实验室创建的免费、轻量级、开源 NLP 库，用于学习词嵌入和句子分类。</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">Spark 机器学习</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP 是针对所有 NLP 任务和要求的单一、统一的解决方案，可为实际生产用例提供可扩展、高性能和高精度的 NLP 软件。它利用迁移学习并在研究和跨行业中实施最新的最先进的算法和模型。由于 Spark 缺乏对上述库的全面支持，Spark NLP 建立在<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block>利用 Spark 的通用内存分布式数据处理引擎作为关键任务生产工作流的企业级 NLP 库。它的注释器利用基于规则的算法、机器学习和 TensorFlow 来支持深度学习的实现。这涵盖了常见的 NLP 任务，包括但不限于标记化、词形还原、词干提取、词性标注、命名实体识别、拼写检查和情感分析。</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">来自 Transformer 的双向编码器表示 (BERT) 是一种基于 Transformer 的 NLP 机器学习技术。它推广了预训练和微调的概念。 BERT 中的 Transformer 架构源自机器翻译，它比基于循环神经网络 (RNN) 的语言模型更好地模拟长期依赖关系。它还引入了掩蔽语言建模 (MLM) 任务，其中随机 15% 的所有标记被掩蔽，并且模型对其进行预测，从而实现真正的双向性。</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">路透社 TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">金融短语库</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">解释文档 DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">由于该领域的专业语言和缺乏标记数据，金融情绪分析具有挑战性。 FinBERT 是一种基于预训练 BERT 的语言模型，已在以下领域进行了调整：<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> ，一个金融语料库，并使用标记数据进行微调（<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) 用于金融情绪分类。研究人员从包含金融术语的新闻文章中提取了 4,500 个句子。然后，16位具有金融背景的专家和硕士生将这些句子标记为肯定、中性和否定。我们构建了一个端到端的 Spark 工作流程，使用 FinBERT 和其他两个预先训练的流程来分析 2016 年至 2020 年纳斯达克十大公司收益电话会议记录的情绪，<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ）来自 Spark NLP。</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLP 的底层深度学习引擎是 TensorFlow，这是一个端到端的开源机器学习平台，可以轻松构建模型、在任何地方进行强大的 ML 生产以及进行强大的研究实验。因此，在 Spark 中执行管道时<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block>模式，我们本质上是在运行分布式 TensorFlow，数据和模型在一个主节点和多个工作节点上并行化，并在集群上安装网络附加存储。</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod分布式训练</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">NetApp E系列Hadoop解决方案</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">与 MapReduce 相关的性能的核心 Hadoop 验证是使用 TeraGen、TeraSort、TeraValidate 和 DFSIO（读写）执行的。  TeraGen 和 TeraSort 验证结果如下<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block>以及AFF的“存储分层”部分。</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Spark 上的 Hovorod</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">根据客户要求，我们认为使用 Spark 进行分布式训练是各种用例中最重要的用例之一。在本文档中，我们使用了<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block>使用NetApp All Flash FAS (AFF) 存储控制器、 Azure NetApp Files和StorageGRID来验证 Spark 与NetApp本地、云原生和混合云解决方案的性能。</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Spark 包为 Horovod 提供了一个便捷的包装器，使得在 Spark 集群中运行分布式训练工作负载变得简单，从而实现了紧密的模型设计循环，其中数据处理、模型训练和模型评估都在训练和推理数据所在的 Spark 中完成。</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann 商店销售</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">有两个用于在 Spark 上运行 Horovod 的 API：高级 Estimator API 和低级 Run API。尽管两者都使用相同的底层机制在 Spark 执行器上启动 Horovod，但 Estimator API 抽象了数据处理、模型训练循环、模型检查点、指标收集和分布式训练。我们使用 Horovod Spark Estimators、TensorFlow 和 Keras 进行端到端数据准备和分布式训练工作流程，基于<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block>竞赛。</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">脚本<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>可以在以下部分找到<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>它包含三个部分：</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">第一部分对 Kaggle 提供并由社区收集的一组初始 CSV 文件执行各种数据预处理步骤。输入数据被分成一个训练集，<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block>子集和测试数据集。</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">第二部分定义了一个具有对数 S 型激活函数和 Adam 优化器的 Keras 深度神经网络 (DNN) 模型，并使用 Spark 上的 Horovod 对模型进行分布式训练。</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">第三部分使用最小化验证集总体平均绝对误差的最佳模型对测试数据集进行预测。然后创建一个输出 CSV 文件。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">机器学习</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">请参阅<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block>用于各种运行时比较结果。</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">使用 Keras 进行多任务深度学习以进行 CTR 预测</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">随着机器学习平台和应用的最新进展，人们将大量注意力放在了大规模学习上。点击率（CTR）定义为每百次在线广告展示的平均点击次数（以百分比表示）。它被广泛采用为各个行业垂直领域和用例的关键指标，包括数字营销、零售、电子商务和服务提供商。有关 CTR 和分布式训练性能结果的应用的更多详细信息，请参阅<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block>部分。</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte 点击日志数据集</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">在本技术报告中，我们使用了<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block>（参见 TR-4904）用于多工作者分布式深度学习，使用 Keras 构建具有深度和交叉网络 (DCN) 模型的 Spark 工作流，并将其对数损失误差函数方面的性能与基线 Spark ML 逻辑回归模型进行比较。  DCN 有效地捕获有界度的有效特征交互，学习高度非线性交互，不需要手动特征工程或穷举搜索，并且计算成本低。</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">网络规模推荐系统的数据大多是离散的和分类的，导致特征空间庞大且稀疏，这对于特征探索来说是一个挑战。这使得大多数大型系统仅限于逻辑回归等线性模型。然而，识别经常预测的特征并同时探索看不见的或罕见的交叉特征是做出良好预测的关键。线性模型简单、可解释、易于扩展，但其表达能力有限。</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">另一方面，交叉特征已被证明对提高模型的表现力具有重要意义。不幸的是，通常需要手动特征工程或详尽搜索来识别这些特征。推广到看不见的特征交互通常很困难。使用像 DCN 这样的交叉神经网络可以通过以自动方式明确应用特征交叉来避免特定于任务的特征工程。交叉网络由多层组成，其中最高程度的交互可由层深度决定。每一层都会在现有交互的基础上产生更高阶的交互，并保留前几层的交互。</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">深度神经网络 (DNN) 有望捕捉跨特征的非常复杂的交互。然而，与 DCN 相比，它需要的参数几乎多一个数量级，无法明确地形成交叉特征，并且可能无法有效地学习某些类型的特征交叉。交叉网络内存效率高并且易于实现。联合训练交叉和 DNN 组件可以有效地捕获预测特征交互并在 Criteo CTR 数据集上提供最先进的性能。</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">深度点击率</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">DCN 模型从嵌入和堆叠层开始，然后并行连接交叉网络和深度网络。接下来是最终的组合层，它将两个网络的输出组合在一起。您的输入数据可以是具有稀疏和密集特征的向量。在 Spark 中，库包含类型<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>。因此，用户区分两者并在调用各自的函数和方法时要小心，这一点很重要。在 CTR 预测等网络规模推荐系统中，输入大多是分类特征，例如<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block>。这些特征通常被编码为独热向量，例如，<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> 。独热编码（OHE）<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>在处理词汇不断变化和增长的真实世界数据集时很有用。我们修改了示例<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block>处理大型词汇表，在 DCN 的嵌入和堆叠层中创建嵌入向量。</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo 展示广告数据集</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">这<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block>预测广告点击率。它有 13 个整数特征和 26 个分类特征，其中每个类别都有很高的基数。对于该数据集，由于输入规模较大，对数损失 0.001 的改进实际上具有显著意义。对于庞大的用户群，预测准确度的微小提升都可能带来公司收入的大幅增加。该数据集包含 7 天内 11GB 的用户日志，相当于约 4100 万条记录。我们使用了 Spark<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block>随机分割数据用于训练（80%）、交叉验证（10%），剩余 10% 用于测试。</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN 是使用 Keras 在 TensorFlow 上实现的。使用DCN实现模型训练过程主要有四个部分：</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*数据处理和嵌入。*通过应用对数变换对实值特征进行规范化。对于分类特征，我们将特征嵌入到维度为 6×(类别基数)1/4 的密集向量中。连接所有嵌入将产生一个维度为 1026 的向量。</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*优化。*我们利用 Adam 优化器进行了小批量随机优化。批次大小设置为 512。对深度网络进行批量归一化，梯度裁剪范数设为100。</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*正则化。*我们采用了提前停止的方法，因为 L2 正则化或 dropout 被发现无效。</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">超参数。我们报告基于对隐藏层数量、隐藏层大小、初始学习率和交叉层数量的网格搜索的结果。隐藏层的数量范围为 2 至 5，隐藏层大小范围为 32 至 1024。对于DCN，交叉层的数量为1至6。初始学习率从 0.0001 调整到 0.001，增量为 0.0001。所有实验均在训练步骤 150,000 时提前停止，超过该步骤后就会开始出现过度拟合。</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">自动输入</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">除了 DCN 之外，我们还测试了其他流行的深度学习模型来进行 CTR 预估，包括<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>，<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> ， 和<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>。</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">用于验证的架构</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">为了进行此验证，我们使用了四个工作节点和一个主节点以及一个AFF-A800 HA 对。所有集群成员都通过 10GbE 网络交换机连接。</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">为了验证NetApp Spark 解决方案，我们使用了三种不同的存储控制器：E5760、E5724 和AFF-A800。  E系列存储控制器通过12Gbps SAS连接连接到五个数据节点。  AFF HA 对存储控制器通过 10GbE 连接向 Hadoop 工作节点提供导出的 NFS 卷。  Hadoop 集群成员通过 E 系列、 AFF和StorageGRID Hadoop 解决方案中的 10GbE 连接进行连接。</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">用于验证的架构。</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">现代企业数据中心是一种混合云，它通过具有一致操作模式的连续数据管理平面在本地和/或多个公共云中连接多个分布式基础设施环境。为了充分利用混合云，您必须能够在本地和多云环境之间无缝移动数据，而无需进行任何数据转换或应用程序重构。</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">混合云解决方案</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">客户表示，他们开始混合云之旅的方法是将二级存储迁移到云端用于数据保护等用例，或者将不太重要的业务工作负载（如应用程序开发和 DevOps）迁移到云端。然后他们转向处理更重要的工作。 Web 和内容托管、DevOps 和应用程序开发、数据库、分析和容器化应用程序是最受欢迎的混合云工作负载。企业 AI 项目的复杂性、成本和风险历来阻碍 AI 从实验阶段走向生产阶段。</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">借助NetApp混合云解决方案，客户可以通过单一控制面板享受集成的安全性、数据治理和合规性工具，用于跨分布式环境的数据和工作流管理，同时根据其消费情况优化总体拥有成本。下图是一个云服务合作伙伴的示例解决方案，该合作伙伴负责为客户的大数据分析数据提供多云连接。</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">云服务合作伙伴的示例解决方案。</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">在这种情况下，AWS 从不同来源接收的 IoT 数据存储在NetApp私有存储 (NPS) 的中心位置。 NPS 存储连接到位于 AWS 和 Azure 中的 Spark 或 Hadoop 集群，使在多个云中运行的大数据分析应用程序能够访问相同的数据。此用例的主要要求和挑战包括：</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">必须通过不同的传感器和集线器从不同来源（例如本地和云环境）接收数据。</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">该解决方案必须高效且具有成本效益。</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">主要挑战是构建一个经济高效的解决方案，在不同的内部部署和云环境之间提供混合分析服务。</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">我们的数据保护和多云连接解决方案解决了跨多个超大规模计算平台的云分析应用程序的痛点。如上图所示，来自传感器的数据通过 Kafka 流式传输并输入到 AWS Spark 集群中。数据存储在 NPS 中的 NFS 共享中，NPS 位于 Equinix 数据中心内的云提供商之外。</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">由于NetApp NPS 分别通过 Direct Connect 和 Express Route 连接连接到 Amazon AWS 和 Microsoft Azure，因此客户可以利用 In-Place Analytics Module 访问来自 Amazon 和 AWS 分析集群的数据。因此，由于本地存储和 NPS 存储都运行ONTAP软件，<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block>可以将NPS数据镜像到本地集群，提供跨本地和多云的混合云分析。</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">为了获得最佳性能， NetApp通常建议使用多个网络接口和直接连接或快速路由来访问云实例的数据。我们还有其他数据移动解决方案，包括<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block>和<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block>帮助客户构建应用感知、安全且经济高效的混合云 Spark 集群。</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">以下三个 Python 脚本对应测试的三个主要用例。首先是<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>。</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">第二个脚本是<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>。</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">第三个脚本是<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>。</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp有三个存储产品组合： FAS/ AFF、E 系列和Cloud Volumes ONTAP。我们已经通过 Apache Spark 验证了适用于 Hadoop 解决方案的AFF和带有ONTAP存储系统的 E 系列。  NetApp支持的数据结构集成了数据管理服务和应用程序（构建块），用于数据访问、控制、保护和安全。</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark 解决方案概述</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp有三个存储产品组合： FAS/ AFF、E 系列和Cloud Volumes ONTAP。我们已经通过 Apache Spark 验证了适用于 Hadoop 解决方案的AFF和带有ONTAP存储系统的 E 系列。</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">数据结构提供数据管理服务和应用程序。</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 直接访问。*为最新的 Hadoop 和 Spark 集群提供对NetApp NFS 卷的直接访问，无需额外的软件或驱动程序要求。</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror技术。*在本地和ONTAP Cloud 或 NPS 实例之间提供数据保护功能。</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">下图描述了采用NetApp存储的 Spark 解决方案。</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">采用NetApp存储的 Spark 解决方案。</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">ONTAP Spark 解决方案使用NetApp NFS 直接访问协议进行就地分析以及通过访问现有生产数据来实现 AI、ML 和 DL 工作流。 Hadoop 节点可用的生产数据被导出以执行就地分析和 AI、ML 和 DL 作业。您可以使用NetApp NFS 直接访问或不使用 NetApp NFS 直接访问来访问 Hadoop 节点中要处理的数据。在 Spark 中，使用独立或<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>集群管理器，您可以使用配置 NFS 卷<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block>。我们用不同的数据集验证了三个用例。这些验证的详细信息在“测试结果”部分中介绍。  （外部参照）</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">下图描述了NetApp Apache Spark/Hadoop 存储定位。</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop存储定位。</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">我们确定了 E 系列 Spark 解决方案、 AFF/ FAS ONTAP Spark 解决方案和StorageGRID Spark 解决方案的独特功能，并进行了详细的验证和测试。根据我们的观察， NetApp建议对于绿地安装和新的可扩展部署使用 E 系列解决方案，对于使用现有 NFS 数据的就地分析、AI、ML 和 DL 工作负载使用AFF/ FAS解决方案，对于需要对象存储时的 AI、ML、DL 和现代数据分析使用StorageGRID 。</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">推荐用于 Spark 的NetApp解决方案。</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">数据湖是原生形式的大型数据集的存储库，可用于分析、AI、ML 和 DL 作业。我们为 E 系列、 AFF/ FAS和StorageGRID SG6060 Spark 解决方案构建了一个数据湖存储库。 E 系列系统提供对 Hadoop Spark 集群的 HDFS 访问，而现有生产数据则通过 NFS 直接访问协议访问 Hadoop 集群。对于驻留在对象存储中的数据集， NetApp StorageGRID提供 S3 和 S3a 安全访问。</block>
  <block id="881214767967db331c99550277ceb793" category="summary">本页介绍了 Splunk 架构，包括关键定义、Splunk 分布式部署、Splunk SmartStore、数据流、硬件和软件要求、单站点和多站点要求等。</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk 架构</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">本节介绍 Splunk 架构，包括关键定义、Splunk 分布式部署、Splunk SmartStore、数据流、硬件和软件要求、单站点和多站点要求等。</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">关键定义</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">接下来的两个表列出了分布式 Splunk 部署中使用的 Splunk 和NetApp组件。</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">此表列出了分布式 Splunk Enterprise 配置的 Splunk 硬件组件。</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk 组件</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">任务</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">索引器</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise 数据存储库</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">通用转发器</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">负责提取数据并将数据转发给索引器</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">搜索头</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">用于在索引器中搜索数据的用户前端</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">集群主节点</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">管理索引器和搜索头的 Splunk 安装</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">监控控制台</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">整个部署中使用的集中监控工具</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">许可证主控</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">许可证管理员处理 Splunk Enterprise 许可</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">部署服务器</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">更新配置并将应用程序分发到处理组件</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">存储组件</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">用于管理热层数据的全闪存存储。也称为本地存储。</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">用于管理热层数据的 S3 对象存储。 SmartStore 使用它在热层和温层之间移动数据。也称为远程存储。</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">下表列出了 Splunk 存储架构中的组件。</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">负责组件</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">智能商店</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">为索引器提供将数据从本地存储分层到对象存储的能力。</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">Splunk</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">热的</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">通用转发器放置新写入数据的着陆点。存储是可写的，数据是可搜索的。该数据层通常由 SSD 或快速 HDD 组成。</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">缓存管理器</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">管理索引数据的本地缓存，在搜索时从远程存储中获取热数据，并从缓存中逐出最不常用的数据。</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">温暖的</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">数据按逻辑滚动到存储桶，首先从热层重命名为暖层。此层内的数据受到保护，并且与热层一样，可以由更大容量的 SSD 或 HDD 组成。使用常见的数据保护解决方案支持增量备份和完整备份。</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk 分布式部署</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">为了支持数据来自多台机器的更大环境，您需要处理大量数据。如果许多用户需要搜索数据，您可以通过在多台机器上分发 Splunk Enterprise 实例来扩展部署。这被称为分布式部署。</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">在典型的分布式部署中，每个 Splunk Enterprise 实例执行一项专门的任务，并驻留在与主要处理功能相对应的三个处理层之一上。</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">下表列出了 Splunk Enterprise 处理层。</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">层级</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">组件</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">描述</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">数据输入</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">货运代理</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">转发器消费数据，然后将数据转发给一组索引器。</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">索引</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">索引器对通常从一组转发器接收的传入数据进行索引。索引器将数据转换为事件并将事件存储在索引中。索引器还根据搜索头的搜索请求搜索索引数据。</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">搜索管理</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">搜索头是搜索的中心资源。集群中的搜索头是可互换的，并且可以从搜索头集群的任何成员访问相同的搜索、仪表板、知识对象等。</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">下表列出了分布式 Splunk Enterprise 环境中使用的重要组件。</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">责任</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">索引集群主节点</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">协调索引器集群的活动和更新</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">索引管理</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">索引集群</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">配置为相互复制数据的 Splunk Enterprise 索引器组</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">搜索头部署器</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">处理集群主控的部署和更新</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">搜索头管理</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">搜索头集群</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">一组搜索头，作为搜索的中心资源</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">负载均衡器</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">由集群组件使用，以处理搜索头、索引器和 S3 目标不断增长的需求，从而在集群组件之间分配负载。</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">集群组件的负载管理</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">了解 Splunk Enterprise 分布式部署的以下优势：</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">访问多样化或分散的数据源</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">提供处理任何规模和复杂程度的企业数据需求的功能</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">通过数据复制和多站点部署实现高可用性并确保灾难恢复</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore 是一种索引器功能，它使远程对象存储（如 Amazon S3）能够存储索引数据。随着部署的数据量增加，对存储的需求通常会超过对计算资源的需求。  SmartStore 允许您通过单独扩展这些资源来经济高效地管理索引器存储和计算资源。</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore 引入了远程存储层和缓存管理器。这些功能允许数据驻留在本地索引器上或远程存储层上。缓存管理器管理索引器和在索引器上配置的远程存储层之间的数据移动。</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">使用 SmartStore，您可以将索引器存储占用空间降至最低，并选择针对 I/O 优化的计算资源。大多数数据驻留在远程存储上。索引器维护一个包含最少量数据的本地缓存：热存储桶、参与活动或最近搜索的热存储桶副本以及存储桶元数据。</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore 数据流</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">当来自各个来源的数据到达索引器时，数据会被索引并本地保存在热存储桶中。索引器还将热存储桶数据复制到目标索引器。到目前为止，数据流与非 SmartStore 索引的数据流相同。</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">当热桶变暖时，数据流就会分叉。源索引器将热存储桶复制到远程对象存储（远程存储层），同时将现有副本保留在其缓存中，因为搜索往往会遇到最近索引的数据。但是，目标索引器会删除其副本，因为远程存储无需维护多个本地副本即可提供高可用性。存储桶的主副本现在位于远程存储中。</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">下图显示了 Splunk SmartStore 数据流。</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">索引器上的缓存管理器是 SmartStore 数据流的核心。它根据需要从远程存储中获取存储桶的副本来处理搜索请求。它还会从缓存中逐出较旧或搜索较少的存储桶副本，因为它们参与搜索的可能性会随着时间的推移而降低。</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">缓存管理器的工作是优化可用缓存的使用，同时确保搜索可以立即访问所需的存储桶。</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">下表列出了实施该解决方案所需的软件组件。解决方案实施过程中所使用的软件组件可能会根据客户要求而有所不同。</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">产品系列</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">产品名称</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">产品版本</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">操作系统</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID对象存储</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">不适用</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise 与 SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">单站点和多站点要求</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">在企业 Splunk 环境（中型和大型部署）中，数据源自多台机器，并且许多用户需要搜索数据，您可以通过在单个和多个站点上分发 Splunk Enterprise 实例来扩展部署。</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">下表列出了分布式 Splunk Enterprise 环境中使用的组件。</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">配置为相互复制数据的 Splunk Enterprise 索引器组</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">负载均衡器</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">集群组件的负载管理</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">该图描绘了单站点分布式部署的示例。</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">该图描绘了多站点分布式部署的示例。</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">下表列出了实施该解决方案所需的最少硬件组件数量。解决方案具体实施中使用的硬件组件可能根据客户要求而有所不同。</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">无论您在单个站点还是多个站点部署了 Splunk SmartStore 和StorageGRID ，所有系统都通过StorageGRID GRID Manager 在单一玻璃窗格中进行管理。有关更多详细信息，请参阅“使用网格管理器进行简单管理”部分。</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">该表列出了单个站点使用的硬件。</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">磁盘</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">可用容量</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">注</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">管理节点和负载均衡器</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48，8TB（NL-SAS 硬盘）</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">远程存储</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">下表列出了用于多站点配置（每个站点）的硬件。</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">管理节点和负载均衡器</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID负载均衡器：SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">对象存储需要使用负载均衡器来呈现云存储命名空间。  StorageGRID支持来自 F5 和 Citrix 等领先供应商的第三方负载均衡器，但许多客户选择企业级StorageGRID均衡器以实现简单性、弹性和高性能。  StorageGRID负载均衡器可作为虚拟机、容器或专用设备使用。</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 有助于使用高可用性 (HA) 组和 S3 数据路径连接的智能负载平衡。没有其他内部部署对象存储系统提供定制的负载均衡器。</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000 设备提供以下功能：</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">StorageGRID系统的负载均衡器和管理节点（可选）功能</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">StorageGRID Appliance Installer 可简化节点部署和配置</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">简化 S3 端点和 SSL 的配置</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">专用带宽（而不是与其他应用程序共享第三方负载均衡器）</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">高达 4 x 100Gbps 聚合以太网带宽</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">下图显示了 SG1000 网关服务设备。</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060 设备包括一个计算控制器（SG6060）和一个存储控制器架（E 系列 E2860），其中包含两个存储控制器和 60 个驱动器。该设备具有以下功能：</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">在单个命名空间中扩展到 400PB。</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">高达 4x 25Gbps 的聚合以太网带宽。</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">包括StorageGRID Appliance Installer，以简化节点部署和配置。</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">每个 SG6060 设备可以有一个或两个额外的扩展架，总共可容纳 180 个驱动器。</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">两个 E 系列 E2800 控制器（双工配置）提供存储控制器故障转移支持。</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">五抽屉驱动器架，可容纳 60 个 3.5 英寸驱动器（两个固态驱动器和 58 个 NL-SAS 驱动器）。</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">下图显示了 SG6060 设备。</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunk 设计</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">下表列出了单个站点的 Splunk 配置。</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">核心</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">操作系统</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16 核</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32 GB 内存</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">管理用户数据</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">用户前端在索引器中搜索数据</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">处理搜索头集群的更新</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">管理 Splunk 安装和索引器</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">监控控制台和许可证主控器</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">对整个 Splunk 部署进行集中监控并管理 Splunk 许可证</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">下表描述了多站点配置的 Splunk 配置。</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">下表列出了多站点配置（站点 A）的 Splunk 配置。</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">负责提取数据并将数据转发给索引器。</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">对整个 Splunk 部署进行集中监控并管理 Splunk 许可证。</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">下表列出了多站点配置（站点 B）的 Splunk 配置。</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise 是市场领先的 SIEM 解决方案，可推动安全、IT 和 DevOps 团队取得成果。</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise 是市场领先的 SIEM 解决方案，可推动安全、IT 和 DevOps 团队取得成果。我们客户组织中 Splunk 的使用量已显著增加。因此，需要添加更多数据源，同时保留更长时间的数据，从而给 Splunk 基础设施带来压力。</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore 和NetApp StorageGRID的结合旨在为组织提供可扩展的架构，以通过 SmartStore 和StorageGRID对象存储实现更高的摄取性能，并提高跨多个地理区域的 Splunk 环境的可扩展性。</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">NetApp StorageGRID文档资源</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Splunk Enterprise 文档</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise 关于 SmartStore</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Splunk Enterprise 分布式部署手册</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise 管理索引器和索引器集群</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">本技术报告概述了NetApp为 Splunk SmartStore 解决方案带来的优势，同时演示了在您的环境中设计和调整 Splunk SmartStore 大小的框架。最终结果是一个简单、可扩展且有弹性的解决方案，可提供极具吸引力的 TCO。</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869： NetApp StorageGRID与 Splunk SmartStore</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise 是市场领先的安全信息和事件管理 (SIEM) 解决方案，可推动安全、IT 和 DevOps 团队取得成果。</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">概述</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">数据量继续以指数级增长，为能够利用这一巨大资源的企业创造了巨大的机会。 Splunk Enterprise 在更广泛的使用案例中得到广泛应用。随着用例的增长，Splunk Enterprise 提取和处理的数据量也在增加。 Splunk Enterprise 的传统架构是分布式横向扩展设计，提供出色的数据访问和可用性。然而，使用这种架构的企业面临着与扩展相关的成本不断增长的问题，以满足快速增长的数据量。</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">采用NetApp StorageGRID的 Splunk SmartStore 通过提供一种计算和存储分离的新部署模型解决了这一难题。该解决方案还允许客户跨单个和多个站点进行扩展，从而为 Splunk Enterprise 环境提供无与伦比的规模和弹性，同时通过允许计算和存储独立扩展并为经济高效的基于云的 S3 对象存储添加智能分层来降低成本。</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">该解决方案在保持搜索性能的同时优化了本地存储的数据量，允许按需扩展计算和存储。  SmartStore 自动评估数据访问模式，以确定哪些数据需要进行实时分析，哪些数据应该驻留在成本较低的 S3 对象存储中。</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">本技术报告概述了NetApp为 Splunk SmartStore 解决方案带来的优势，同时演示了在您的环境中设计和调整 Splunk SmartStore 大小的框架。最终结果是一个简单、可扩展且有弹性的解决方案，可提供极具吸引力的 TCO。  StorageGRID提供可扩展且经济高效的基于 S3 协议/API 的对象存储（也称为远程存储），使组织能够以较低的成本扩展其 Splunk 解决方案，同时提高弹性。</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore 将对象存储称为远程存储或远程存储层。</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">关于NetApp StorageGRID</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID是一种软件定义的对象存储解决方案，适用于大型档案、媒体存储库和 Web 数据存储。借助StorageGRID， NetApp利用二十年来提供业界领先的创新和数据管理解决方案的经验，同时帮助组织管理和最大化其内部以及公共、私有或混合云部署中的信息价值。</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID为大规模非结构化数据提供安全、持久的存储。集成的、元数据驱动的生命周期管理策略可优化数据在整个生命周期中的存储位置。将内容放置在正确的位置、正确的时间以及正确的存储层以降低成本。单一命名空间允许通过单一调用访问数据，而不管StorageGRID存储的地理位置如何。客户可以在数据中心之间和云基础设施中部署和管理多个StorageGRID实例。</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID系统由全球分布、冗余、异构的节点组成，可以与现有和下一代客户端应用程序集成。</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape 最近在最新报告《IDC MarketScape：2019 年全球基于对象的存储供应商评估》中将NetApp评为领导者。  StorageGRID拥有近 20 年在要求最严格的行业中进行生产部署的经验，是非结构化数据领域公认的领导者。</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">借助StorageGRID，您可以实现以下目标：</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">部署多个StorageGRID实例，通过可轻松扩展到数百 PB 的单个命名空间访问数据中心和云之间任何位置的数据。</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">提供跨基础设施部署和集中管理的灵活性。</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">利用分层擦除编码 (EC) 提供无与伦比的耐用性，耐用性达到 15 个 9。</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">通过与 Amazon S3 Glacier 和 Azure Blob 进行验证的集成，实现更多混合多云功能。</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">通过防篡改数据保留满足监管义务并促进合规性，无需专有 API 或供应商锁定。</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID主页</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">有关StorageGRID如何帮助您解决最复杂的非结构化数据管理问题的更多信息，请参阅<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>。</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">关于Splunk Enterprise</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise 是一个将数据转化为行动的平台。日志文件、网站、设备、传感器和应用程序等各种来源生成的数据被发送到 Splunk Indexer 并由其解析，从而使您可以从数据中获得丰富的见解。它可能识别数据泄露、指出客户和产品趋势、寻找优化基础设施的机会或在各种用例中创建可操作的见解。</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">关于Splunk SmartStore</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore 扩展了 Splunk 架构的优势，同时简化了其经济高效扩展的能力。计算和存储资源的分离导致索引器节点针对 I/O 进行了优化，并且存储需求显著减少，因为它们仅将一部分数据存储为缓存。当只需要其中一种资源时，您不必添加额外的计算或存储，从而可以实现显著的成本节约。您可以使用经济高效且易于扩展的基于 S3 的对象存储，这进一步简化了环境、降低了成本并允许您维护更庞大的数据集。</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore 为组织带来巨大价值，包括：</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">通过将热数据移动到成本优化的 S3 对象存储来降低存储成本</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">通过分离存储和计算实现无缝扩展</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">利用弹性云原生存储简化业务连续性</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">本页介绍了NetApp StorageGRID控制器上的 Splunk SmartStore 性能。</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">单站点 SmartStore 性能</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">本节介绍 Splunk SmartStore 在NetApp StorageGRID控制器上的性能。  Splunk SmartStore 将热数据移动到远程存储，在本例中是性能验证中的StorageGRID对象存储。</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">我们使用 EF600 作为热/缓存存储，使用StorageGRID 6060 作为远程存储。我们使用以下架构进行性能验证。我们使用了两个搜索头、四个重型转发器将数据转发到索引器、七个 Splunk 事件生成器（Eventgens）来生成实时数据，以及 18 个索引器来存储数据。</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">配置</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">下表列出了用于 SmartStorage 性能验证的硬件。</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">重型货运代理</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16 核</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">用户前端在索引器中搜索数据</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore远程商店性能验证</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">在本次性能验证中，我们在所有索引器的本地存储中配置了 SmartStore 缓存，以保存 10 天的数据。我们启用了<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block>（750MB 存储桶大小）在 Splunk 集群管理器中并将更改推送到所有索引器。为了测量上传性能，我们在 10 天内每天摄取 10TB 的数据，并同时将所有热存储桶转为热存储桶，并从 SmartStore 监控控制台仪表板捕获每个实例和整个部署的峰值和平均吞吐量。</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">此图显示了一天内摄取的数据。</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">我们从集群主节点运行以下命令（索引名称是<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>）。然后，我们通过 SmartStore 监控控制台仪表板捕获每个实例和整个部署的峰值和平均上传吞吐量。</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">集群主控对所有索引器（rtp-idx0001…rtp-idx0018）均采用无密码身份验证。</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">为了测量下载性能，我们使用以下命令运行两次 evict CLI，从缓存中逐出所有数据。</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">我们从集群主机运行以下命令，并从搜索头基于来自StorageGRID的远程存储的 10 天数据运行搜索。然后，我们通过 SmartStore 监控控制台仪表板捕获每个实例和整个部署的峰值和平均上传吞吐量。</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">索引器配置是从 SmartStore 集群主机推送的。集群主机对索引器有以下配置。</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">我们在搜索头上运行了以下搜索查询来收集性能矩阵。</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">我们从集群主机收集了性能信息。峰值性能为61.34GBps。</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">平均性能约为 29GBps。</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID性能</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">事件生成</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore 的性能基于从大量数据中搜索特定的模式和字符串。在此验证中，事件是使用<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block>通过搜索头在特定的 Splunk 索引（eventgen-test）上进行搜索，并且请求对于大多数查询转到StorageGRID 。下图显示了查询数据的命中和未命中情况。命中数据来自本地磁盘，未命中数据来自StorageGRID控制器。</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">绿色显示命中数据，橙色显示未命中数据。</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">当在StorageGRID上运行搜索查询时， StorageGRID的 S3 检索率的时间如下图所示。</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID硬件使用情况</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID实例有一个负载均衡器和三个StorageGRID控制器。所有三个控制器的 CPU 利用率均为 75% 至 100%。</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">采用NetApp存储控制器的 SmartStore - 为客户带来好处</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*将计算和存储分离。*  Splunk SmartStore 将计算和存储分离，帮助您独立扩展它们。</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*按需提供数据。*  SmartStore 使数据接近按需计算，并提供计算和存储弹性和成本效率，以实现更长时间的大规模数据保留。</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*符合 AWS S3 API。*  SmartStore 使用 AWS S3 API 与恢复存储进行通信，恢复存储是符合 AWS S3 和 S3 API 的对象存储，例如StorageGRID。</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*减少存储需求和成本。* SmartStore 减少了老化数据（暖/冷）的存储要求。它只需要一份数据副本，因为NetApp存储提供数据保护并处理故障和高可用性。</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*硬件故障。*  SmartStore 部署中的节点故障不会导致数据无法访问，并且索引器从硬件故障或数据不平衡中恢复的速度更快。</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">应用程序和数据感知缓存。</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">按需添加或删除索引器以及设置或拆除集群。</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">存储层不再与硬件相关。</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">该解决方案允许添加计算、热存储或 S3 资源，以满足单站点和多站点部署中用户数量或摄取率不断增长的需求。</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">此解决方案的优势</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*表现。*  Splunk SmartStore 和NetApp StorageGRID的结合使用对象存储在热存储桶和温存储桶之间实现数据的快速迁移。  StorageGRID通过为大型对象工作负载提供快速性能来加速迁移过程。</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*多站点就绪。*  StorageGRID分布式架构允许 Splunk SmartStore 通过单个全局命名空间扩展跨单个和多个站点的部署，无论数据位于何处，都可以从任何站点访问数据。</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*提高了可扩展性。*独立于计算资源扩展存储资源，以满足 Splunk 环境中不断变化的需求，从而提供更好的 TCO。</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*容量。*使用StorageGRID将单个命名空间扩展到 560PB 以上，满足 Splunk 部署中快速增长的容量。</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*数据可用性。*使用元数据驱动的策略来优化数据可用性、性能、地理分布、保留、保护和存储成本，这些策略可以随着数据的业务价值的发展而动态调整。</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunk 提供的指南</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">使用 SmartStore 缓存提高性能，它是索引器的一个组件，用于处理本地（热）和远程（温）存储之间的存储桶副本传输。此解决方案的 Splunk 规模基于<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>。该解决方案允许添加计算、热存储或 S3 资源，以满足单站点和多站点部署中用户数量或摄取率不断增长的需求。</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">本页介绍了完成此解决方案所使用的组件，包括NetApp StorageGRID、Splunk Enterprise 和 Splunk SmartStore。</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">解决方案概述</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID是一个高性能且经济高效的对象存储平台。它使用分布式、基于节点的网格架构提供智能、策略驱动的全球数据管理。它通过其无处不在的全局对象命名空间与复杂的数据管理功能相结合，简化了 PB 级非结构化数据和数十亿个对象的管理。单次调用对象访问可跨站点扩展，并简化高可用性架构，同时确保无论站点或基础设施是否中断，都能持续进行对象访问。</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">多租户允许多个云和企业非结构化数据应用程序在同一网格内得到安全地服务，从而增加了StorageGRID的投资回报率和用例。可以使用元数据驱动的对象生命周期策略创建多个服务级别，从而优化跨多个地区的耐用性、保护性、性能和局部性。随着需求的变化，用户可以调整策略并且无中断地重新调整数据格局。</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore 利用StorageGRID作为远程存储层，并允许客户部署多个地理分布的站点，以实现强大的可用性和耐用性，并以单个对象命名空间的形式呈现。这使得 Splunk SmartStore 能够利用StorageGRID的高性能、高密度容量以及使用单个 URL 与对象交互扩展到多个物理站点上的数百个节点的能力。此单一 URL 还允许在不中断的情况下进行存储扩展、升级和修复，甚至超越单个站点。  StorageGRID独特的数据管理策略引擎提供了优化的性能和耐用性水平，并符合数据局部性要求。</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk 是机器生成数据收集和分析领域的领导者，通过其运营分析功能帮助简化和现代化 IT。它还扩展到商业分析、安全和物联网用例。存储是成功部署 Splunk 软件的关键因素。</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">机器生成的数据是增长最快的大数据类型。其格式难以预测，并且来自许多不同的来源，通常速率很高且数量巨大。这些工作负载特征通常被称为数字排气。  Splunk SmartStore 有助于理解这些数据并提供智能数据分层，以便在最具成本效益的存储层上优化放置热数据和温数据。</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore 是一种索引器功能，它使用对象存储（也称为远程存储或远程存储层）例如StorageGRID通过 S3 协议存储热数据。</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">随着部署的数据量增加，对存储的需求通常会超过对计算机资源的需求。  SmartStore 允许您通过分别扩展计算和存储来经济高效地管理索引器存储和计算资源。</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore 引入了使用 S3 协议的远程存储层和缓存管理器。这些功能允许数据驻留在本地索引器或远程存储上。缓存管理器位于索引器上，负责管理索引器和远程存储层之间的数据移动。数据与存储桶元数据一起存储在存储桶（热和温）中。</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">使用 SmartStore，您可以将索引器存储占用空间降至最低，并选择 I/O 优化的计算资源，因为大多数数据都驻留在远程存储层上。索引器维护一个本地缓存，代表返回请求和预测结果所需的最少数据量。本地缓存包含热存储桶、参与活动或最近搜索的热存储桶副本以及存储桶元数据。</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">带有StorageGRID的 Splunk SmartStore 使客户能够通过高性能且经济高效的远程存储逐步扩展环境，同时为整体解决方案提供高度的弹性。这使得客户可以在任何给定时间添加任何给定数量的任何组件（热存储和/或温 S3 存储），无论他们是需要更多索引器、更改数据保留，还是在不造成任何中断的情况下增加摄取率。</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID具有多种功能，用户可以利用这些功能并根据不断变化的环境进行定制。</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">适用于 Splunk SmartStore 的灵活StorageGRID功能</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID具有多种功能，用户可以利用这些功能并根据不断变化的环境进行定制。从部署到扩展您的 Splunk SmartStore，您的环境需要快速适应变化，并且不应对 Splunk 造成干扰。  StorageGRID灵活的数据管理策略 (ILM) 和流量分类器 (QoS) 让您可以规划并适应您的环境。</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager 是基于浏览器的图形界面，允许您在单个玻璃窗格中配置、管理和监控全球分布位置的StorageGRID系统，如下图所示。</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">使用网格管理器界面执行以下任务：</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">适用于 Splunk 的NetApp StorageGRID应用程序</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">NetApp StorageGRID App for Splunk 是一款专用于 Splunk Enterprise 的应用程序。此应用程序与 Splunk 的NetApp StorageGRID附加组件配合使用。它提供对StorageGRID健康状况、帐户使用信息、安全审计详细信息、资源使用情况和监控等方面的可见性。</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">下图显示了适用于 Splunk 的StorageGRID应用程序。</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM 策略</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID具有灵活的数据管理策略，包括保留对象的多个副本，并使用 EC（擦除编码）方案（如 2+1 和 4+2（以及许多其他方案））根据特定的性能和数据保护要求存储对象。由于工作负载和需求随时间而变化，ILM 策略通常也必须随时间而变化。修改 ILM 策略是一项核心功能，允许StorageGRID客户快速轻松地适应不断变化的环境。</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID通过添加更多节点来扩展性能，这些节点可以是虚拟机、裸机或专用设备，如 SG5712、SG5760、SG6060 或 SGF6024。在我们的测试中，我们使用 SG6060 设备以最小尺寸的三节点网格超出了 SmartStore 关键性能要求。当客户使用附加索引器扩展其 Splunk 基础设施时，他们可以添加更多存储节点来提高性能和容量。</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">负载均衡器和端点配置</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID中的管理节点提供网格管理器 UI（用户界面）和 REST API 端点来查看、配置和管理您的StorageGRID系统，以及审计日志来跟踪系统活动。为了为 Splunk SmartStore 远程存储提供高可用性 S3 端点，我们实施了StorageGRID负载均衡器，它作为管理节点和网关节点上的服务运行。此外，负载均衡器还管理本地流量并与 GSLB（全局服务器负载均衡）对话以帮助进行灾难恢复。</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">为了进一步增强端点配置， StorageGRID提供了内置于管理节点的流量分类策略，让您监控工作负载流量，并对工作负载应用各种服务质量 (QoS) 限制。流量分类策略应用于网关节点和管理节点的StorageGRID负载均衡器服务上的端点。这些策略可以帮助限制和监控流量。</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">当客户意识到 Splunk 数据分析的强大功能和易用性时，他们自然希望索引不断增长的数据量。随着数据量的增长，服务数据所需的计算和存储基础设施也在增长。</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">智能分层和成本节约</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">当客户意识到 Splunk 数据分析的强大功能和易用性时，他们自然希望索引不断增长的数据量。随着数据量的增长，服务数据所需的计算和存储基础设施也在增长。由于旧数据的引用频率较低，因此投入相同数量的计算资源并消耗昂贵的主存储变得越来越低效。为了大规模运营，客户可以将热数据移动到更具成本效益的层，从而释放热数据的计算和主存储。</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">带有StorageGRID 的Splunk SmartStore 为组织提供了可扩展、高性能且经济高效的解决方案。由于 SmartStore 具有数据感知能力，它会自动评估数据访问模式，以确定哪些数据需要进行实时分析（热数据），哪些数据应该驻留在低成本的长期存储中（温数据）。  SmartStore 动态且智能地使用行业标准的 AWS S3 API，将数据放置在StorageGRID提供的 S3 存储中。  StorageGRID灵活的横向扩展架构允许热数据层根据需要以经济高效的方式进行增长。  StorageGRID基于节点的架构确保性能和成本要求得到最佳满足。</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">下图说明了 Splunk 和StorageGRID分层。</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">Splunk SmartStore 与NetApp StorageGRID的业界领先组合通过全栈解决方案提供了解耦架构的优势。</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623： NetApp E 系列 E5700 和 Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">NetApp的 Mitch Blackburn</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 描述了NetApp E 系列和 Splunk 设计的集成架构。该设计针对节点存储均衡、可靠性、性能、存储容量、密度等进行了优化，采用了Splunk聚集索引节点模型，具有更高的可扩展性和更低的TCO。将存储与计算分离可以实现分别扩展，从而节省过度配置其中一个或另一个的成本。此外，本文档还总结了通过Splunk机器日志事件模拟工具获得的性能测试结果。</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">NetApp AI 功能可实现跨 AI 管道的无缝数据管理和数据移动，以进行训练、再训练、微调、推理和监控生成 AI 模型。</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">生成式人工智能和NetApp价值</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">对生成人工智能 (AI) 的需求正在推动各个行业的颠覆，增强商业创造力和产品创新。</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">许多组织正在使用生成式人工智能来构建新的产品功能、提高工程生产力和原型人工智能应用程序，以提供更好的结果和消费者体验。生成式人工智能（例如生成式预训练变压器 (GPT)）使用神经网络来创建新内容，包括文本、音频和视频等多种内容。鉴于大型语言模型 (LLM) 涉及的极端规模和海量数据集，在公司设计 AI 解决方案之前，构建一个强大的 AI 基础架构至关重要，该基础架构可以利用内部部署、混合和多云部署选项的强大数据存储功能，并降低与数据移动性、数据保护和治理相关的风险。本文介绍了这些考虑因素以及相应的NetApp AI 功能，这些功能支持跨 AI 数据管道进行无缝数据管理和数据移动，以训练、再训练、微调和推理生成 AI 模型。</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">内容提要</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">最近，自 2022 年 11 月推出 GPT-3 的衍生产品 ChatGPT 以来，用于根据用户提示生成文本、代码、图像甚至治疗性蛋白质的新型 AI 工具获得了极大的声誉。这表明用户可以使用自然语言提出请求，人工智能将解释和生成文本，例如反映用户请求的新闻文章或产品描述，或使用基于现有数据训练的算法生成代码、音乐、语音、视觉效果和 3D 资产。因此，稳定扩散、幻觉、快速工程和价值一致性等短语正在人工智能系统的设计中迅速涌现。这些自监督或半监督机器学习 (ML) 模型正作为预先训练的基础模型 (FM) 通过云服务提供商和其他 AI 公司供应商得到广泛应用，各行各业的各种商业机构正在采用这些模型来执行广泛的下游 NLP (自然语言处理) 任务。正如麦肯锡等研究分析公司所言——“生成式人工智能对生产力的影响可能会为全球经济增加数万亿美元的价值。”当企业将人工智能重新想象为人类的思想伙伴，而设施管理者也同时拓展企业和机构利用生成性人工智能的能力时，管理海量数据的机会将继续增长。本文档介绍了生成式人工智能以及与NetApp功能相关的设计概念，这些功能为NetApp客户（包括本地和混合或多云环境）带来了价值。</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*那么，客户在其 AI 环境中使用NetApp有什么好处呢？*  NetApp帮助组织应对快速数据和云增长、多云管理以及采用 AI 等下一代技术所带来的复杂性。 NetApp将各种功能整合到智能数据管理软件和存储基础架构中，并与针对 AI 工作负载优化的高性能实现了良好的平衡。像 LLM 这样的生成式 AI 解决方案需要多次读取和处理从存储到内存的源数据集以促进智能。  NetApp一直是边缘到核心到云生态系统中数据移动性、数据治理和数据安全技术的领导者，帮助企业客户构建大规模 AI 解决方案。  NetApp凭借强大的合作伙伴网络，一直致力于帮助首席数据官、AI 工程师、企业架构师和数据科学家设计自由流动的数据管道，以完成 AI 模型训练和推理的数据准备、数据保护和战略数据管理职责，从而优化 AI/ML 生命周期的性能和可扩展性。 NetApp数据技术和功能（例如用于深度学习数据管道的NetApp ONTAP AI、用于在存储端点之间无缝高效地传输数据的NetApp SnapMirror以及用于在数据流从批量转变为实时且数据工程即时发生时进行实时渲染的NetApp FlexCache）为实时生成 AI 模型的部署带来了价值。随着各类企业采用新的人工智能工具，他们面临着从边缘到数据中心再到云端的数据挑战，需要可扩展、负责任和可解释的人工智能解决方案。作为混合和多云领域的数据权威， NetApp致力于构建合作伙伴和联合解决方案网络，以帮助构建数据管道和数据湖的各个方面，以进行生成式 AI 模型训练（预训练）、微调、基于上下文的推理和 LLM 的模型衰减监控。</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">什么是生成式人工智能？</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">生成式人工智能正在改变我们创造内容、产生新设计概念和探索新颖构图的方式。它展示了生成对抗网络 (GAN)、变分自动编码器 (VAE) 和生成预训练变压器 (GPT) 等神经网络框架，它们可以生成文本、代码、图像、音频、视频和合成数据等新内容。 OpenAI 的 Chat-GPT、Google 的 Bard、Hugging Face 的 BLOOM 和 Meta 的 LLaMA 等基于 Transformer 的模型已成为支撑大型语言模型诸多进步的基础技术。同样，OpenAI 的 Dall-E、Meta 的 CM3leon 和 Google 的 Imagen 都是文本到图像扩散模型的例子，它们为客户提供了前所未有的照片级真实感，可以从头开始创建新的复杂图像，或编辑现有图像以生成高质量的上下文感知图像，使用数据集增强和链接文本和视觉语义的文本到图像合成。数字艺术家开始将 NeRF（神经辐射场）等渲染技术与生成式人工智能相结合，将静态 2D 图像转换为沉浸式 3D 场景。一般来说，LLM 大致由四个参数表征：（1）模型的大小（通常有数十亿个参数）；（2）训练数据集的大小；（3）训练成本；（4）训练后的模型性能。  LLM 也主要分为三种变压器架构。 （i）仅编码器模型。例如 BERT（Google，2018）；（ii）编码器-解码器，例如 BART（Meta，2020）和（iii）仅解码器模型。例如LLaMA（Meta，2023 年）、PaLM-E（Google，2023 年）。根据业务需求，无论公司选择哪种架构，训练数据集中的模型参数数量（N）和标记数量（D）通常决定训练（预训练）或微调 LLM 的基准成本。</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">企业用例和下游 NLP 任务</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">各行各业的企业都发现人工智能有越来越多的潜力，可以从现有数据中提取并产生新的价值形式，用于业务运营、销售、营销和法律服务。根据 IDC（国际数据公司）关于全球生成式人工智能用例和投资的市场情报，软件开发和产品设计中的知识管理受到的影响最大，其次是营销的故事情节创作和开发人员的代码生成。在医疗保健领域，临床研究组织正在开辟医学新领域。 ProteinBERT 等预训练模型结合了基因本体 (GO) 注释，可以快速设计药物的蛋白质结构，这代表了药物发现、生物信息学和分子生物学领域的一个重要里程碑。生物技术公司已启动生成性人工智能药物的人体试验，旨在治疗肺纤维化（IPF）等疾病，这是一种导致肺组织不可逆瘢痕形成的肺部疾病。</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">图 1：驱动生成式人工智能的用例</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">生成式人工智能推动的自动化应用的增加也正在改变许多职业的工作活动的供需。根据麦肯锡的数据，美国劳动力市场（下图）经历了快速转型，考虑到人工智能的影响，这种转型可能还会持续下去。</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">资料来源：麦肯锡公司</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">图2：资料来源：麦肯锡公司</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">存储在生成式人工智能中的作用</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">LLM 主要依赖于深度学习、GPU 和计算。然而，当GPU缓冲区填满时，数据需要快速写入存储器。虽然一些 AI 模型足够小，可以在内存中执行，但 LLM 需要高 IOPS 和高吞吐量存储才能快速访问大型数据集，特别是当它涉及数十亿个令牌或数百万个图像时。对于 LLM 的典型 GPU 内存要求，训练具有 10 亿个参数的模型所需的内存可能高达 80GB @32 位全精度。在这种情况下，Meta 的 LLaMA 2（一系列 LLM，规模从 70 亿到 700 亿个参数）可能需要 70x80、约 5600GB 或 5.6TB 的 GPU RAM。此外，您需要的内存量与您想要生成的最大令牌数量成正比。例如，如果你想生成最多 512 个 token（约 380 个单词）的输出，你需要<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block>。这看起来似乎无关紧要——但是，如果您想运行更大的批次，它就会开始累积。因此，对于组织来说，在内存中训练或微调 LLM 的成本非常高，从而使存储成为生成 AI 的基石。</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">攻读法学硕士学位的三种主要途径</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">《哈佛商业评论》</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">对于大多数企业而言，根据目前的趋势，部署 LLM 的方法可以概括为 3 种基本场景。正如最近<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block>文章：（1）从头开始训练（预训练）法学硕士——成本高昂，并且需要专业的 AI/ML 技能；（2）使用企业数据微调基础模型——复杂但可行；（3）使用检索增强生成 (RAG) 查询包含公司数据的文档存储库、API 和矢量数据库。在实施过程中，每种方法都需要在工作量、迭代速度、成本效率和模型准确性之间进行权衡，用于解决不同类型的问题（下图）。</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">图 3：问题类型</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">基础模型</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">基础模型 (FM) 也称为基础模型，是一种大型 AI 模型 (LLM)，使用大规模自我监督对大量未标记数据进行训练，通常适用于广泛的下游 NLP 任务。由于训练数据没有经过人工标记，因此模型是自然产生的，而不是明确编码的。这意味着该模型无需明确编程即可生成自己的故事或叙述。因此FM的一个重要特点就是同质化，即在许多领域使用相同的方法。然而，通过个性化和微调技术，如今出现的产品中集成的 FM 不仅擅长生成文本、文本转图像和文本转代码，而且还擅长解释特定领域的任务或调试代码。例如，OpenAI 的 Codex 或 Meta 的 Code Llama 等 FM 可以根据编程任务的自然语言描述生成多种编程语言的代码。这些模型精通十几种编程语言，包括 Python、C#、JavaScript、Perl、Ruby 和 SQL。它们理解用户的意图并生成完成所需任务的特定代码，这对于软件开发、代码优化和编程任务的自动化很有用。</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">微调、领域特异性和再训练</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">Meta 的骆驼 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">在数据准备和数据预处理之后进行 LLM 部署的常见做法之一是选择已经在大型多样化数据集上训练过的预训练模型。在微调的背景下，这可以是一个开源的大型语言模型，例如<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block>对 700 亿个参数和 2 万亿个标记进行训练。一旦选择了预训练模型，下一步就是根据特定领域的数据对其进行微调。这涉及调整模型的参数并根据新数据对其进行训练以适应特定的领域和任务。例如，BloombergGPT 是一门专有的法学硕士课程，接受过广泛金融数据的培训，服务于金融行业。针对特定任务设计和训练的领域特定模型通常在其范围内具有更高的准确性和性能，但在其他任务或领域之间的可转移性较低。当业务环境和数据在一段时间内发生变化时，与测试期间的表现相比，FM 的预测准确性可能会开始下降。这时，重新训练或微调模型就变得至关重要。传统 AI/ML 中的模型再训练是指使用新数据更新已部署的 ML 模型，通常是为了消除发生的两种类型的漂移。  （1）概念漂移——当输入变量和目标变量之间的联系随时间而改变时，由于我们想要预测的描述发生了变化，模型可能会产生不准确的预测。 (2) 数据漂移——当输入数据的特征发生变化时发生，例如客户习惯或行为随时间发生变化，因此模型无法对此类变化做出反应。类似地，再培训也适用于 FM/LLM，但是成本可能要高得多（数百万美元），因此大多数组织可能不会考虑。它正处于积极的研究中，在 LLMOps 领域中仍然处于新兴阶段。因此，当微调 FM 中出现模型衰减时，企业可以选择使用较新的数据集再次进行微调（便宜得多），而不是重新训练。从成本角度来看，下面列出了 Azure-OpenAI 服务的模型价格表示例。对于每个任务类别，客户可以在特定数据集上微调和评估模型。</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">来源：Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">快速工程和推理</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">即时工程是指如何与 LLM 通信以执行所需任务而无需更新模型权重的有效方法。人工智能模型训练和微调对于 NLP 应用非常重要，推理也同样重要，训练后的模型可以响应用户的提示。推理的系统要求通常更多地取决于 AI 存储系统的读取性能，该系统将数据从 LLM 输送到 GPU，因为它需要能够应用数十亿个存储的模型参数来产生最佳响应。</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps、模型监控和向量存储</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">与传统的机器学习操作 (MLOps) 一样，大型语言模型操作 (LLMOps) 也需要数据科学家和 DevOps 工程师的协作，并使用工具和最佳实践来管理生产环境中的 LLM。然而，法学硕士的工作流程和技术堆栈在某些方面可能会有所不同。例如，使用 LangChain 等框架构建的 LLM 管道将多个 LLM API 调用串联到外部嵌入端点（例如矢量存储或矢量数据库）。嵌入端点和矢量存储作为下游连接器（如矢量数据库）的使用代表了数据存储和访问方式的重大发展。与从头开始开发的传统 ML 模型相比，LLM 通常依赖于迁移学习，因为这些模型从 FM 开始，并使用新数据进行微调以提高在更特定领域的性能。因此，LLMOps 提供风险管理和模型衰减监测功能至关重要。</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">生成人工智能时代的风险与伦理</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">“ChatGPT——虽然很巧妙，但仍然会输出一些无意义的信息。”——《麻省理工科技评论》。垃圾进，垃圾出，一直是计算领域的难题。生成式人工智能的唯一区别在于，它擅长使垃圾变得高度可信，从而导致不准确的结果。法学硕士 (LLM) 倾向于捏造事实来适应其所构建的叙述。因此，那些将生成式人工智能视为利用人工智能降低成本的绝佳机会的公司需要有效地检测深度伪造、减少偏见并降低风险，以保持系统的诚实和道德。在负责任且可解释的生成式人工智能模型的设计中，拥有强大人工智能基础设施的自由流动数据管道至关重要，该管道通过端到端加密和人工智能护栏支持数据移动性、数据质量、数据治理和数据保护。</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">客户场景和NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">图 3：机器学习/大型语言模型工作流程</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*我们是在训练还是在微调？*问题是（a）是否从头开始训练 LLM 模型、微调预先训练的 FM，或使用 RAG 从基础模型之外的文档存储库中检索数据并增强提示，以及（b）是否利用开源 LLM（例如 Llama 2）或专有 FM（例如 ChatGPT、Bard、AWS Bedrock），对于组织来说是一个战略决策。每种方法都需要在成本效率、数据引力、操作、模型准确性和 LLM 管理之间进行权衡。</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp公司在其工作文化以及产品设计和工程工作方法中都采用了人工智能。例如，NetApp 的自主勒索软件防护是使用人工智能和机器学习构建的。它提供文件系统异常的早期检测，以帮助在威胁影响操作之前识别它们。其次， NetApp将预测性 AI 用于其业务运营，例如销售和库存预测，并使用聊天机器人协助客户提供呼叫中心产品支持服务、技术规格、保修、服务手册等。第三， NetApp通过产品和解决方案为 AI 数据管道和 ML/LLM 工作流带来客户价值，帮助客户构建预测性 AI 解决方案，例如需求预测、医学成像、情绪分析和生成性 AI 解决方案，例如用于制造业工业图像异常检测和银行及金融服务中反洗钱和欺诈检测的 GAN ，NetApp NetApp ONTAP 、 NetApp SnapMirror和NetApp FlexCache。</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetApp功能</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">聊天机器人、代码生成、图像生成或基因组模型表达等生成式人工智能应用中的数据移动和管理可以跨越边缘、私有数据中心和混合多云生态系统。例如，一个实时人工智能机器人可以通过 ChatGPT 等预先训练模型的 API 公开的终端用户应用程序帮助乘客将机票升级为商务舱，但由于乘客信息并未在互联网上公开，因此该机器人无法自行完成该任务。该 API 需要访问乘客的个人信息和航空公司的机票信息，这些信息可能存在于混合或多云生态系统中。类似的情况可能适用于科学家通过最终用户应用程序共享药物分子和患者数据，该应用程序使用 LLM 完成涉及一对多生物医学研究机构的药物发现临床试验。传递给 FM 或 LLM 的敏感数据可能包括 PII、财务信息、健康信息、生物特征数据、位置数据、通信数据、在线行为和法律信息。在实时渲染、快速执行和边缘推理的情况下，数据会通过开源或专有 LLM 模型从最终用户应用程序移动到存储端点，再移动到内部数据中心或公共云平台上。在所有这些场景中，数据移动性和数据保护对于依赖大量训练数据集及其移动的 LLM 的 AI 操作至关重要。</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">图 4：生成式 AI - LLM 数据管道</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">图 4：生成式 AI-LLM 数据管道</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">NetApp 的存储基础设施、数据和云服务产品组合由智能数据管理软件提供支持。</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*数据准备*：LLM 技术栈的第一个支柱与旧的传统 ML 栈基本没有变化。人工智能管道中的数据预处理是必要的，以便在训练或微调之前对数据进行规范化和清理。此步骤包括连接器，用于提取位于任何位置的数据，无论数据是以 Amazon S3 层的形式驻留在本地存储系统（例如文件存储或NetApp StorageGRID之类的对象存储）中。</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* 是 NetApp 在数据中心和云端的关键存储解决方案的基础技术。  ONTAP包含各种数据管理和保护特性和功能，包括针对网络攻击的自动勒索软件保护、内置数据传输功能以及适用于本地、混合、NAS、SAN、对象和软件定义存储 (SDS) 等多种架构的存储效率功能。LLM 部署的情况。</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* NetApp ONTAP AI* 用于深度学习模型训练。对于拥有ONTAP存储集群和NVIDIA DGX 计算节点的NetApp客户， NetApp ONTAP支持使用 NFS over RDMA 实现NVIDIA GPU 直接存储。它以经济高效的性能多次读取和处理来自存储的源数据集到内存中以促进智能，使组织能够对 LLM 进行培训、微调和扩展访问。</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* 是一种远程缓存功能，可简化文件分发并仅缓存主动读取的数据。这对于 LLM 训练、再训练和微调非常有用，为具有实时渲染和 LLM 推理等业务需求的客户带来价值。</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror* 是ONTAP 的一项功能，可在任意两个ONTAP系统之间复制卷快照。此功能可以最佳地将边缘数据传输到您的本地数据中心或云端。当客户希望使用包含企业数据的 RAG 在云中开发生成性 AI 时， SnapMirror可用于在本地和超大规模云之间安全高效地移动数据。它有效地仅传输更改，节省带宽并加快复制速度，从而在 FM 或 LLM 的训练、再训练和微调操作期间带来必要的数据移动功能。</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* 为基于ONTAP的存储系统带来不可变磁盘功能，用于数据集版本控制。微核架构旨在通过 FPolicy Zero Trust 引擎保护客户数据。当攻击者以特别耗费资源的方式与 LLM 交互时， NetApp可通过抵御拒绝服务 (DoS) 攻击来确保客户数据可用。</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* 有助于识别、映射和分类企业数据集中的个人信息，制定政策，满足本地或云端的隐私要求，帮助改善安全态势并遵守法规。</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* NetApp BlueXP* 分类，由 Cloud Data Sense 提供支持。客户可以自动扫描、分析、分类和处理数据资产中的数据，检测安全风险，优化存储并加速云部署。它通过统一的控制平面结合了存储和数据服务，客户可以使用 GPU 实例进行计算，并使用混合多云环境进行冷存储分层以及存档和备份。</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* NetApp文件对象二元性*。 NetApp ONTAP支持 NFS 和 S3 的双协议访问。通过此解决方案，客户可以通过NetApp Cloud Volumes ONTAP的 S3 存储桶访问来自 Amazon AWS SageMaker 笔记本的 NFS 数据。这为需要轻松访问异构数据源并能够从 NFS 和 S3 共享数据的客户提供了灵活性。例如，在 SageMaker 上通过访问文件对象存储桶来微调 FM，例如 Meta 的 Llama 2 文本生成模型。</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">* NetApp Cloud Sync* 服务提供了一种简单、安全的方式将数据迁移到云端或本地的任何目标。  Cloud Sync在本地或云存储、NAS 和对象存储之间无缝传输和同步数据。</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* 是一款客户端软件，可实现快速可靠的任意到NetApp和NetApp到NetApp 的数据迁移。  XCP 还提供将批量数据从 Hadoop HDFS 文件系统高效移动到ONTAP NFS、S3 或StorageGRID 的功能，并且 XCP 文件分析可提供文件系统的可见性。</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* 是一个 Python 库，它使数据科学家、DevOps 和数据工程师能够轻松执行各种数据管理任务，例如近乎即时地配置、克隆或快照数据卷或 JupyterLab 工作区，这些任务由高性能横向扩展NetApp存储支持。</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*NetApp 的产品安全*。 LLM 可能会在回答中无意中泄露机密数据，因此研究利用 LLM 的 AI 应用程序相关漏洞的 CISO 对此表示担忧。正如 OWASP（开放式全球应用安全项目）所概述的，数据中毒、数据泄露、拒绝服务和 LLM 中的提示注入等安全问题可能会影响企业，防止数据暴露给未经授权的攻击者。数据存储要求应包括结构化、半结构化和非结构化数据的完整性检查和不可变快照。 NetApp Snapshots 和SnapLock用于数据集版本控制。它带来严格的基于角色的访问控制（RBAC）、安全协议和行业标准加密，以保护静态和传输中的数据。  Cloud Insights和 Cloud Data Sense 共同提供功能，帮助您通过法医手段识别威胁来源并确定需要恢复的数据的优先级。</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* 搭载 DGX BasePOD 的ONTAP AI *</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">采用NVIDIA DGX BasePOD 的NetApp ONTAP AI 参考架构是一种适用于机器学习 (ML) 和人工智能 (AI) 工作负载的可扩展架构。对于 LLM 的关键训练阶段，数据通常会定期从数据存储复制到训练集群中。此阶段使用的服务器使用 GPU 来并行计算，从而产生巨大的数据需求。满足原始 I/O 带宽需求对于维持高 GPU 利用率至关重要。</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* ONTAP AI 与NVIDIA AI Enterprise*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise 是一款端到端、云原生的 AI 和数据分析软件套件，经过NVIDIA优化、认证和支持，可在具有NVIDIA认证系统的 VMware vSphere 上运行。该软件有助于在现代混合云环境中简单、快速地部署、管理和扩展 AI 工作负载。由NetApp和 VMware 提供支持的NVIDIA AI Enterprise 以简化、熟悉的软件包提供企业级 AI 工作负载和数据管理。</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1P云平台*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">完全托管的云存储产品在 Microsoft Azure 上以Azure NetApp Files (ANF) 的形式原生提供，在 AWS 上以Amazon FSx for NetApp ONTAP (FSx ONTAP) 的形式提供，在 Google 上以Google Cloud NetApp Volumes (GNCV ) 的形式提供。  1P 是一种托管的高性能文件系统，使客户能够在公共云中运行高可用性 AI 工作负载并提高数据安全性，以便使用 AWS SageMaker、Azure-OpenAI Services 和 Google 的 Vertex AI 等云原生 ML 平台对 LLM/FM 进行微调。</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetApp合作伙伴解决方案套件</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">除了核心数据产品、技术和功能外， NetApp还与强大的 AI 合作伙伴网络密切合作，为客户带来附加值。</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* 人工智能系统中的NVIDIA Guardrails* 作为保障措施，确保以合乎道德和负责任的方式使用人工智能技术。  AI 开发人员可以选择定义 LLM 驱动的应用程序在特定主题上的行为，并阻止它们参与不想要的话题的讨论。  Guardrails 是一个开源工具包，它能够将 LLM 无缝安全地连接到其他服务，从而构建值得信赖、安全且有保障的 LLM 对话系统。</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* 提供多功能的企业级工具，用于构建和产品化生成式人工智能 - 无论您在人工智能之旅中的哪个阶段，都能快速、安全且经济地实现。借助 Domino 的企业 MLOps 平台，数据科学家可以使用首选工具和所有数据，在任何地方轻松训练和部署模型，并有效地管理风险和成本——所有这些都可以通过一个控制中心完成。</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Modzy 用于 Edge AI*。  NetApp和 Modzy 携手合作，为任何类型的数据（包括图像、音频、文本和表格）提供大规模 AI。  Modzy 是一个用于部署、集成和运行 AI 模型的 MLOps 平台，为数据科学家提供模型监控、漂移检测和可解释性的功能，并提供无缝 LLM 推理的集成解决方案。</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* 和NetApp合作展示了NetApp ONTAP AI 解决方案与 Run:AI 集群管理平台的独特功能，以简化 AI 工作负载的编排。它自动分割和合并 GPU 资源，旨在将您的数据处理管道扩展到数百台机器，并为 Spark、Ray、Dask 和 Rapids 内置集成框架。</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">只有在大量高质量数据上训练模型时，生成式人工智能才能产生有效的结果。虽然 LLM 已经取得了显著的里程碑，但认识到其局限性、设计挑战以及与数据移动性和数据质量相关的风险至关重要。 LLM 依赖于来自异构数据源的大量且不同的训练数据集。模型产生的不准确结果或有偏见的结果可能会使企业和消费者都陷入危险。这些风险可能对应于 LLM 可能因与数据质量、数据安全和数据移动性相关的数据管理挑战而产生的限制。 NetApp帮助组织应对快速数据增长、数据移动性、多云管理和 AI 采用所带来的复杂性。大规模的人工智能基础设施和高效的数据管理对于定义生成人工智能等人工智能应用的成功至关重要。至关重要的是，客户要覆盖所有部署场景，同时又不能影响企业根据需要扩展的能力，同时还要保持成本效益、数据治理和道德的人工智能实践。  NetApp一直致力于帮助客户简化和加速他们的 AI 部署。</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN： NetApp AIPod与联想合作，支持NVIDIA OVX</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">Bobby Oommen、Abhinav Singh、Roney Daniel、 NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">该参考架构将搭载NVIDIA L40S GPU 的NVIDIA认证 OVX Lenovo ThinkSystem 服务器与NVIDIA Spectrum 网络配对，以提供优化和部署 LLM（大型语言模型）的最佳基础设施解决方案。本文档旨在提供与 OVX 配置存储相关的指导。该平台适用于各种生成式人工智能工作负载，包括 RAG（检索增强生成）、微调和轻量级模型训练。</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN：适用于NVIDIA OVX 的NetApp AIPod与联想设计指南</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPod与NVIDIA DGX 系统 - 架构</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX H100 系统 - 解决方案架构</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">本节重点介绍采用NVIDIA DGX 系统的NetApp AIPod的架构。</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">搭载 DGX 系统的NetApp AIPod</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">该参考架构利用单独的结构进行计算集群互连和存储访问，并在计算节点之间实现 400Gb/s InfiniBand (IB) 连接。下图展示了NetApp AIPod与 DGX H100 系统的整体解决方案拓扑。</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">NetApp AIpod 解决方案拓扑</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">网络设计</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">在此配置中，计算集群结构使用一对 QM9700 400Gb/s IB 交换机，它们连接在一起以实现高可用性。每个 DGX H100 系统使用八个连接连接到交换机，其中偶数端口连接到一个交换机，奇数端口连接到另一个交换机。</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">对于存储系统访问、带内管理和客户端访问，使用一对 SN4600 以太网交换机。交换机之间通过交换机间链路连接，并配置多个VLAN来隔离各种流量类型。在特定 VLAN 之间启用基本 L3 路由，以在同一交换机上的客户端和存储接口之间以及交换机之间启用多条路径，从而实现高可用性。对于更大的部署，可以通过根据需要为主干交换机添加额外的交换机对以及为其他叶子交换机添加额外的交换机对，将以太网网络扩展为叶子-主干配置。</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">部署详细信息</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">除了计算互连和高速以太网网络之外，所有物理设备还连接到一个或多个 SN2201 以太网交换机，以进行带外管理。请参阅<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>页面以获取有关网络配置的更多信息。</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">DGX H100 系统的存储访问概述</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">每个 DGX H100 系统都配备了两个双端口 ConnectX-7 适配器用于管理和存储流量，并且对于此解决方案，每个卡上的两个端口都连接到同一个交换机。然后将每个卡的一个端口配置为 LACP MLAG 绑定，并将一个端口连接到每个交换机，并且带内管理、客户端访问和用户级存储访问的 VLAN 都托管在此绑定上。</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">每张卡上的另一个端口用于连接AFF A90存储系统，并且可以根据工作负载要求以多种配置使用。对于使用 NFS over RDMA 来支持NVIDIA Magnum IO GPUDirect Storage 的配置，端口单独使用，并且 IP 地址位于单独的 VLAN 中。对于不需要 RDMA 的部署，存储接口也可以配置 LACP 绑定，以提供高可用性和额外的带宽。无论是否使用 RDMA，客户端都可以使用 NFS v4.1 pNFS 和会话中继挂载存储系统，以实现对集群中所有存储节点的并行访问。请参阅<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>页面以获取有关客户端配置的更多信息。</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePOD 文档</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">有关 DGX H100 系统连接的详细信息，请参阅<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block>。</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">存储系统设计</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">每个AFF A90存储系统使用每个控制器的六个 200 GbE 端口进行连接。每个控制器的四个端口用于从 DGX 系统访问工作负载数据，每个控制器的两个端口配置为 LACP 接口组，以支持从管理平面服务器访问集群管理工件和用户主目录。存储系统的所有数据访问均通过 NFS 提供，其中有一个专用于 AI 工作负载访问的存储虚拟机 (SVM) 和一个专用于集群管理用途的单独 SVM。</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">管理 SVM 只需要一个 LIF，该 LIF 托管在每个控制器上配置的 2 端口接口组上。其他FlexGroup卷在管理 SVM 上进行配置，以容纳集群管理构件，如集群节点映像、系统监控历史数据和最终用户主目录。下图显示了存储系统的逻辑配置。</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">NetApp A90 存储集群逻辑配置</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">管理平面服务器</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">该参考架构还包括五个基于 CPU 的服务器，用于管理平面。其中两个系统用作NVIDIA Base Command Manager 的头节点，用于集群部署和管理。其他三个系统用于提供额外的集群服务，例如 Kubernetes 主节点或利用 Slurm 进行作业调度的部署的登录节点。利用 Kubernetes 的部署可以利用NetApp Trident CSI 驱动程序为AFF A900存储系统上的管理和 AI 工作负载提供具有持久存储的自动配置和数据服务。</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">每台服务器都物理连接到 IB 交换机和以太网交换机，以实现集群部署和管理，并通过管理 SVM 配置 NFS 挂载到存储系统，以存储前面所述的集群管理工件。</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPod与NVIDIA DGX 系统 - 在哪里可以找到更多信息</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX 系统 - 结论及其他信息</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">本节包含有关带有NVIDIA DGX 系统的NetApp AIPod的更多信息的参考。</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">DGX BasePOD 架构是下一代深度学习平台，需要同样先进的存储和数据管理功能。通过将 DGX BasePOD 与NetApp AFF系统相结合， NetApp AIPod与 DGX 系统架构几乎可以在任何规模上实现。结合NetApp ONTAP卓越的云集成和软件定义功能， AFF可为成功的 DL 项目提供涵盖边缘、核心和云的全方位数据管道。</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">追加信息</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">要了解有关本文档中描述的信息的更多信息，请参阅以下文档和/或网站：</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP数据管理软件 — ONTAP信息库</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">NetApp AFF A90存储系统-</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA 信息-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect 存储博客-</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100 系统</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIA 网络连接</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">NVIDIA Magnum IO&amp;#8482; GPUDirect&amp;#174; 存储</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">NVIDIA基本命令</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIA基础命令管理器</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI 企业版</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">本文档由NetApp解决方案和ONTAP工程团队（David Arnette、Olga Kornievskaia、Dustin Fischer、Srikanth Kaligotla、Mohit Kumar 和 Raghuram Sudhaakar）编写。作者还要感谢NVIDIA和NVIDIA DGX BasePOD工程团队的持续支持。</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPod与NVIDIA DGX 系统 - 部署</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX 系统 - 部署详情</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">本节介绍验证此解决方案期间使用的部署细节。使用的 IP 地址仅供参考，请根据部署环境进行修改。有关此配置的实现中使用的特定命令的更多信息，请参阅相应的产品文档。</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">下图显示了 1 个 DGX H100 系统和 1 个 HA 对AFF A90控制器的详细网络和连接信息。以下部分中的部署指南基于此图中的详细信息。</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">NetApp AIpod 网络配置</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">下表显示了最多 16 个 DGX 系统和 2 个AFF A90 HA 对的示例布线分配。</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">交换机和端口</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">设备</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">设备端口</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">交换机1端口1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01 至 -16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0，插槽1端口1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">交换机1端口17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1，插槽1端口2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">交换机1端口33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01 至 -04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">端口 e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">交换机1端口37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">端口 e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">交换机1端口41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">端口 e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">交换机1端口57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL 到交换机 2</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">端口 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">交换机2端口1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0，插槽2端口1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">交换机2端口17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1，插槽 2 端口 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">交换机2端口33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">端口 e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">交换机2端口37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">端口 e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">交换机2端口41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">端口 e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">交换机2端口57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL 到交换机 1</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">下表显示了本次验证中使用的各个组件的软件版本。</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">软件版本</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">NVIDIA SN4600 交换机</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">Cumulus Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">NVIDIA DGX 系统</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX 操作系统 v6.2.1（Ubuntu 22.04 LTS）</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">Mellanox OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24.01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">存储网络配置</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">NVIDIA Cumulus Linux 文档</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">本节概述以太网存储网络配置的关键细节。有关配置 InfiniBand 计算网络的信息，请参阅<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block>。有关交换机配置的详细信息，请参阅<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block>。</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">配置 SN4600 交换机的基本步骤概述如下。此过程假定布线和基本交换机设置（管理 IP 地址、许可等）已完成。</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">配置交换机之间的 ISL 绑定以启用多链路聚合 (MLAG) 和故障转移流量</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">本次验证使用了 8 条链路，为测试的存储配置提供了足够的带宽</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">有关启用 MLAG 的具体说明，请参阅 Cumulus Linux 文档。</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">为两台交换机上的每对客户端端口和存储端口配置 LACP MLAG</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">每个交换机上的端口 swp17 用于 DGX-H100-01（enp170s0f1np1 和 enp41s0f1np1），端口 swp18 用于 DGX-H100-02，等等（bond1-16）</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">每个交换机上的端口 swp41 用于AFF-A90-01（e2a 和 e2b），端口 swp42 用于AFF-A90-02，等等（bond17-20）</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv 设置接口 bondX 债券成员 swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv 设置接口 bondx 绑定 mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">将所有端口和 MLAG 绑定添加到默认桥接域</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv 设置 int swp1-16,33-40 桥接域 br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv 设置 int bond1-20 桥接域 br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">在每台交换机上启用 RoCE</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv 设置 roce 模式无损</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">配置 VLAN - 2 个用于客户端端口，2 个用于存储端口，1 个用于管理，1 个用于 L3 交换机到交换机</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">开关 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">VLAN 3 用于在客户端 NIC 发生故障时进行 L3 交换机到交换机的路由</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">每个 DGX 系统上的存储端口 1 的 VLAN 101（enp170s0f0np0，slot1 端口 1）</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">每个AFF A90存储控制器上的端口 e6a 和 e11a 的 VLAN 102</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">VLAN 301 用于使用 MLAG 接口对每个 DGX 系统和存储控制器进行管理</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">开关 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">每个 DGX 系统上的存储端口 2 的 VLAN 201（enp41s0f0np0，slot2 端口 1）</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">每个AFF A90存储控制器上的端口 e6b 和 e11b 的 VLAN 202</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">根据需要将物理端口分配给每个 VLAN，例如客户端 VLAN 中的客户端端口和存储 VLAN 中的存储端口</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv 设置 int &lt;swpX&gt; 桥接域 br_default 访问 &lt;vlan id&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">MLAG 端口应保持为中继端口，以根据需要在绑定接口上启用多个 VLAN。</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">在每个 VLAN 上配置交换机虚拟接口 (SVI) 以充当网关并启用 L3 路由</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv 设置 int vlan3 ip 地址 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv 设置 int vlan101 ip 地址 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv 设置 int vlan102 ip 地址 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv 设置 int vlan3 ip 地址 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv 设置 int vlan201 ip 地址 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv 设置 int vlan202 ip 地址 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">创建静态路由</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">同一交换机上的子网将自动创建静态路由</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">当客户端链路发生故障时，交换机到交换机的路由需要额外的静态路由</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv 设置 VRF 默认路由器静态 100.127.128.0/17 通过 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv 设置 VRF 默认路由器静态 100.127.0.0/17 通过 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">存储系统配置</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAP 文档</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">本节介绍此解决方案的 A90 存储系统配置的关键细节。有关ONTAP系统配置的更多详细信息，请参阅<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block>。下图显示了存储系统的逻辑配置。</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">配置存储系统的基本步骤概述如下。此过程假设基本存储集群安装已经完成。</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">在每个控制器上配置 1 个聚合，所有可用分区减去 1 个备用分区</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;节点&gt; -aggregate &lt;节点&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">在每个控制器上配置 ifgrps</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">网络端口 ifgrp create -node &lt;节点&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">网络端口 ifgrp add-port -node &lt;节点&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;节点&gt;:e2a,&lt;节点&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">在每个控制器上的 ifgrp 上配置 mgmt vlan 端口</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">网络端口 vlan 创建 -节点 aff-a90-01 -端口 a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">网络端口 vlan 创建 -节点 aff-a90-02 -端口 a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">网络端口 vlan 创建 -节点 aff-a90-03 -端口 a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">网络端口 vlan 创建 -节点 aff-a90-04 -端口 a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">创建广播域</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">广播域创建-广播域vlan21-mtu 9000-端口aff-a90-01：e6a，aff-a90-01：e11a，aff-a90-02：e6a，aff-a90-02：e11a，aff-a90-03：e6a，aff-a90-03：e11a，aff-a90-04：e6a，aff-a90-04：e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">广播域创建-广播域vlan22-mtu 9000-端口aaff-a90-01：e6b，aff-a90-01：e11b，aff-a90-02：e6b，aff-a90-02：e11b，aff-a90-03：e6b，aff-a90-03：e11b，aff-a90-04：e6b，aff-a90-04：e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">广播域创建-广播域vlan31-mtu 9000-端口aff-a90-01:a1a-31，aff-a90-02:a1a-31，aff-a90-03:a1a-31，aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">创建管理 SVM *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">配置管理 SVM</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">创建 LIF</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">创建FlexGroup卷-</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">卷创建-vserver basepod-mgmt-volume home-size 10T-auto-provision-as flexgroup-junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">卷创建-vserver basepod-mgmt-volume cm-size 10T-auto-provision-as flexgroup-junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">制定出口政策</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">导出策略规则创建-vserver basepod-mgmt-policy default-client-match 192.168.31.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">创建数据 SVM *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">配置数据 SVM</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">配置 SVM 以支持 RDMA</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs 修改-vserver basepod-data -rdma 已启用</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">创建 LIF</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create-vserver basepod-data-lif c2-11a-lif2-home-node aff-a90-02-home-port e11a-address 100.127.102.108-netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create-vserver basepod-data-lif c2-11b-lif2-home-node aff-a90-02-home-port e11b-address 100.127.202.108-netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">配置 LIF 以进行 RDMA 访问</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">对于使用ONTAP 9.15.1 的部署，物理信息的 RoCE QoS 配置需要ONTAP CLI 中不可用的操作系统级命令。请联系NetApp支持以获取有关 RoCE 支持端口配置的帮助。  NFS over RDMA 功能正常</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">从ONTAP 9.16.1 开始，物理接口将自动配置适当的设置以实现端到端 RoCE 支持。</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int 修改-vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">在数据 SVM 上配置 NFS 参数</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs 修改 -vserver basepod-data -v4.1 已启用 -v4.1-pnfs 已启用 -v4.1-trunking 已启用 -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">创建FlexGroup卷</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">卷创建-vserver basepod-data-volume数据-size 100T-auto-provision-as flexgroup-junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">创建导出策略</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">导出策略规则创建-vserver basepod-data-policy default-client-match 100.127.101.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">导出策略规则创建-vserver basepod-data-policy default-client-match 100.127.201.0/24-rorule sys-rwrule sys-superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">创建路线</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">路由添加-vserver basepod_data-目的地100.127.0.0/17-网关100.127.102.1度量20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">路由添加-vserver basepod_data-目的地100.127.0.0/17-网关100.127.202.1度量30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">路由添加-vserver basepod_data-目的地100.127.128.0/17-网关100.127.202.1度量20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">路由添加-vserver basepod_data-目的地100.127.128.0/17-网关100.127.102.1度量30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">用于 RoCE 存储访问的 DGX H100 配置</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">BCM 文档</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">本节介绍 DGX H100 系统配置的关键细节。许多配置项可以包含在部署到 DGX 系统的 OS 映像中，或者在启动时由 Base Command Manager 实现。这里列出它们以供参考，有关在 BCM 中配置节点和软件映像的更多信息，请参阅<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block>。</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">安装其他软件包</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">安装 Python 包</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">波罗米科</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">matplotlib</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">软件包安装后重新配置 dpkg</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg——配置-a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">安装 MOFED</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">设置 mst 值以进行性能调整</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; 设置 ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">修改设置后重置适配器</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y 重置</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">在 PCI 设备上设置 MaxReadReq</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">设置 RX 和 TX 环形缓冲区大小</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">使用 mlnx_qos 设置 PFC 和 DSCP</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">为网络端口上的 RoCE 流量设置 ToS</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">echo 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">在适当的子网上为每个存储 NIC 配置一个 IP 地址</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">100.127.101.0/24 用于存储 NIC 1</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">100.127.201.0/24 用于存储 NIC 2</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">配置带内网络端口进行 LACP 绑定（enp170s0f1np1、enp41s0f1np1）</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">为每个存储子网的主路径和次路径配置静态路由</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">路由添加 –net 100.127.0.0/17 gw 100.127.101.1 metric 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">路由添加 –net 100.127.0.0/17 gw 100.127.201.1 公制 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">路由添加 –net 100.127.128.0/17 gw 100.127.201.1 公制 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">路由添加 –net 100.127.128.0/17 gw 100.127.101.1 公制 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">挂载 /home 卷</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">安装-o vers = 3，nconnect = 16，rsize = 262144，wsize = 262144 192.168.31.X：/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">挂载/数据卷</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">安装数据卷时使用了以下安装选项-</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # 启用 pNFS 来并行访问多个存储节点</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # 将传输协议设置为 RDMA，而不是默认的 TCP</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 #启用 NFS 会话中继来聚合存储端口带宽</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # 提高缓冲写入的写入性能</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # 将 I/O 传输大小设置为 256k</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">搭载NVIDIA DGX 系统的NetApp AIPod - 硬件组件</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">搭载NVIDIA DGX 系统的 NVA-1173 NetApp AIPod - 硬件组件</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">本节重点介绍带有NVIDIA DGX 系统的NetApp AIPod的硬件组件。</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFF存储系统</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">NetApp AFF最先进的存储系统使 IT 部门能够通过业界领先的性能、卓越的灵活性、云集成和一流的数据管理来满足企业存储需求。  AFF系统专为闪存设计，有助于加速、管理和保护关键业务数据。</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">AFF A90存储系统</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">由NetApp ONTAP数据管理软件提供支持的NetApp AFF A90提供内置数据保护、可选的反勒索软件功能以及支持最关键业务工作负载所需的高性能和弹性。它消除了对关键任务操作的中断，最大限度地减少了性能调整，并保护您的数据免受勒索软件攻击。它提供：• 行业领先的性能 • 不折不扣的数据安全性 • 简化的无中断升级</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">NetApp AFF A90存储系统</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">行业领先的性能</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">AFF A90可轻松管理深度学习、人工智能和高速分析等下一代工作负载以及 Oracle、SAP HANA、Microsoft SQL Server 和虚拟化应用程序等传统企业数据库。它使关键业务应用程序保持最高速度运行，每个 HA 对高达 2.4M IOPS，延迟低至 100µs，并且性能比以前的NetApp型号提高高达 50%。借助 NFS over RDMA、pNFS 和会话中继，客户可以使用现有的数据中心网络基础设施实现下一代应用程序所需的高水平网络性能。客户还可以通过对 SAN、NAS 和对象存储的统一多协议支持进行扩展和增长，并通过统一的单一ONTAP数据管理软件为本地或云端数据提供最大的灵活性。此外，还可以通过Active IQ和Cloud Insights提供的基于 AI 的预测分析来优化系统健康状况。</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">不妥协的数据安全</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">AFF A90系统包含一整套NetApp集成和应用程序一致的数据保护软件。它提供内置数据保护和尖端反勒索软件解决方案，用于预防和攻击后恢复。可以阻止恶意文件写入磁盘，并且可以轻松监控存储异常以获取洞察。</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">简化的无中断升级</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">对于现有的 A800 客户来说， AFF A90可以作为无中断机箱内升级。 NetApp凭借其先进的可靠性、可用性、可维护性和可管理性 (RASM) 功能，可以轻松更新并消除关键任务操作的中断。此外，由于ONTAP软件会自动为所有系统组件应用固件更新， NetApp进一步提高了运营效率并简化了 IT 团队的日常活动。</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">对于最大的部署， AFF A1K系统提供最高的性能和容量选项，而其他NetApp存储系统（如AFF A70和AFF C800）则以较低的成本为较小的部署提供选项。</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD是由NVIDIA硬件和软件组件、MLOps 解决方案以及第三方存储组成的集成解决方案。利用NVIDIA产品和经过验证的合作伙伴解决方案的横向扩展系统设计最佳实践，客户可以实现高效且易于管理的 AI 开发平台。图 1 突出显示了NVIDIA DGX BasePOD的各个组件。</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">NVIDIA DGX BasePOD 解决方案</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100 系统</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">NVIDIA DGX H100™ 系统是 AI 的强大引擎，由NVIDIA H100 Tensor Core GPU 的突破性性能加速。</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">NVIDIA DGX H100 系统</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">DGX H100 系统的主要规格如下：• 八个NVIDIA H100 GPU。  • 每个 GPU 配备 80 GB GPU 内存，总计 640GB。  • 四个NVIDIA NVSwitch 芯片。  • 双 56 核 Intel Xeon Platinum 8480 处理器，支持 PCIe 5.0。  • 2 TB DDR5 系统内存。  • 四个 OSFP 端口，服务于八个单端口NVIDIA ConnectX™-7（InfiniBand/以太网）适配器和两个双端口NVIDIA ConnectX-7（InfiniBand/以太网）适配器。  • 两个 1.92 TB M.2 NVMe 驱动器用于 DGX OS，八个 3.84 TB U.2 NVMe 驱动器用于存储/缓存。  • 最大功率10.2 kW。 DGX H100 CPU 托盘的后端口如下所示。四个 OSFP 端口为 InfiniBand 计算结构的八个 ConnectX-7 适配器提供服务。每对双端口 ConnectX-7 适配器为存储和管理结构提供并行路径。带外端口用于BMC访问。</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_NVIDIA DGX H100 后面板_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA Quantum-2 QM9700 交换机</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_NVIDIA Quantum-2 QM9700 InfiniBand 交换机_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">具有 400Gb/s InfiniBand 连接的NVIDIA Quantum-2 QM9700 交换机为NVIDIA Quantum-2 InfiniBand BasePOD 配置中的计算结构提供动力。 ConnectX-7 单端口适配器用于 InfiniBand 计算结构。每个NVIDIA DGX 系统与每个 QM9700 交换机都有双重连接，从而在系统之间提供多条高带宽、低延迟路径。</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum-3 SN4600 交换机</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_NVIDIA Spectrum-3 SN4600 交换机_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">NVIDIA Spectrum™-3 SN4600 交换机总共提供 128 个端口（每个交换机 64 个），为 DGX BasePOD 的带内管理提供冗余连接。 NVIDIA SN4600 交换机可以提供 1 GbE 到 200 GbE 之间的速度。对于通过以太网连接的存储设备，也使用NVIDIA SN4600 交换机。  NVIDIA DGX 双端口 ConnectX-7 适配器上的端口用于带内管理和存储连接。</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201 交换机</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">NVIDIA Spectrum SN2201 交换机</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201 交换机提供 48 个端口，可为带外管理提供连接。带外管理为 DGX BasePOD 中的所有组件提供整合的管理连接。</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7 适配器</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_NVIDIA ConnectX-7 适配器_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">NVIDIA ConnectX-7 适配器可提供 25/50/100/200/400G 的吞吐量。  NVIDIA DGX 系统使用单端口和双端口 ConnectX-7 适配器，为具有 400Gb/s InfiniBand 和以太网的 DGX BasePOD 部署提供灵活性。</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">采用NVIDIA DGX 系统的NetApp AIPod是一种企业级参考架构，基于NVIDIA BasePOD，用于深度学习和人工智能，使用NetApp ONTAP AFF存储系统以及NVIDIA网络和 DGX 系统。</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX 系统 - 简介</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,错误：缺少图形图像</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetApp解决方案工程</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">NetApp™ AIPod配备NVIDIA DGX™ 系统和NetApp云连接存储系统，通过消除设计复杂性和猜测，简化了机器学习 (ML) 和人工智能 (AI) 工作负载的基础设施部署。基于NVIDIA DGX BasePOD™ 设计，旨在为下一代工作负载提供卓越的计算性能，搭载NVIDIA DGX 系统的AIPod增加了NetApp AFF存储系统，使客户能够从小规模开始并无中断地发展，同时智能地管理从边缘到核心再到云端的数据。  NetApp AIPod是NetApp AI 解决方案产品组合的一部分，如下图所示。</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_NetApp 人工智能解决方案组合_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">本文档描述了AIPod参考架构的关键组件、系统连接和配置信息、验证测试结果和解决方案规模指导。本文档适用于有兴趣为 ML/DL 和分析工作负载部署高性能基础架构的NetApp和合作伙伴解决方案工程师以及客户战略决策者。</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPod与NVIDIA DGX 系统 - 软件组件</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX 系统 - 软件组件</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">本节重点介绍带有NVIDIA DGX 系统的NetApp AIPod的软件组件。</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIA软件</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command™ 为每个 DGX BasePOD 提供支持，使组织能够充分利用NVIDIA软件创新的最佳成果。企业可以通过经过验证的平台充分发挥其投资潜力，该平台包括企业级编排和集群管理、加速计算、存储和网络基础设施的库以及针对 AI 工作负载优化的操作系统 (OS)。</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_NVIDIA BaseCommand 解决方案_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU 云 (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC 提供的软件可以满足具有不同 AI 专业水平的数据科学家、开发人员和研究人员的需求。 NGC 上托管的软件会针对一组常见漏洞和暴露 (CVE)、加密和私钥进行扫描。它经过测试和设计，可扩展到多个 GPU，在许多情况下，可扩展到多节点，确保用户最大限度地利用其在 DGX 系统上的投资。</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU 云_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise 是一个端到端软件平台，可让每个企业都能够使用生成式 AI，为在NVIDIA DGX 平台上优化的生成式 AI 基础模型提供最快、最高效的运行时。凭借生产级的安全性、稳定性和可管理性，它简化了生成式 AI 解决方案的开发。  NVIDIA AI Enterprise 包含在 DGX BasePOD 中，企业开发人员可以访问预训练模型、优化框架、微服务、加速库和企业支持。</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetApp 软件</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">ONTAP 9 是NetApp最新一代存储管理软件，它支持企业实现基础架构现代化并过渡到云就绪数据中心。 ONTAP利用业界领先的数据管理功能，只需一套工具即可管理和保护数据，无论数据位于何处。您还可以将数据自由移动到任何需要的地方：边缘、核心或云端。  ONTAP 9 包含众多功能，可简化数据管理、加速和保护关键数据，并支持跨混合云架构的下一代基础架构功能。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">加速并保护数据</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP提供卓越级别的性能和数据保护，并通过以下方式扩展这些功能：</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">性能和更低的延迟。  ONTAP以最低的延迟提供最高的吞吐量，包括支持使用 NFS over RDMA、并行 NFS (pNFS) 和 NFS 会话中继的NVIDIA GPUDirect Storage (GDS)。</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">数据保护。ONTAP提供内置数据保护功能和业界最强大的反勒索软件保障，并在所有平台上实现通用管理。</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp卷加密 (NVE)。  ONTAP提供原生卷级加密，同时支持板载和外部密钥管理。</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">存储多租户和多因素身份验证。  ONTAP支持以最高级别的安全性共享基础设施资源。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">简化数据管理</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">数据管理对于企业 IT 运营和数据科学家至关重要，以便将适当的资源用于 AI 应用程序和训练 AI/ML 数据集。以下有关NetApp技术的附加信息超出了本次验证的范围，但可能与您的部署相关。</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP数据管理软件包括以下功能，可简化操作并降低总运营成本：</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">快照和克隆支持 ML/DL 工作流的协作、并行实验和增强数据治理。</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror可在混合云和多站点环境中实现无缝数据移动，并在需要的时间和地点提供数据。</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">内联数据压缩和扩展重复数据删除。数据压缩减少了存储块内部浪费的空间，重复数据删除显著增加了有效容量。这适用于本地存储的数据和分层到云的数据。</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">最小、最大和自适应服务质量 (AQoS)。细粒度的服务质量 (QoS) 控制有助于维持高度共享环境中关键应用程序的性能水平。</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups 支持在存储集群中的所有节点上分布数据，为超大数据集提供巨大的容量和更高的性能。</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598： FabricPool最佳实践</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool。提供冷数据自动分层到公共和私有云存储选项，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID存储解决方案。有关FabricPool的更多信息，请参阅<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>。</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache。提供远程卷缓存功能，可简化文件分发、减少 WAN 延迟并降低 WAN 带宽成本。  FlexCache支持跨多个站点的分布式产品开发，以及从远程位置加速访问公司数据集。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">面向未来的基础设施</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP具有以下功能，可帮助满足苛刻且不断变化的业务需求：</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">无缝扩展和无中断操作。 ONTAP支持在线向现有控制器和横向扩展集群添加容量。客户可以升级到最新技术，例如 NVMe 和 32Gb FC，而无需昂贵的数据迁移或中断。</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">云连接。  ONTAP是与云连接最紧密的存储管理软件，在所有公共云中均提供软件定义存储（ONTAP Select）和云原生实例（Google Cloud NetApp Volumes）的选项。</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">与新兴应用程序的集成。  ONTAP使用支持现有企业应用的相同基础架构，为下一代平台和应用（如自动驾驶汽车、智能城市和工业 4.0）提供企业级数据服务。</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit 是一款基于 Python 的工具，可简化由高性能、横向扩展NetApp存储支持的开发/培训工作区和推理服务器的管理。 DataOps Toolkit 可以作为独立实用程序运行，并且在利用NetApp Trident自动化存储操作的 Kubernetes 环境中更加有效。主要功能包括：</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">快速配置由高性能、横向扩展NetApp存储支持的新的高容量 JupyterLab 工作区。</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">快速配置由企业级NetApp存储支持的全新NVIDIA Triton 推理服务器实例。</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">近乎即时地克隆高容量的 JupyterLab 工作区，以实现实验或快速迭代。</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">用于备份和/或可追溯性/基准的高容量 JupyterLab 工作区的近乎即时的快照。</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">近乎即时地配置、克隆和快照高容量、高性能数据卷。</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident是一个完全受支持的开源存储编排器，适用于容器和 Kubernetes 发行版（包括 Anthos）。Trident可与整个NetApp存储产品组合配合使用，包括NetApp ONTAP，并且还支持 NFS、NVMe/TCP 和 iSCSI 连接。Trident允许最终用户从其NetApp存储系统配置和管理存储，而无需存储管理员的干预，从而加速 DevOps 工作流程。</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPod与NVIDIA DGX 系统 - 解决方案验证和规模调整指南</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPod与NVIDIA DGX 系统 - 解决方案验证和规模调整指南</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">本节重点介绍采用NVIDIA DGX 系统的NetApp AIPod的解决方案验证和尺寸调整指导。</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">解决方案验证</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">使用开源工具 FIO 通过一系列合成工作负载验证了此解决方案中的存储配置。这些测试包括读写 I/O 模式，旨在模拟执行深度学习训练作业的 DGX 系统产生的存储工作负载。使用同时运行 FIO 工作负载的 2 插槽 CPU 服务器集群来验证存储配置，以模拟 DGX 系统集群。每个客户端都配置了前面描述的相同网络配置，并添加了以下详细信息。</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">以下安装选项用于此验证：</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">版本=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">启用 pNFS 来并行访问多个存储节点</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">原型=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">将传输协议设置为 RDMA，而不是默认的 TCP</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">端口=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">为 RDMA NFS 服务指定正确的端口</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">最大连接数=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">启用 NFS 会话中继来聚合存储端口带宽</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">写=渴望</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">提高缓冲写入的写入性能</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144,wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">将 I/O 传输大小设置为 256k</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">此外，客户端的 NFS max_session_slots 值配置为 1024。由于该解决方案是使用 NFS over RDMA 进行测试的，因此存储网络端口配置了主动/被动结合。本次验证使用了以下债券参数：</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">模式=主动备份</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">将绑定设置为主动/被动模式</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;接口名称&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">所有客户端的主接口分布在交换机上</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-监控间隔=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">指定监控间隔为100ms</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">故障转移 mac 策略=活动</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">指定活动链路的 MAC 地址是绑定的 MAC。这是 RDMA 通过绑定接口正确运行所必需的。</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">存储系统配置如下，包括两个 A900 HA 对（4 个控制器），每个 HA 对连接两个 NS224 磁盘架，每个磁盘架有 24 个 1.9TB NVMe 磁盘驱动器。如架构部分所述，所有控制器的存储容量使用FlexGroup卷进行组合，并且所有客户端的数据分布在集群中的所有控制器上。</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">存储系统规模指南</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp已成功完成 DGX BasePOD 认证，经测试的两个 A90 HA 对可以轻松支持由 16 个 DGX H100 系统组成的集群。对于具有更高存储性能要求的大型部署，可以将额外的AFF系统添加到NetApp ONTAP集群中，单个集群中最多可包含 12 个 HA 对（24 个节点）。使用本解决方案中描述的FlexGroup技术，24 节点集群可以在单个命名空间中提供超过 79 PB 和高达 552 GBps 的吞吐量。其他NetApp存储系统（例如AFF A400、A250 和 C800）以较低的成本为较小规模的部署提供较低的性能和/或更高的容量选项。由于ONTAP 9 支持混合模型集群，客户可以从较小的初始占用空间开始，并随着容量和性能需求的增长向集群添加更多或更大的存储系统。下表粗略估计了每个AFF型号支持的 A100 和 H100 GPU 的数量。</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">NetApp 存储系统规模调整指南</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">NetApp上的 BeeGFS 与 E 系列存储</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">NetApp上带有 E 系列存储的 BeeGFS 是一种经过验证的集成解决方案，具有简单、可靠、可扩展且经济高效的 HPC 基础架构，可满足您最极端的工作负载的需要。</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY：Quantum StorNext 与NetApp E 系列系统部署指南</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">NetApp的 Ryan Rodine</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">本文档详细介绍了如何使用NetApp E 系列存储系统部署 StorNext 并行文件系统解决方案。该解决方案涵盖NetApp EF280 全闪存阵列、 NetApp EF300 全闪存 NVMe 阵列、 NetApp EF600 全闪存 NVMe 阵列和NetApp E5760 混合系统。它提供基于 Frametest 基准测试的性能表征，Frametest 是一种广泛用于媒体和娱乐行业测试的工具。</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN：Quantum StorNext 与NetApp E 系列系统设计指南</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">本文档详细介绍了如何使用NetApp E 系列存储系统设计 StorNext 并行文件系统解决方案。该解决方案涵盖NetApp EF280 全闪存阵列、 NetApp EF300 全闪存 NVMe 阵列、EF600 全闪存 NVMe 阵列和NetApp E5760 混合系统。它提供基于 Frametest 基准测试的性能表征，Frametest 是一种广泛用于媒体和娱乐行业测试的工具。</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859：使用NetApp E 系列存储部署 IBM Spectrum Scale - 安装和验证</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">NetApp的 Chris Seirer</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 描述了基于 IBM 的 Spectrum Scale 软件堆栈部署完整并行文件系统解决方案的过程。  TR-4859 旨在提供有关如何安装 Spectrum Scale、验证基础设施和管理配置的详细信息。</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">此NetApp验证架构描述了带有NetApp BeeGFS 构建块的NVIDIA DGX SuperPOD的设计。该解决方案是一个全栈数据中心平台，已在NVIDIA的专用验收集群上经过验证。</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPOD与NetApp - 设计指南</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">此NetApp验证架构描述了带有NetApp BeeGFS 构建块的NVIDIA DGX SuperPOD的设计。该解决方案是一个全栈数据中心平台，在NVIDIA的专用验收集群上进行了验证。</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200,200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">NetApp 的Amine Bennani、Christian Whiteside、David Arnette 和 Sathish Thyagarajan</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">内容提要</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">在当今快速发展的技术格局中，人工智能正在彻底改变消费者体验并推动各行各业的创新。然而，这也给 IT 部门带来了巨大的挑战，他们面临着部署能够处理 AI 工作负载的强烈需求的高性能计算 (HPC) 解决方案的压力。随着各组织竞相利用人工智能的力量，对易于部署、扩展和管理的解决方案的需求也日益迫切。</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD是一个 AI 数据中心基础设施平台，作为 IT 的交钥匙解决方案提供，以支持当今企业面临的最复杂的 AI 工作负载。任何精确的深度学习 (DL) 模型的核心都是大量数据，需要能够高效提供和重新提供这些数据的高吞吐量存储解决方案。  NetApp BeeGFS 解决方案由带有 BeeGFS 并行文件系统的NetApp EF600 存储阵列组成，使NVIDIA DGX SuperPOD能够充分发挥其功能。 NetApp BeeGFS 解决方案已通过NVIDIA验证，可与 SuperPOD 架构集成和扩展。其结果是简化了 AI 数据中心的部署和管理，同时提供了几乎无限的性能和容量可扩展性。</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">NetApp BeeGFS 解决方案由高性能NetApp EF600 NVMe 存储系统和可扩展的 BeeGFS 并行文件系统提供支持，为要求苛刻的 AI 工作负载提供了强大而高效的存储基础。其共享磁盘架构确保高可用性，即使面临系统挑战也能保持一致的性能和可访问性。该解决方案提供了可扩展且灵活的架构，可以定制以满足不同的存储需求。客户可以通过集成额外的存储构建块来轻松扩展其存储性能和容量，以处理最苛刻的工作负载。</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD利用 DGX H100 和 H200 系统以及经过验证的外部连接共享存储：</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">每个 DGX SuperPOD 可扩展单元 (SU) 由 32 个 DGX 系统组成，能够以 FP8 精度实现 640 petaFLOPS 的 AI 性能。  NetApp建议为单个 DGX SuperPOD 配置使用至少 2 个构建块来调整NetApp BeeGFS 存储解决方案的大小。</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_解决方案的高层视图_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">该图显示了采用NVIDIA DGX SuperPOD的NetApp BeeGFS 解决方案的高级概览。</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">NetApp BeeGFS 构建块由两个NetApp EF600 阵列和两台 x86 服务器组成：</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">借助以NVIDIA DGX SuperPOD为基础的NetApp EF600 全闪存阵列，客户可以获得可靠的存储基础，并享有 6 个 9 的正常运行时间。</block>
  <block id="23830778b135794055062035d895d122" category="list-text">NetApp EF600 和NVIDIA DGX 系统之间的文件系统层是 BeeGFS 并行文件系统。 BeeGFS 由德国弗劳恩霍夫高性能计算中心创建，旨在解决传统并行文件系统的痛点。其结果是一个具有现代用户空间架构的文件系统，现在由 ThinkParQ 开发和交付，并被许多超级计算环境使用。</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">NetApp对 BeeGFS 的支持使 NetApp 优秀的支持组织与客户对性能和正常运行时间的要求保持一致。客户可以获得优质的支持资源、提前获得 BeeGFS 版本，以及使用部分 BeeGFS 企业功能，例如配额实施和高可用性 (HA)。</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">NVIDIA SuperPOD SU 和NetApp BeeGFS 构建块的结合提供了一种敏捷的 AI 解决方案，其中计算或存储可以轻松无缝地扩展。</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">NetApp BeeGFS 构建块</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">图中显示了单个NetApp BeeGFS 构建块。</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">使用情形概要</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">此解决方案适用于以下用例：</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">人工智能（AI）包括机器学习（ML）、深度学习（DL）、自然语言处理（NLP）、自然语言理解（NLU）和生成人工智能（GenAI）。</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">中大规模人工智能训练</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">计算机视觉、语音、音频和语言模型</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">HPC，包括通过消息传递接口 (MPI) 和其他分布式计算技术加速的应用程序</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">应用程序工作负载具有以下特点：</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">读取或写入大于 1GB 的文件</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">多个客户端（10 个、100 个和 1000 个）读取或写入同一文件</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">多 TB 或多 PB 数据集</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">需要针对大文件和小文件混合进行优化的单一存储命名空间的环境</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">本节介绍采用NetApp解决方案的NVIDIA DGX SuperPOD的技术要求。</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">NVIDIA DGX H100 SuperPOD 参考架构</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN： NetApp NVA 上的 BeeGFS 设计</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">下表 1 列出了为单个 SU 实施解决方案所需的硬件组件。解决方案规模从 32 个NVIDIA DGX H100 系统和两个或三个NetApp BeeGFS 构建块开始。单个NetApp BeeGFS 构建块由两个NetApp EF600 阵列和两台 x86 服务器组成。随着部署规模的增加，客户可以添加额外的构建块。有关详细信息，请参阅<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block>和<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block>。</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 或 H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">NVIDIA Quantum QM9700 交换机</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8 片叶子，4 根脊柱</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">NetApp BeeGFS 构建块</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">下表 2 列出了实施该解决方案所需的软件组件。解决方案的任何特定实施中使用的软件组件可能会根据客户要求而有所不同。</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">NVIDIA DGX 软件堆栈</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">ThinkParQ BeeGFS并行文件系统</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">解决方案验证</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD： NetApp EF600 和 BeeGFS 参考架构</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NVIDIA DGX SuperPOD与NetApp通过使用NetApp BeeGFS 构建块在NVIDIA的专用验收集群上进行了验证。验收标准基于NVIDIA执行的一系列应用程序、性能和压力测试。有关详细信息，请参阅<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block>。</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp和NVIDIA有着长期的合作，致力于向市场提供一系列 AI 解决方案。 NVIDIA DGX SuperPOD与NetApp EF600 全闪存阵列相结合，是经过验证的解决方案，客户可以放心部署。这种完全集成的交钥匙架构消除了部署风险，使任何人都可以走上赢得人工智能领导地位的道路。</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">NVIDIA DGX SuperPOD参考架构</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">NVIDIA DGX SuperPOD数据中心设计参考指南</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD： NetApp EF600 和 BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">人工智能驱动的自动化和边缘计算是帮助商业组织实现数字化转型并最大限度提高运营效率和安全性的领先方法。通过边缘计算，数据处理速度更快，因为它不必往返于数据中心。因此，与数据中心或云端来回发送数据相关的成本就会降低。</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">人工智能驱动的自动化和边缘计算是帮助商业组织实现数字化转型并最大限度提高运营效率和安全性的领先方法。通过边缘计算，数据处理速度更快，因为它不必往返于数据中心。因此，与数据中心或云端来回发送数据相关的成本就会降低。当企业必须使用部署在边缘的人工智能推理模型近乎实时地做出决策时，更低的延迟和更高的速度会很有帮助。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp存储系统提供与本地 SSD 存储相同或更好的性能，并为数据科学家、数据工程师、AI/ML 开发人员以及业务或 IT 决策者提供以下优势：</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">在人工智能系统、分析系统和其他关键业务系统之间轻松共享数据。这种数据共享减少了基础设施开销，提高了性能，并简化了整个企业的数据管理。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">独立可扩展的计算和存储，以最大限度地降低成本并提高资源利用率。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">使用集成的 Snapshot 副本和克隆来简化开发和部署工作流程，以实现即时且节省空间的用户工作区、集成版本控制和自动部署。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">实现灾难恢复和业务连续性的企业级数据保护。本文档中介绍的NetApp和联想解决方案是一种灵活的横向扩展架构，非常适合边缘企业级 AI 推理部署。</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">声明</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">俊杰Falkanger，联想 HPC 和人工智能解决方案高级经理</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">NetApp技术营销工程师 Dave Arnette</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell， NetApp E 系列 AI 解决方案技术主管</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman， NetApp质量保证工程师</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">要了解有关本文档中描述的信息的更多信息，请参阅以下文档和/或网站：</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A系列阵列产品页面</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP数据管理软件 - ONTAP 9 信息库</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727： NetApp EF系列简介</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E系列SANtricity软件数据表</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetApp容器持久存储 — NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 基准测试</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">联想 ThinkSystem SE350 边缘服务器</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">联想 ThinkSystem DM5100F 统一闪存存储阵列</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">本节介绍测试的配置、网络基础设施、SE350 服务器和存储配置详细信息。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">测试配置</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">下图显示了测试配置。我们使用了NetApp AFF C190存储系统和两台 Lenovo ThinkSystem SE350 服务器（每台配备一个NVIDIA T4 加速器）。这些组件通过 10GbE 网络交换机连接。网络存储保存验证/测试数据集和预训练模型。服务器提供计算能力，并通过 NFS 协议访问存储。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">本节介绍测试的配置、网络基础设施、SE350 服务器和存储配置详细信息。下表列出了解决方案架构的基本组件。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">联想 ThinkSystem 服务器</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">2 台 SE350 服务器，每台配备一张NVIDIA T4 GPU 卡</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">每台服务器包含一个 Intel Xeon D-2123IT CPU，该 CPU 具有四个物理核心，运行频率为 2.20GHz，并配备 128GB RAM</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">入门级NetApp AFF存储系统（HA 对）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 软件</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24个960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 协议</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">每个控制器一个接口组，具有四个用于挂载点的逻辑 IP 地址</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">下表列出了存储配置： AFF C190 ，24 个驱动器插槽。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">控制器</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">聚合</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup 卷</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">聚合尺寸</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">体积大小</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">操作系统挂载点</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg 文件夹包含用于模型验证的数据集。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">下图显示了测试配置。我们使用了NetApp EF280 存储系统和两台 Lenovo ThinkSystem SE350 服务器（每台配备一个NVIDIA T4 加速器）。这些组件通过 10GbE 网络交换机连接。网络存储保存验证/测试数据集和预训练模型。服务器提供计算能力，并通过 NFS 协议访问存储。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">下表列出了 EF280 的存储配置。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">卷组</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">卷</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDP大小</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">连接方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">卷 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1 到 iSCSI LUN 0</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">卷 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2 到 iSCSI LUN 1</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">本文档介绍了一种计算和存储架构，用于在满足新兴应用场景的边缘环境中在NetApp存储控制器和 Lenovo ThinkSystem 服务器上部署基于 GPU 的人工智能 (AI) 推理。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886：边缘 AI 推理 - NetApp与联想 ThinkSystem - 解决方案设计</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan， NetApp Miroslav Hodak，联想</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">摘要</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">高级驾驶辅助系统 (ADAS)、工业 4.0、智能城市和物联网 (IoT) 等一些新兴应用场景需要在接近零延迟的情况下处理连续数据流。本文档介绍了一种计算和存储架构，用于在满足这些要求的边缘环境中的NetApp存储控制器和 Lenovo ThinkSystem 服务器上部署基于 GPU 的人工智能 (AI) 推理。本文档还提供了行业标准 MLPerf 推理基准的性能数据，评估了配备NVIDIA T4 GPU 的边缘服务器上的各种推理任务。我们研究了离线、单流和多流推理场景的性能，并表明具有经济高效的共享网络存储系统的架构性能高，并为多个边缘服务器的数据和模型管理提供了中心点。</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">越来越多的公司在网络边缘生成大量数据。为了从智能传感器和物联网数据中获得最大价值，组织正在寻找能够实现边缘计算的实时事件流解决方案。因此，计算要求高的工作越来越多地在数据中心之外的边缘执行。人工智能推理是这一趋势的驱动因素之一。边缘服务器为这些工作负载提供了足够的计算能力，尤其是在使用加速器时，但有限的存储空间通常是一个问题，尤其是在多服务器环境中。在本文档中，我们展示了如何在边缘环境中部署共享存储系统，以及它如何在不影响性能的情况下使 AI 推理工作负载受益。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">本文档描述了边缘 AI 推理的参考架构。它将多台联想 ThinkSystem 边缘服务器与NetApp存储系统相结合，创建易于部署和管理的解决方案。它旨在成为各种情况下实际部署的基准指南，例如具有多个摄像头和工业传感器的工厂车间、零售交易中的销售点 (POS) 系统或识别自动驾驶汽车视觉异常的全自动驾驶 (FSD) 系统。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">本文档涵盖由 Lenovo ThinkSystem SE350 Edge 服务器和入门级NetApp AFF和 EF 系列存储系统组成的计算和存储配置的测试和验证。参考架构为 AI 部署提供了高效且经济的解决方案，同时还通过NetApp ONTAP和NetApp SANtricity数据管理软件提供全面的数据服务、集成数据保护、无缝可扩展性和云连接数据存储。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">本文档适用于以下受众：</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">希望将边缘 AI 产品化的商业领袖和企业架构师。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">数据科学家、数据工程师、人工智能/机器学习 (ML) 研究人员和人工智能系统开发人员。</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">为 AI/ML 模型和应用程序的开发设计解决方案的企业架构师。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">数据科学家和人工智能工程师正在寻找部署深度学习 (DL) 和 ML 模型的有效方法。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">负责边缘推理模型的部署和管理的边缘设备管理员和边缘服务器管理员。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">解决方案架构</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">这款联想 ThinkSystem 服务器和NetApp ONTAP或NetApp SANtricity存储解决方案旨在利用 GPU 和传统 CPU 的处理能力来处理大型数据集上的 AI 推理。此验证展示了高性能和最佳数据管理，其架构使用单个或多个 Lenovo SR350 边缘服务器与单个NetApp AFF存储系统互连，如以下两图所示。</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">下图中的逻辑架构概览展示了此架构中计算和存储元素的角色。具体来说，它显示了以下内容：</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">边缘计算设备对从摄像头、传感器等接收的数据进行推理。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">具有多种用途的共享存储元素：</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">为推理模型和执行推理所需的其他数据提供一个中心位置。计算服务器直接访问存储并通过网络使用推理模型，而无需在本地复制它们。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">更新的模型推送到这里。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">将边缘服务器接收的输入数据存档以供日后分析。例如，如果边缘设备连接到摄像机，则存储元件会保存摄像机捕获的视频。</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">红色的</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">蓝色的</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">联想计算系统</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF存储系统</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">边缘设备对来自摄像头、传感器等的输入进行推理。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">共享存储保存推理模型和来自边缘设备的数据以供后续分析。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">NetApp和联想的解决方案具有以下主要优势：</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">边缘 GPU 加速计算。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">部署由共享存储支持和管理的多个边缘服务器。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">强大的数据保护，满足低恢复点目标 (RPO) 和恢复时间目标 (RTO)，且不会丢失数据。</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">使用NetApp Snapshot 副本和克隆优化数据管理，以简化开发工作流程。</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">如何使用此架构</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">本文档验证了所提出的架构的设计和性能。但是，我们还没有测试某些软件级别的部分，例如容器、工作负载或模型管理以及与云或数据中心内部的数据同步，因为它们特定于部署场景。这里存在多种选择。</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">NetApp AI 控制平面</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">在容器管理层面，Kubernetes 容器管理是一个不错的选择，无论是完全上游版本（Canonical）还是适合企业部署的修改版本（Red Hat）都得到了很好的支持。这<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block>它采用NetApp Trident和新添加的<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block>为数据科学家和数据工程师提供内置可追溯性、数据管理功能、接口和工具，以便与NetApp存储集成。 Kubeflow 是 Kubernetes 的 ML 工具包，它提供了额外的 AI 功能，并在 TensorFlow Serving 或NVIDIA Triton Inference Server 等多个平台上支持模型版本控制和 KFServing。另一个选择是NVIDIA EGX 平台，它提供工作负载管理以及对支持 GPU 的 AI 推理容器目录的访问。然而，这些选项可能需要付出大量努力和专业知识才能投入生产，并且可能需要第三方独立软件供应商 (ISV) 或顾问的协助。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">解决方案领域</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推理和边缘计算的主要优势在于设备能够高质量且无延迟地计算、处理和分析数据。本文档中描述了太多边缘计算用例的示例，但以下是一些突出的示例：</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">汽车：自动驾驶汽车</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">经典的边缘计算例证是自动驾驶汽车（AV）中的高级驾驶辅助系统（ADAS）。无人驾驶汽车中的人工智能必须快速处理来自摄像头和传感器的大量数据才能成为成功的安全驾驶员。花费太长时间来解读物体和人之间的区别可能意味着生死，因此能够尽可能靠近车辆处理数据至关重要。在这种情况下，一个或多个边缘计算服务器处理来自摄像机、雷达、激光雷达和其他传感器的输入，而共享存储保存推理模型并存储来自传感器的输入数据。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">医疗保健：患者监护</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">人工智能和边缘计算的最大影响之一是它能够增强对家庭护理和重症监护病房 (ICU) 中慢性病患者的持续监测。监测胰岛素水平、呼吸、神经活动、心律和胃肠功能的边缘设备的数据需要进行即时分析，并且必须立即采取行动，因为采取行动来挽救生命的时间有限。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">零售：无收银员支付</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">边缘计算可以为人工智能和机器学习提供支持，帮助零售商减少结账时间并增加客流量。无收银系统支持各种组件，例如：</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">身份验证和访问。将实体购物者连接到已验证的帐户并允许进入零售空间。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">库存监控。使用传感器、RFID 标签和计算机视觉系统来帮助购物者确认选择或取消选择商品。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">在这里，每个边缘服务器处理每个结账柜台，共享存储系统作为中央同步点。</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融服务：自助服务终端的人员安全和欺诈预防</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">银行机构正在使用人工智能和边缘计算来创新和创造个性化的银行体验。使用实时数据分析和人工智能推理的交互式自助服务终端现在不仅能够让 ATM 机帮助客户取款，还能通过摄像头捕获的图像主动监控自助服务终端，以识别对人类安全的风险或欺诈行为。在这个场景中，边缘计算服务器和共享存储系统连接到交互式信息亭和摄像头，帮助银行使用人工智能推理模型收集和处理数据。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">制造业：工业4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">第四次工业革命（工业 4.0）已经开始，同时还出现了智能工厂和 3D 打印等新兴趋势。为了迎接数据主导的未来，大规模机器对机器 (M2M) 通信和物联网被集成在一起，以提高自动化程度，而无需人工干预。制造业已经高度自动化，添加人工智能功能是长期趋势的自然延续。人工智能可以实现自动化操作，这些操作可以借助计算机视觉和其他人工智能功能实现。您可以自动化质量控制或依赖人类视觉或决策的任务，以便对工厂车间装配线上的材料进行更快的分析，帮助制造工厂满足所需的 ISO 安全和质量管理标准。在这里，每个计算边缘服务器都连接到监控制造过程的传感器阵列，并根据需要将更新的推理模型推送到共享存储。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">电信：锈蚀检测、塔台检查和网络优化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">电信行业使用计算机视觉和人工智能技术处理图像，自动检测锈蚀并识别含有腐蚀并因此需要进一步检查的手机信号塔。近年来，使用无人机图像和人工智能模型来识别塔的不同区域以分析锈蚀、表面裂纹和腐蚀的情况越来越多。人们对人工智能技术的需求持续增长，这些技术可以高效地检查电信基础设施和手机信号塔，定期评估其性能是否下降，并在需要时及时修复。</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">此外，电信领域的另一个新兴用例是使用人工智能和机器学习算法来预测数据流量模式、检测支持 5G 的设备以及自动化和增强多输入多输出 (MIMO) 能源管理。无线电塔使用 MIMO 硬件来增加网络容量；然而，这会带来额外的能源成本。部署在蜂窝基站的“MIMO 睡眠模式”的 ML 模型可以预测无线电的有效使用情况，并有助于降低移动网络运营商 (MNO) 的能源消耗成本。人工智能推理和边缘计算解决方案可帮助 MNO 减少往返于数据中心的数据量、降低 TCO、优化网络运营并提高最终用户的整体性能。</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">本文档遵循 MLPerf Inference v0.7 代码、MLPerf Inference v1.1 代码和规则。我们运行了专为边缘推理而设计的基准测试，如本节表格中所定义。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">测试计划</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">代码</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">规则</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">本文档遵循 MLPerf Inference v0.7<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> ，MLPerf 推理 v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> ， 和<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。我们运行了专为边缘推理而设计的 MLPerf 基准，如下表所定义。</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">区域</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">型号</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">数据集</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL 大小</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">质量</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">多流延迟约束</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">想象</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">图像分类</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">图像网（224x224）</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32 的 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50毫秒</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">物体检测（大）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">可可 (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66毫秒</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">物体检测（小）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD-MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">可可 (300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">医学图像分割</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">BraTS 2019（224x224x160）</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32 的 99% 和 99.9%</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">演讲</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">语音转文本</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech dev-clean</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">语言</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">语言处理</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">下表列出了 Edge 基准测试场景。</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">场景</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">图像分类</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">单流、离线、多流</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">单流、离线</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">语音转文本</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">我们使用本次验证中开发的网络存储架构执行了这些基准测试，并将结果与之前提交给 MLPerf 的边缘服务器上的本地运行结果进行了比较。比较是为了确定共享存储对推理性能有多大的影响。</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">本节介绍用于验证该解决方案的测试程序。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">测试程序</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">操作系统和 AI 推理设置</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">对于AFF C190，我们使用了带有NVIDIA驱动程序的 Ubuntu 18.04 和支持NVIDIA GPU 的 docker，并使用了 MLPerf<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>作为联想向 MLPerf Inference v0.7 提交的一部分提供。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">对于 EF280，我们使用了带有NVIDIA驱动程序的 Ubuntu 20.04 和支持NVIDIA GPU 和 MLPerf 的 docker<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>作为联想向 MLPerf Inference v1.1 提交的一部分提供。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">要设置 AI 推理，请按照以下步骤操作：</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">下载需要注册的数据集，ImageNet 2012 验证集、Criteo Terabyte 数据集、BraTS 2019 训练集，然后解压文件。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">创建至少 1TB 的工作目录并定义环境变量<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block>参考目录。</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">您应该在网络存储用例的共享存储上共享此目录，或者在使用本地数据进行测试时在本地磁盘上共享此目录。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">运行 make<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block>命令，该命令为所需的推理任务构建并启动 docker 容器。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">以下命令均在正在运行的 docker 容器内执行：</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">下载用于 MLPerf 推理任务的预训练 AI 模型：<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">下载可免费下载的其他数据集：<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">预处理数据：<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">跑步：<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> 。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">构建针对计算服务器中的 GPU 优化的推理引擎：<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">要运行推理工作负载，请运行以下命令（一个命令）：</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI推理运行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">执行了三种类型的运行：</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">使用本地存储的单服务器 AI 推理</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">使用网络存储的单服务器 AI 推理</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">使用网络存储的多服务器 AI 推理</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">我们进行了大量的测试来评估所提出的架构的性能。有六种不同的工作负载（图像分类、对象检测 [小]、对象检测 [大]、医学成像、语音转文本和自然语言处理 [NLP]），您可以在三种不同的场景中运行 - 离线、单流和多流。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">测试结果</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">我们进行了大量的测试来评估所提出的架构的性能。</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">有六种不同的工作负载（图像分类、对象检测[小]、对象检测[大]、医学成像、语音转文本和自然语言处理[NLP]），您可以在三种不同的场景中运行：离线、单流和多流。</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最后一种场景仅用于图像分类和对象检测。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">这给出了 15 种可能的工作负载，它们都在三种不同的设置下进行了测试：</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">单服务器/本地存储</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">单服务器/网络存储</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">多服务器/网络存储</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">结果在以下章节中描述。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF离线场景下的AI推理</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">在这种情况下，所有数据都可供服务器使用，并且测量了处理所有样本所需的时间。我们将每秒样本的带宽作为测试结果进行报告。当使用多台计算服务器时，我们会报告所有服务器的总带宽。下图显示了所有三个用例的结果。对于双服务器的情况，我们报告两台服务器的组合带宽。</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">结果表明，网络存储不会对性能产生负面影响——变化很小，对于某些任务来说，没有发现任何变化。当添加第二台服务器时，总带宽要么正好翻倍，要么在最坏的情况下，变化小于 1%。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF单流场景下的 AI 推理</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">该基准测量延迟。对于多计算服务器的情况，我们报告平均延迟。下图给出了这组任务的结果。对于双服务器的情况，我们报告两台服务器的平均延迟。</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">结果再次表明，网络存储足以处理这些任务。在一台服务器的情况下，本地存储和网络存储之间的差异很小或者没有。类似地，当两台服务器使用相同的存储时，两台服务器上的延迟保持不变或变化很小。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF多流场景下的 AI 推理</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">在这种情况下，结果是系统在满足 QoS 约束的同时可以处理的流的数量。因此，结果始终是一个整数。对于多台服务器，我们报告所有服务器上的流总数。并非所有工作负载都支持此场景，但我们执行了支持此场景的工作负载。下图总结了我们的测试结果。对于双服务器的情况，我们报告来自两个服务器的流的总数。</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">结果显示该设置的性能完美——本地和网络存储给出相同的结果，并且添加第二台服务器使建议的设置可以处理的流数量增加一倍。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF 测试结果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">我们进行了大量的测试来评估所提出的架构的性能。有六种不同的工作负载（图像分类、对象检测[小]、对象检测[大]、医学成像、语音转文本和自然语言处理[NLP]），它们在两种不同的场景中运行：离线和单流。结果在以下章节中描述。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF 离线场景下的 AI 推理</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">在这种情况下，所有数据都可供服务器使用，并且测量了处理所有样本所需的时间。我们将每秒样本的带宽作为测试结果进行报告。对于单节点运行，我们报告两台服务器的平均值，而对于双服务器运行，我们报告所有服务器的总带宽总和。用例的结果如下图所示。</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF 单流场景下的 AI 推理</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">该基准测量延迟。对于所有情况，我们报告运行中涉及的所有服务器的平均延迟。给出了这一系列任务的结果。</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">结果再次表明网络存储足以处理这些任务。在一台服务器的情况下，本地存储和网络存储之间的差异很小或者没有。类似地，当两台服务器使用相同的存储时，两台服务器上的延迟保持不变或变化很小。</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">您可以调整用于验证的设置以适合其他用例。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">架构规模选项</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">计算服务器</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">我们使用了 Intel Xeon D-2123IT CPU，这是 SE350 支持的最低级别的 CPU，具有四个物理核心和 60W TDP。虽然该服务器不支持更换 CPU，但可以订购功能更强大的 CPU。支持的最高 CPU 是 Intel Xeon D-2183IT，16 核，100W，运行频率为 2.20GHz。这大大提高了CPU的计算能力。虽然 CPU 本身并不是运行推理工作负载的瓶颈，但它有助于数据处理和其他与推理相关的任务。目前， NVIDIA T4 是唯一可用于边缘用例的 GPU；因此，目前无法升级或降级 GPU。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共享存储</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">为了进行测试和验证，本文档使用了NetApp AFF C190系统，该系统的最大存储容量为 50.5TB，顺序读取的吞吐量为 4.4GBps，小型随机读取的吞吐量为 230K IOPS，事实证明它非常适合边缘推理工作负载。</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">但是，如果您需要更大的存储容量或更快的网络速度，则应该使用NetApp AFF A220或NetApp AFF A250存储系统。此外，最大容量1.5PB、带宽10GBps的NetApp EF280系统也被用于该解决方案的验证。如果您希望拥有更大的存储容量和更高的带宽，<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block>可以使用。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">本节介绍此AI解决方案的技术基础。</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF 系统</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">最先进的NetApp AFF存储系统支持边缘 AI 推理部署，以业界领先的性能、卓越的灵活性、云集成和一流的数据管理满足企业存储需求。  NetApp AFF系统专为闪存设计，有助于加速、管理和保护业务关键数据。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">入门级NetApp AFF存储系统基于FAS2750硬件和 SSD 闪存介质</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 配置中的两个控制器</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp入门级AFF C190存储系统支持以下功能：</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">最大驱动器数量为 24 个 960GB SSD</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">两种可能的配置：</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">以太网 (10GbE)：4 个 10GBASE-T (RJ-45) 端口</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">统一（16Gb FC 或 10GbE）：4 个统一目标适配器 2 (UTA2) 端口</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大50.5TB有效容量</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">对于 NAS 工作负载，单个入门级AFF C190系统支持 4.4GBps 的顺序读取吞吐量和 230K IOPS 的小型随机读取吞吐量，延迟时间为 1ms 或更短。</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp还提供其他入门级存储系统，为更大规模的部署提供更高的性能和可扩展性。对于 NAS 工作负载，单个入门级AFF A220系统支持：</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">顺序读取吞吐量为 6.2GBps</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS，用于延迟为 1ms 或更短的小随机读取</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">最大驱动器数量为 144 个 960GB、3.8TB 或 7.6TB SSD</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220可扩展至超过 1PB 的有效容量</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大有效容量为 35PB，最大横向扩展 2-24 个节点（12 个 HA 对）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">性能比AFF A220提高 ≥ 45%</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS 随机读取@1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">基于最新的NetApp ONTAP版本： ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">利用两个 25Gb 以太网实现 HA 和集群互连</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E系列EF系统</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF 系列是入门级和中档全闪存 SAN 存储阵列系列，可以加速对数据的访问，并帮助您通过NetApp SANtricity软件更快地从中获取价值。这些系统提供 SAS 和 NVMe 闪存，并为您提供从经济实惠到极致的 IOPS、低于 100 微秒的响应时间和高达 44GBps 的带宽，使其成为混合工作负载和 AI 推理和高性能计算 (HPC) 等要求苛刻的应用程序的理想选择。</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">下图显示的是NetApp EF280 存储系统。</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC、25Gb/10Gb iSCSI 和 12Gb SAS 支持</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大有效容量为 96 个驱动器，总计 1.5PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">吞吐量为 10GBps（顺序读取）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPs（随机读取）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280 是NetApp产品组合中成本最低的全闪存阵列 (AFA)</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24 个 NVMe SSD 驱动器，总容量为 367TB</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">扩展选项总计 240 个 NL-SAS HDD、96 个 SAS SSD 或组合</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB、NVMe/RoCE、iSER/IB 和 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVME/FC，FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps（连续读取）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPs（随机读取）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF 系列NetApp EF 系列全闪存阵列 EF600、F300、EF570 和 EF280 数据表</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">有关详细信息，请参阅<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>。</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">ONTAP 9.8.1 是NetApp最新一代的存储管理软件，它支持企业实现基础架构现代化并过渡到云就绪数据中心。 ONTAP利用业界领先的数据管理功能，只需一套工具即可管理和保护数据，无论数据位于何处。您还可以将数据自由移动到任何需要的地方：边缘、核心或云端。  ONTAP 9.8.1 包含众多功能，可简化数据管理、加速和保护关键数据，并支持跨混合云架构的下一代基础架构功能。</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">数据管理对于企业 IT 运营至关重要，以便为应用程序和数据集使用适当的资源。  ONTAP包括以下功能，可简化操作并降低总体运营成本：</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*内联数据压缩和扩展重复数据删除。*数据压缩减少了存储块内部浪费的空间，重复数据删除显著增加了有效容量。这适用于本地存储的数据和分层到云的数据。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*最小、最大和自适应服务质量 (AQoS)。*细粒度的服务质量 (QoS) 控制有助于维持高度共享环境中关键应用程序的性能水平。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool。*此功能可将冷数据自动分层到公共和私有云存储选项，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID存储解决方案。有关FabricPool的更多信息，请参阅<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>。</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 提供卓越级别的性能和数据保护，并通过以下方式扩展这些功能：</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*性能和更低的延迟。*  ONTAP以尽可能低的延迟提供尽可能高的吞吐量。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*数据保护*  ONTAP提供内置数据保护功能，并在所有平台上提供通用管理。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp卷加密 (NVE)。*  ONTAP提供原生卷级加密，同时支持板载和外部密钥管理。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*多租户和多因素身份验证。*  ONTAP支持以最高级别的安全性共享基础设施资源。</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 具有以下功能，可帮助满足苛刻且不断变化的业务需求：</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*无缝扩展和无中断运行。* ONTAP支持无中断地向现有控制器和横向扩展集群添加容量。客户可以升级到最新技术，例如 NVMe 和 32Gb FC，而无需昂贵的数据迁移或中断。</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*云连接。*  ONTAP是与云连接最紧密的存储管理软件，在所有公共云中均提供软件定义存储（ONTAP Select）和云原生实例（Google Cloud NetApp Volumes）的选项。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*与新兴应用程序集成。*  ONTAP使用支持现有企业应用的相同基础架构，为下一代平台和应用（如自动驾驶汽车、智能城市和工业 4.0）提供企业级数据服务。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E系列SANtricity软件数据表</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity旨在为 E 系列混合闪存和 EF 系列全闪存阵列提供业界领先的性能、可靠性和简便性。实现 E 系列混合闪存和 EF 系列全闪存阵列的最大性能和利用率，适用于数据分析、视频监控以及备份和恢复等高负载应用。借助SANtricity，可以在存储保持在线的情况下完成配置调整、维护、容量扩展和其他任务。 SANtricity还提供卓越的数据保护、主动监控和经过认证的安全性——所有这些都可以通过易于使用的机载系统管理器界面访问。要了解更多信息，请参阅<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">性能优化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">性能优化的SANtricity软件以高 IOPS、高吞吐量和低延迟向您的所有数据分析、视频监控和备份应用程序提供数据。加速高 IOPS、低延迟应用程序以及高带宽、高吞吐量应用程序的性能。</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">最大化正常运行时间</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">在存储保持在线时完成所有管理任务。调整配置、执行维护或扩展容量，而无需中断 I/O。通过自动化功能、在线配置、最先进的动态磁盘池 (DPP) 技术等实现一流的可靠性。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">安心休息</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity软件通过易于使用的机载系统管理器界面提供卓越的数据保护、主动监控和经过认证的安全性。简化存储管理工作。获得对所有 E 系列存储系统进行高级调整所需的灵活性。随时随地管理您的NetApp E 系列系统。我们的基于网络的机载界面简化了您的管理工作流程。</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>NetApp推出的一款适用于 Docker 和 Kubernetes 的开源动态存储编排器，可简化持久存储的创建、管理和使用。  Trident是 Kubernetes 原生应用程序，直接在 Kubernetes 集群内运行。  Trident使客户能够将 DL 容器映像无缝部署到NetApp存储上，并为 AI 容器部署提供企业级体验。  Kubernetes 用户（例如 ML 开发人员和数据科学家）可以创建、管理和自动化编排和克隆，以利用由NetApp技术提供支持的NetApp高级数据管理功能。</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>是NetApp 的一项快速、安全的数据同步服务。无论您需要在本地 NFS 或 SMB 文件共享、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google Cloud Storage 或 IBM Cloud Object Storage 之间传输文件， BlueXP Copy and Sync 都能快速安全地将文件移动到您需要的位置。数据传输完成后，可在源端和目标端完全使用。  BlueXP Copy and Sync 根据您预先定义的时间表持续同步数据，仅移动增量，从而最大限度地减少数据复制所花费的时间和金钱。  BlueXP Copy and Sync 是一种软件即服务 (SaaS) 工具，其设置和使用极其简单。 BlueXP Copy 和 Sync 触发的数据传输由数据代理执行。您可以在 AWS、Azure、Google Cloud Platform 或本地部署BlueXP Copy 和 Sync 数据代理。</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">联想 ThinkSystem 服务器采用创新的硬件、软件和服务，可解决客户当前面临的挑战，并提供革命性的、适合用途的模块化设计方法来应对未来的挑战。这些服务器利用一流的行业标准技术以及差异化的联想创新，为 x86 服务器提供最大的灵活性。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">部署联想 ThinkSystem 服务器的主要优势包括：</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">高度可扩展、模块化设计，可随着您的业务增长</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">行业领先的弹性，可节省数小时昂贵的计划外停机时间</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">快速闪存技术可实现更低的延迟、更快的响应时间和更智能的实时数据管理</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">在人工智能领域，联想正在采取切实可行的方法帮助企业了解并采用机器学习和人工智能为其工作负载带来的好处。联想客户可以在联想人工智能创新中心探索和评估联想人工智能产品，以充分了解其特定用例的价值。为了缩短价值实现时间，这种以客户为中心的方法为客户提供了可立即使用且针对 AI 进行优化的解决方案开发平台的概念验证。</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">边缘计算允许在网络边缘分析来自物联网设备的数据，然后再将其发送到数据中心或云端。如下图所示，联想 ThinkSystem SE350 专为满足边缘部署的独特要求而设计，注重灵活性、连接性、安全性和远程可管理性，具有紧凑、坚固且耐环境侵蚀的外形。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 配备英特尔至强 D 处理器，可灵活支持边缘 AI 工作负载的加速，专为解决数据中心外各种环境中的服务器部署挑战而设计。</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推理 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf 是业界领先的评估 AI 性能的基准套件。它涵盖了应用人工智能的许多领域，包括图像分类、对象检测、医学成像和自然语言处理 (NLP)。在本次验证中，我们使用了 Inference v0.7 工作负载，这是本次验证完成时 MLPerf Inference 的最新版本。这<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block>该套件包括四个针对数据中心和边缘系统的新基准：</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*伯特*使用 SQuAD 数据集对 Transformer 的双向编码器表示 (BERT) 进行微调，以用于问答。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM。*深度学习推荐模型 (DLRM) 是一种经过训练以优化点击率 (CTR) 的个性化和推荐模型。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">3D U-Net。  3D U-Net 架构在脑肿瘤分割 (BraTS) 数据集上进行训练。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T* 循环神经网络传感器 (RNN-T) 是一种在 LibriSpeech 子集上训练的自动语音识别 (ASR) 模型。  MLPerf 推理结果和代码是公开的，并根据 Apache 许可发布。  MLPerf Inference 有一个 Edge 部门，支持以下场景：</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*单流。*该场景模拟了响应能力是关键因素的系统，例如在智能手机上执行的离线 AI 查询。单独的查询被发送到系统并记录响应时间。所有响应的第 90 个百分位延迟被报告为结果。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*多流。*该基准适用于处理来自多个传感器的输入的系统。在测试期间，查询以固定的时间间隔发送。施加了 QoS 约束（允许的最大延迟）。该测试报告系统在满足 QoS 约束的情况下可以处理的流数量。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*离线。*这是涵盖批处理应用程序的最简单的场景，其指标是每秒样本的吞吐量。所有数据均可供系统使用，基准测量处理所有样本所需的时间。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">联想已发布本文档中使用的服务器 SE350 与 T4 的 MLPerf 推理分数。查看结果<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block>在条目 #0.7-145 的“边缘，封闭分区”部分中。</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">可以调整用于验证的设置以适应其他用例。</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">架构调整</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">可以调整用于此验证的设置以适应其他用例。</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU调整</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">按照联想的推荐，我们使用 Skylake Intel Xeon Platinum 8360Y 处理器进行此验证。我们预计同等的 Cascade Lake CPU（英特尔至强金牌 6330 处理器）将提供类似的性能，因为此工作负载不受 CPU 限制。</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">增加存储容量</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">根据您的存储容量需求，您可以按需增加共享存储（NFS 卷），前提是您有额外的磁盘架和控制器型号。您可以以管理员用户身份从 CLI 或存储控制器的NetApp Web 界面执行此操作。</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">NetApp和联想的解决方案是一种灵活的横向扩展架构，非常适合进入中型企业 AI。  NetApp存储提供与本地 SSD 存储相同或更好的性能，并为数据科学家、数据工程师和 IT 决策者提供以下优势。</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">这里验证的NetApp和联想解决方案是一种灵活的横向扩展架构，非常适合进入中型企业 AI。</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetApp存储提供与本地 SSD 存储相同或更好的性能，并为数据科学家、数据工程师和 IT 决策者提供以下优势：</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">独立可扩展的计算和存储，以最大限度地降低成本并提高资源利用率。</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">使用集成快照和克隆来简化开发和部署工作流程，以实现即时且节省空间的用户工作区、集成版本控制和自动部署。</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">用于灾难恢复和业务连续性的企业级数据保护。</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam， NetApp技术营销工程师</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton，联想人工智能实验室系统管理员</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetApp全闪存阵列产品页面</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400页面</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAP数据管理软件产品页面</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI（nvidia-smi）</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">本节介绍测试的配置、网络基础设施、SR670 V2 服务器和存储配置详细信息。</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">本节介绍测试的配置、网络基础设施、SR670 V2 服务器和NetApp存储配置详细信息。</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">我们使用下表列出的解决方案组件进行此验证。</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">两台 SR670 V2 服务器，每台配备八张NVIDIA A100 80GB GPU 卡</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">每台服务器包含 2 个 Intel Xeon Platinum 8360Y CPU（28 个物理核心）和 1TB RAM</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux（Ubuntu - 20.04，带有 CUDA 11.8）</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF存储系统（HA 对）</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1软件</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">每个控制器 1 个接口组 (ifgrp)，具有四个用于挂载点的逻辑 IP 地址</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">在本次验证中，我们使用了 ResNet v2.0 和 MLPerf v2.0 指定的 ImageNet 基集。数据集存储在具有 NFS 协议的NetApp AFF存储系统中。  SR670 通过 100GbE 交换机连接到NetApp AFF A400存储系统。</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet 是一个经常使用的图像数据集。它包含近 130 万张图片，总大小为 144GB。平均图像大小为 108KB。</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">下图描述了测试配置的网络拓扑。</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">该图描绘了计算层（联想 ThinkSystem SR670 V2）、网络层（联想以太网交换机）和存储层（ NetApp AFF A400存储控制器）。包括所有网络连接。</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">下表列出了存储配置。</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">骨料大小</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">卷大小</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">操作系统挂载点</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100克</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g 文件夹包含用于 ResNet 验证的数据集。</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">本节描述了详细的测试过程结果。</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">测试程序和详细结果</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">在ONTAP中使用 ResNet 进行图像识别训练</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">我们使用一台和两台 SR670 V2 服务器运行 ResNet50 基准测试。本次测试使用MXNet 22.04-py3 NGC容器运行训练。</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">我们在本次验证中使用了以下测试程序：</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">我们在运行脚本之前清除了主机缓存，以确保数据尚未被缓存：</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">我们在服务器存储（本地 SSD 存储）以及NetApp AFF存储系统上使用 ImageNet 数据集运行基准测试脚本。</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">我们使用以下方法验证了网络和本地存储性能<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>命令。</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">对于单节点运行，我们使用以下命令：</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">对于分布式运行，我们使用了参数服务器的并行化模型。我们每个节点使用两个参数服务器，并将 epoch 数设置为与单节点运行相同。我们这样做是因为由于进程之间的同步不完善，分布式训练通常需要更多的时期。不同的时期数可能会扭曲单节点和分布式情况之间的比较。</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">数据读取速度：本地存储与网络存储</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">读取速度是通过<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>对 ImageNet 数据集的其中一个文件执行命令。具体来说，我们对本地和网络数据运行以下命令：</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">两个值相似，表明网络存储可以以与本地存储相似的速率传输数据。</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">共享用例：多个独立、同时的作业</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">该测试模拟了该解决方案的预期用例：多作业、多用户 AI 训练。每个节点在使用共享网络存储的同时运行自己的训练。结果如下图所示，从图中可以看出，该解决方案案例提供了出色的性能，所有作业的运行速度与单个作业基本相同。总吞吐量与节点数量成线性关系。</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">该图显示了每秒的聚合图像数。</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">该图显示了运行时间（以分钟为单位）。</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">这些图表显示了使用 100 GbE 客户端网络上每个服务器的八个 GPU 的计算节点的运行时间（以分钟为单位）和每秒的聚合图像数，结合了并发训练模型和单一训练模型。训练模型的平均运行时间为35分9秒。个人成绩分别为34分32秒、36分21秒、34分37秒、35分25秒、34分31秒。训练模型每秒的平均图像数为 22,573 张，每秒的单个图像数为 21,764 张；23,438 张；22,556 张；22,564 张；22,547 张。</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">根据我们的验证，一个使用NetApp数据运行时间的独立训练模型的运行时间为 34 分 54 秒，每秒 22,231 张图像。一个具有本地数据（DAS）的独立训练模型的运行时间为 34 分 21 秒，每秒 22,102 张图像。在这些运行期间，平均 GPU 利用率为 96%，如在 nvidia-smi 上观察到的。请注意，此平均值包括测试阶段，在此期间未使用 GPU，而 CPU 利用率为 40%（由 mpstat 测量）。这表明在每种情况下数据传输率都是足够的。</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">该解决方案专注于入门级和中端集群架构，使用针对人工智能工作负载优化的NetApp存储和联想服务器。它适用于大多数计算作业是单节点（单或多 GPU）或分布在几个计算节点上的中小型团队。这不是一个主要的限制，因为大多数日常的人工智能训练工作都是单节点的。</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810： NetApp AFF A400与联想 ThinkSystem SR670 V2 搭配用于 AI 和 ML 模型训练</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan、David Arnette、 NetApp Mircea Troaca、联想</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">该解决方案采用了NetApp存储和针对人工智能 (AI) 工作负载进行优化的联想服务器的中端集群架构。它适用于大多数计算作业是单节点（单 GPU 或多 GPU）或分布在几个计算节点上的中小型企业。该解决方案与许多企业的大多数日常 AI 培训工作相一致。</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">本文档涵盖由八 GPU 联想 SR670V2 服务器、中档NetApp AFF A400存储系统和 100GbE 互连交换机组成的计算和存储配置的测试和验证。为了衡量性能，我们使用了 ResNet50 和 ImageNet 数据集、批量大小为 408、半精度、CUDA 和 cuDNN。该架构为刚刚开始 AI 计划且需要NetApp ONTAP云连接数据存储的企业级功能的中小型组织提供了高效且经济的解决方案。</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">数据科学家、数据工程师、数据管理员和人工智能系统开发人员</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">为 AI 模型开发设计解决方案的企业架构师</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">寻求有效方法实现深度学习 (DL) 和机器学习 (ML) 开发目标的数据科学家和数据工程师</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">希望尽快实现 AI 计划上市的企业领导者和 OT/IT 决策者</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">该解决方案采用联想 ThinkSystem 服务器和带有AFF存储的NetApp ONTAP，旨在利用 GPU 和传统 CPU 的处理能力来处理大型数据集的 AI 训练。此次验证展示了采用横向扩展架构的高性能和最佳数据管理，该架构使用一台、两台或四台 Lenovo SR670 V2 服务器以及一台NetApp AFF A400存储系统。下图提供了架构概览。</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">该图描绘了一个以太网交换机，周围是管理服务器、四个 SR670 V2（每个有八个 GPU）和一个NetApp ONTAP存储系统。</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">并行执行多个训练作业时具有高效且经济的性能</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">根据不同数量的联想服务器和不同型号的NetApp存储控制器扩展性能</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">强大的数据保护，满足低恢复点目标 (RPO) 和恢复时间目标 (RTO)，且不会丢失数据</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">通过快照和克隆优化数据管理，简化开发工作流程</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">在本次验证中，我们按照 MLPerf v2.0 的规定执行了图像识别训练。具体来说，我们使用 ImageNet 数据集训练了 ResNet v2.0 模型。主要指标是达到所需精度的时间。我们还报告了每秒图像数的训练带宽，以便更好地判断扩展效率。</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">在本次验证中，我们按照 MLPerf v2.0 的规定执行了图像识别训练。具体来说，我们使用 ImageNet 数据集训练 ResNet v2.0 模型，直到达到 76.1% 的准确率。主要指标是达到所需精度的时间。我们还报告了每秒图像数的训练带宽，以便更好地判断扩展效率。</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">主要测试用例评估同时运行的多个独立训练过程（每个节点一个）。这模拟了主要用例，即多个数据科学家使用的共享系统。第二个测试用例评估了横向扩展效率。</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">本节总结了此解决方案的测试结果。</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">下表总结了针对该解决方案执行的所有测试的结果。</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">测试描述</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">结果摘要</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">图像识别训练：多个并发作业</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">高效的性能。即使集群已被充分利用，所有作业仍能全速运行。  NetApp存储系统提供了与本地 SSD 存储相当的训练性能，同时支持服务器之间轻松共享数据。</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">图像识别训练：横向扩展</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">最多四个节点效率极高。此时，横向扩展的效率较低，但仍然可行。使用更高速的计算网络可以提高可扩展性。  NetApp存储系统提供了与本地 SSD 存储相当的训练性能，同时支持服务器之间轻松共享数据。</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">本节更详细地介绍该解决方案的主要组件。</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">NetApp AFF存储系统使企业能够通过行业领先的性能、卓越的灵活性、云集成和一流的数据管理来满足企业存储需求。  AFF系统专为闪存设计，有助于加速、管理和保护关键业务数据。</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">该图展示了NetApp AFF A400存储控制器的正面。</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">该图描绘了NetApp AFF A400存储控制器的背面。</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400是一款中端 NVMe 闪存存储系统，具有以下功能：</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">最大有效容量：~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">最大横向扩展：2-24 个节点（12 个 HA 对）</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbE 和 16Gb FC 主机支持</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">通过融合以太网 (RoCE) 的 100GbE RDMA 连接到 NVMe 扩展存储架</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">如果未连接 NVMe 机架，则可以使用 100GbE RoCE 端口进行主机网络连接</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">全12Gbps SAS连接扩展存储架</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">有两种配置可供选择：</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">以太网：4个25Gb以太网（SFP28）端口</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">光纤通道：4x 16Gb FC（SFP+）端口</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8KB 随机读取 @.4 毫秒 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">NetApp AFF A250适用于入门级 AI/ML 部署的功能包括：</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">最大有效容量：35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">最大横向扩展：2-24 个节点（12 个 HA 对）</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">基于最新的NetApp ONTAP版本ONTAP 9.8 或更高版本</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">两个 25Gb 以太网端口，用于 HA 和集群互连</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp还提供其他存储系统，例如AFF A800和AFF A700 ，它们为更大规模的 AI/ML 部署提供更高的性能和可扩展性。</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">ONTAP 9 是NetApp最新一代存储管理软件，它支持企业实现基础架构现代化并过渡到云就绪数据中心。 ONTAP利用业界领先的数据管理功能，只需一套工具即可管理和保护数据，无论数据位于何处。数据还可以自由移动到任何需要的地方：边缘、核心或云端。  ONTAP 9 包含许多功能，可简化数据管理、加速和保护关键数据以及跨混合云架构的未来基础架构。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*最小、最大和自适应服务质量 (QoS)。*细粒度的 QoS 控制有助于在高度共享的环境中维持关键应用程序的性能水平。</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*此功能自动将冷数据分层到公共和私有云存储选项，包括 Amazon Web Services (AWS)、Azure 和NetApp StorageGRID对象存储。</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*性能和更低的延迟。*  ONTAP以尽可能低的延迟提供尽可能高的吞吐量。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp卷加密。*  ONTAP提供原生卷级加密，并支持板载和外部密钥管理。</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 有助于满足苛刻且不断变化的业务需求：</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*无缝扩展和无中断运行。* ONTAP支持无中断地向现有控制器以及横向扩展集群添加容量。客户可以升级到最新技术，例如 NVMe 和 32Gb FC，而无需昂贵的数据迁移或中断。</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*与新兴应用程序集成。*  ONTAP使用支持现有企业应用程序的相同基础架构，为下一代平台和应用程序（如 OpenStack、Hadoop 和 MongoDB）提供企业级数据服务。</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup卷</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">训练数据集通常是数十亿个文件的集合。文件可以包括文本、音频、视频和其他形式的非结构化数据，这些数据必须存储和处理才能并行读取。存储系统必须存储许多小文件，并且必须并行读取这些文件以实现顺序和随机 I/O。</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroup卷（下图）是由多个组成成员卷组成的单一命名空间，对存储管理员而言，该卷的管理方式和NetApp FlexVol volume类似。 FlexGroup卷中的文件被分配给各个成员卷，并且不会跨卷或节点进行条带化。它们支持以下功能：</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">高达 20 PB 的容量和可预测的低延迟，适用于高元数据工作负载</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">同一命名空间内最多可容纳 4000 亿个文件</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">跨 CPU、节点、聚合体和组成FlexVol卷的 NAS 工作负载的并行操作</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">该图描绘了一对 HA 存储控制器，其中包含FlexGroup内具有主文件的多个卷。</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">联想 ThinkSystem 产品组合</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">部署联想 ThinkSystem 服务器的主要优势包括：</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">高度可扩展的模块化设计，可随着您的业务增长而增长</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">在人工智能领域，联想正在采取切实可行的方法帮助企业了解并采用机器学习和人工智能为其工作负载带来的好处。联想客户可以在联想人工智能创新中心探索和评估联想人工智能产品，以充分了解其特定用例的价值。为了缩短价值实现时间，这种以客户为中心的方法为客户提供了可立即使用且针对 AI 进行优化的解决方案开发平台的概念验证。</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">联想SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Lenovo ThinkSystem SR670 V2 机架式服务器为加速 AI 和高性能计算 (HPC) 提供最佳性能。  SR670 V2 支持多达八个 GPU，适合 ML、DL 和推理的计算密集型工作负载要求。</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">该图描绘了三种 SR670 配置。第一个显示四个 SXM GPU，带有八个 2.5 英寸 HS 驱动器和 2 个 PCIe I/O 插槽。第二个显示四个双宽或八个单宽 GPU 插槽和两个 PCIe I/O 插槽，带有八个 2.5 英寸或四个 3.5 英寸 HS 驱动器。第三个显示八个双宽 GPU 插槽，其中有六个 EDSFF HS 驱动器和两个 PCIe I/O 插槽。</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">ThinkSystem SR670 V2 配备支持高端 GPU（包括NVIDIA A100 80GB PCIe 8x GPU）的最新可扩展 Intel Xeon CPU，可为 AI 和 HPC 工作负载提供优化、加速的性能。</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">由于越来越多的工作负载需要使用加速器的性能，因此对 GPU 密度的需求也随之增加。零售、金融服务、能源和医疗保健等行业正在使用 GPU 来获取更深入的见解，并通过 ML、DL 和推理技术推动创新。</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 是一款优化的企业级解决方案，用于在生产中部署加速的 HPC 和 AI 工作负载，最大限度地提高系统性能，同时保持下一代平台超级计算集群的数据中心密度。</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">其他功能包括：</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">支持 GPU 直接 RDMA I/O，其中高速网络适配器直接连接到 GPU，以最大化 I/O 性能。</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">支持 GPU 直接存储，其中 NVMe 驱动器直接连接到 GPU，以最大限度地提高存储性能。</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf 是业界领先的评估 AI 性能的基准套件。在本次验证中，我们将其图像分类基准与最流行的 AI 框架之一 MXNet 一起使用。使用MXNet_benchmarks训练脚本来驱动AI训练。该脚本包含几种流行的常规模型的实现，并且旨在尽可能快。它可以在单台机器上运行，也可以在多台主机上以分布式模式运行。</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">本文介绍了NetApp AIPod for Enterprise RAG 的经过验证的参考设计，该设计采用了 Intel Xeon 6 处理器和NetApp数据管理解决方案的技术和组合功能。该解决方案演示了下游 ChatQnA 应用程序利用大型语言模型，为并发用户提供准确、上下文相关的响应。这些响应是通过隔离的 RAG 推理管道从组织的内部知识库中检索的。</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - 利用NetApp和 Intel 进行企业 RAG 推理</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">英特尔徽标</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">越来越多的组织正在利用检索增强生成 (RAG) 应用程序和大型语言模型 (LLM) 来解释用户提示并生成响应，以提高生产力和商业价值。这些提示和响应可以包括从组织内部知识库、数据湖、代码存储库和文档存储库检索到的文本、代码、图像，甚至治疗蛋白质结构。本文介绍了NetApp AIPod Mini 解决方案的参考设计，包括NetApp AFF存储和搭载 Intel Xeon 6 处理器的服务器。它包括与英特尔高级矩阵扩展 (Intel AMX) 相结合的NetApp ONTAP数据管理软件，以及基于企业 AI 开放平台 (OPEA) 构建的英特尔企业检索增强生成 (RAG) 软件。适用于企业 RAG 的NetApp AIPod Mini 使组织能够将公共 LLM 增强为私有生成式 AI (GenAI) 推理解决方案。该解决方案展示了企业规模的高效且经济的 RAG 推理，旨在提高可靠性并让您更好地控制您的专有信息。</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">英特尔存储合作伙伴验证</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">搭载英特尔至强 6 处理器的服务器专为处理要求苛刻的 AI 推理工作负载而设计，并使用英特尔 AMX 实现最佳性能。为了实现最佳的存储性能和可扩展性，该解决方案已使用NetApp ONTAP成功验证，使企业能够满足 RAG 应用程序的需求。该验证是在配备 Intel Xeon 6 处理器的服务器上进行的。英特尔和NetApp建立了强大的合作伙伴关系，致力于提供优化、可扩展且符合客户业务需求的 AI 解决方案。</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">使用NetApp运行 RAG 系统的优势</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">RAG 应用程序涉及从公司各种类型的文档存储库中检索知识，例如 PDF、文本、CSV、Excel 或知识图。这些数据通常存储在诸如 S3 对象存储或 NFS 本地解决方案中作为数据源。  NetApp一直是边缘、数据中心和云生态系统中数据管理、数据移动性、数据治理和数据安全技术的领导者。  NetApp ONTAP数据管理提供企业级存储，以支持各种类型的 AI 工作负载，包括批量和实时推理，并提供以下一些优势：</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">速度和可扩展性。您可以高速处理大型数据集以进行版本控制，并能够独立扩展性能和容量。</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">数据访问。多协议支持允许客户端应用程序使用 S3、NFS 和 SMB 文件共享协议读取数据。  ONTAP S3 NAS 存储桶可以促进多模式 LLM 推理场景中的数据访问。</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">可靠性和保密性。  ONTAP提供数据保护、内置NetApp自主勒索软件保护 (ARP) 和动态存储配置，并提供基于软件和硬件的加密以增强机密性和安全性。  ONTAP 的所有 SSL 连接均符合 FIPS 140-2 标准。</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">本文档适用于希望利用为提供企业 RAG 和 GenAI 解决方案而构建的基础设施的 AI 决策者、数据工程师、业务领导者和部门主管。对 AI 推理、LLM、Kubernetes 以及网络及其组件的先前了解将有助于实施阶段。</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">英特尔人工智能技术</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Xeon 6处理器</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">使用 Xeon 6 作为主机 CPU，加速系统可受益于高单线程性能；更高的内存带宽；更高的可靠性、可用性和可服务性 (RAS)；以及更多的 I/O 通道。英特尔 AMX 加速了 INT8 和 BF16 的推理，并支持 FP16 训练模型，INT8 每核每周期最多可进行 2,048 次浮点运算，BF16/FP16 每核每周期最多可进行 1,024 次浮点运算。要使用 Xeon 6 处理器部署 RAG 解决方案，通常建议至少使用 250GB 的 RAM 和 500GB 的磁盘空间。然而，这在很大程度上取决于 LLM 模型的大小。欲了解更多信息，请参阅英特尔<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block>产品简介。</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300,300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">图 1 - 搭载 Intel Xeon 6 处理器的计算服务器<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">NetApp AFF 存储系统</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">入门级和中级NetApp AFF A 系列系统提供更强大的性能、密度和更高的效率。  NetApp AFF A20、 AFF A30 和AFF A50 系统提供真正的统一存储，支持块、文件和对象，基于单一操作系统，可以以最低的成本在混合云中无缝管理、保护和调动 RAG 应用程序的数据。</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">图 2 - NetApp AFF A 系列系统。<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*硬件*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*数量*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*评论*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">基于 Intel Xeon 6 的服务器</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">RAG 推理节点 - 配备双插槽 Intel Xeon 6900 系列或 Intel Xeon 6700 系列处理器以及 250GB 至 3TB RAM，配备 DDR5 (6400MHz) 或 MRDIMM (8800MHz)。  2U服务器。</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">带有英特尔处理器的控制平面服务器</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Kubernetes 控制平面/1U 服务器。</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">100Gb 以太网交换机的选择</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">数据中心交换机。</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20（或AFF A30； AFF A50）</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">最大存储容量：9.3PB。注意：网络：10/25/100 GbE 端口。</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">为了验证此参考设计，我们使用了 Supermicro 的 Intel Xeon 6 处理器服务器（222HA-TN-OTO-37）和 Arista 的 100GbE 交换机（7280R3A）。</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">企业AI开放平台</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">企业 AI 开放平台 (OPEA) 是由英特尔与生态系统合作伙伴共同主导的一项开源计划。它提供了一个可组合构建块的模块化平台，旨在加速尖端生成 AI 系统的开发，重点关注 RAG。  OPEA 包括一个综合框架，该框架具有 LLM、数据存储、提示引擎、RAG 架构蓝图以及基于性能、特性、可信度和企业准备度评估生成式 AI 系统的四步评估方法。</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">OPEA 的核心包括两个关键部分：</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps：由微服务组件组成的基于服务的工具包</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples：可立即部署的解决方案，例如 ChatQnA，可展示实际用例</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">OPEA项目文档</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">有关详细信息，请参阅<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">由 OPEA 提供支持的英特尔企业人工智能推理</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">适用于英特尔企业人工智能 RAG 的 OPEA 简化了将企业数据转化为可操作见解的过程。它由英特尔至强处理器提供支持，集成了来自行业合作伙伴的组件，为部署企业解决方案提供了简化的方法。它可以与成熟的编排框架无缝扩展，提供企业所需的灵活性和选择。</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">在 OPEA 的基础上，英特尔企业人工智能 RAG 通过增强可扩展性、安全性和用户体验的关键功能扩展了这一基础。这些功能包括与现代基于服务的架构无缝集成的服务网格功能、用于管道可靠性的生产就绪验证以及用于 RAG 即服务的功能丰富的 UI，从而可以轻松管理和监控工作流程。此外，英特尔和合作伙伴的支持提供了广泛的解决方案生态系统，结合集成的身份和访问管理 (IAM) 与 UI 和应用程序，实现安全且合规的操作。可编程护栏对管道行为提供细粒度的控制，实现定制的安全性和合规性设置。</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">了解ONTAP S3 配置</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP是 NetApp 关键数据存储解决方案的基础技术。 ONTAP包含各种数据管理和数据保护功能，例如针对网络攻击的自动勒索软件保护、内置数据传输功能和存储效率功能。这些优势适用于一系列架构，从本地到 NAS、SAN、对象和 LLM 部署的软件定义存储中的混合多云。您可以在ONTAP集群中使用ONTAP S3 对象存储服务器来部署 RAG 应用程序，从而利用通过授权用户和客户端应用程序提供的ONTAP的存储效率和安全性。有关详细信息，请参阅<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">Git 上的NetApp Trident</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">NetApp Trident软件是一款开源且完全受支持的存储编排器，适用于容器和 Kubernetes 发行版，包括 Red Hat OpenShift。 Trident可与整个NetApp存储产品组合配合使用，包括NetApp ONTAP ，并且还支持 NFS 和 iSCSI 连接。有关详细信息，请参阅<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*软件*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*版本*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">面向企业 RAG 的英特尔 AI 的 OPEA</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">基于OPEA微服务的企业RAG平台</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">容器存储接口（CSI驱动程序）</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">支持动态配置、 NetApp Snapshot 副本和卷。</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">双节点集群上的操作系统</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">容器编排</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">运行 RAG 框架的环境</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">AFF A20 上的存储操作系统。它具有 Vscan 和 ARP 功能。</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">解决方案部署</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">软件堆栈</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">该解决方案部署在由基于 Intel Xeon 的应用节点组成的 Kubernetes 集群上。至少需要三个节点才能实现 Kubernetes 控制平面的基本高可用性。我们使用以下集群布局验证了该解决方案。</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">表 3 - Kubernetes 集群布局</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">节点</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">角色</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">配备 Intel Xeon 6 处理器和 1TB RAM 的服务器</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">应用节点、控制平面节点</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">通用服务器</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">控制平面节点</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600,600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">下图描述了该解决方案的“软件堆栈视图”。<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">部署步骤</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">部署ONTAP存储设备</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">ONTAP硬件系统文档</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">部署和配置您的NetApp ONTAP存储设备。请参阅<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block>了解详情。</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">配置ONTAP SVM 以进行 NFS 和 S3 访问</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">在 Kubernetes 节点可访问的网络上配置ONTAP存储虚拟机 (SVM) 以进行 NFS 和 S3 访问。</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">ONTAP文档。</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">要使用ONTAP系统管理器创建 SVM，请导航到“存储”&gt;“存储虚拟机”，然后单击“+ 添加”按钮。为您的 SVM 启用 S3 访问时，请选择使用外部 CA（证书颁发机构）签名的证书，而不是系统生成的证书。您可以使用自签名证书或由公众信任的 CA 签名的证书。有关更多详细信息，请参阅<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">以下屏幕截图展示了使用ONTAP系统管理器创建 SVM 的过程。根据您的环境根据需要修改详细信息。</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">图 4 — 使用ONTAP系统管理器创建 SVM。<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">配置 S3 权限</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">为您在上一步中创建的 SVM 配置 S3 用户/组设置。确保您拥有对该 SVM 的所有 S3 API 操作具有完全访问权限的用户。有关详细信息，请参阅ONTAP S3 文档。</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">注意：英特尔 AI for Enterprise RAG 应用程序的数据提取服务需要此用户。如果您使用ONTAP系统管理器创建了 SVM，系统管理器将自动创建一个名为<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>以及一个名为<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block>当您创建 SVM 时，但尚未分配任何权限<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>。</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">要编辑此用户的权限，请导航至“存储”&gt;“存储虚拟机”，单击您在上一步中创建的 SVM 的名称，单击“设置”，然后单击“S3”旁边的铅笔图标。给予<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>拥有所有 S3 API 操作的完全访问权限，创建一个关联<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>与<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block>策略如下面的屏幕截图所示。</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">图 5 - S3 权限。</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">创建 S3 存储桶</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">在您之前创建的 SVM 内创建一个 S3 存储桶。要使用ONTAP系统管理器创建 SVM，请导航到“存储”&gt;“存储桶”，然后单击“+ 添加”按钮。有关更多详细信息，请参阅ONTAP S3 文档。</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">以下屏幕截图展示了使用ONTAP系统管理器创建 S3 存储桶的过程。</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">图 6 - 创建 S3 存储桶。<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">配置 S3 存储桶权限</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">为您在上一步中创建的 S3 存储桶配置权限。确保您在上一步中配置的用户具有以下权限：<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">ONTAP S3 文档</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">要使用ONTAP系统管理器编辑 S3 存储桶权限，请导航到“存储”&gt;“存储桶”，单击存储桶的名称，单击“权限”，然后单击“编辑”。请参阅<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block>了解更多详细信息。</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">以下屏幕截图展示了ONTAP系统管理器中必要的存储桶权限。</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">图 7 - S3 存储桶权限。<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">创建 bucket 跨域资源共享规则</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">使用ONTAP CLI，为您在上一步中创建的存储桶创建存储桶跨域资源共享 (CORS) 规则：</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">此规则允许英特尔 AI for Enterprise RAG Web 应用程序的 OPEA 从 Web 浏览器内与存储桶进行交互。</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">部署服务器</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">部署您的服务器并在每台服务器上安装 Ubuntu 22.04 LTS。安装 Ubuntu 后，在每台服务器上安装 NFS 实用程序。要安装 NFS 实用程序，请运行以下命令：</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">安装 Kubernetes</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Kubespray 文档</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">使用 Kubespray 在您的服务器上安装 Kubernetes。请参阅<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block>了解详情。</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">安装Trident CSI 驱动程序</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Trident安装文档</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">在您的 Kubernetes 集群中安装NetApp Trident CSI 驱动程序。请参阅<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block>了解详情。</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">创建Trident后端</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Trident后端文档</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">为您之前创建的 SVM 创建Trident后端。创建后端时，使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>司机。请参阅<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block>了解详情。</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">创建存储类</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">创建与您在上一步中创建的Trident后端相对应的 Kubernetes 存储类。有关详细信息，请参阅Trident存储类文档。</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">英特尔 AI 企业版 RAG 部署</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">在您的 Kubernetes 集群中安装适用于 Intel AI for Enterprise RAG 的 OPEA。请参阅<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block>文档以了解详细信息。请务必记下本文后面描述的所需的配置文件修改。您必须在执行安装手册之前进行这些修改，以便 Intel AI for Enterprise RAG 应用程序能够与您的ONTAP存储系统正确配合使用。</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">启用ONTAP S3</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">为 Intel AI for Enterprise RAG 安装 OPEA 时，编辑主配置文件以允许使用ONTAP S3 作为源数据存储库。</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">要启用ONTAP S3，请在<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block>部分。</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">注意：默认情况下，Intel AI for Enterprise RAG 应用程序会从 SVM 中所有现有存储桶中提取数据。如果您的 SVM 中有多个存储桶，则可以修改<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block>字段，以便仅从某些存储桶中提取数据。</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">配置计划同步设置</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">安装英特尔企业人工智能 RAG 应用程序的 OPEA 时，启用<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>以便应用程序自动从您的 S3 存储桶中提取新的或更新的文件。</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">什么时候<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>启用后，应用程序会自动检查源 S3 存储桶中是否有新文件或更新的文件。在此同步过程中发现的任何新文件或更新文件都会自动提取并添加到 RAG 知识库中。应用程序根据预设的时间间隔检查您的源存储桶。默认时间间隔为 60 秒，这意味着应用程序每 60 秒检查一次更改。您可能希望更改此间隔以满足您的特定需求。</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">启用<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>并设置同步间隔，在<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">更改卷访问模式</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">在<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block>，对于每个卷<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>列表，更改<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>到<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>。</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">（可选）禁用 SSL 证书验证</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">如果您在为 SVM 启用 S3 访问时使用了自签名证书，则必须禁用 SSL 证书验证。如果您使用由公众信任的 CA 签名的证书，则可以跳过此步骤。</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">要禁用 SSL 证书验证，请在<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">访问适用于企业 RAG UI 的英特尔 AI 的 OPEA</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">英特尔企业人工智能 RAG 部署文档</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">访问英特尔企业人工智能 RAG UI 的 OPEA。请参阅<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block>了解详情。</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">图 8 - 适用于企业 RAG UI 的英特尔 AI 的 OPEA。<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">为 RAG 提取数据</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">您现在可以提取文件以包含在基于 RAG 的查询扩充中。有多种提取文件的选项。根据您的需要选择适当的选项。</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">注意：提取文件后，英特尔 AI for Enterprise RAG 应用程序的 OPEA 会自动检查文件的更新并相应地提取更新。</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*选项 1：直接上传到您的 S3 存储桶 要一次提取多个文件，我们建议使用您选择的 S3 客户端将文件上传到您的 S3 存储桶（您之前创建的存储桶）。流行的 S3 客户端包括 AWS CLI、Amazon SDK for Python（Boto3）、s3cmd、S3 浏览器、Cyberduck 和 Commander One。如果文件属于受支持的类型，则您上传到 S3 存储桶的任何文件都将由英特尔 AI for Enterprise RAG 应用程序的 OPEA 自动提取。</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">注意：在撰写本文时，支持以下文件类型：PDF、HTML、TXT、DOC、DOCX、PPT、PPTX、MD、XML、JSON、JSONL、YAML、XLS、XLSX、CSV、TIFF、JPG、JPEG、PNG 和 SVG。</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">您可以使用 OPEA for Intel AI for Enterprise RAG UI 来确认您的文件是否已正确提取。有关详细信息，请参阅英特尔 AI for Enterprise RAG UI 文档。请注意，应用程序可能需要一些时间来提取大量文件。</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*选项 2：使用 UI 上传 如果您只需要提取少量文件，则可以使用 OPEA for Intel AI for Enterprise RAG UI 来提取它们。有关详细信息，请参阅英特尔 AI for Enterprise RAG UI 文档。</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">图 9-数据提取 UI。<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">执行聊天查询</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">您现在可以使用附带的聊天 UI 与英特尔企业人工智能 RAG 应用程序的 OPEA“聊天”。在响应您的查询时，应用程序会使用您提取的文件执行 RAG。这意味着应用程序会自动在您摄取的文件中搜索相关信息，并在响应您的查询时合并这些信息。</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">作为验证工作的一部分，我们与英特尔合作进行了性能测试。此次测试得出了下表中列出的尺寸指导。</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">特征</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">值</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">模型尺寸</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">200亿个参数</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">Llama-8B、Llama-13B、Mistral 7B、Qwen 14B、DeepSeek Distill 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">输入尺寸</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">约2000个代币</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">约4页</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">输出尺寸</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">并发用户</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">“并发用户”是指同时提交查询的提示请求。</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_注意：上面提供的尺寸指导基于使用 96 核 Intel Xeon 6 处理器收集的性能验证和测试结果。对于具有类似 I/O 令牌和模型大小要求的客户，我们建议使用具有 96 或 128 个内核的 Xeon 6 处理器的服务器。</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">企业 RAG 系统和 LLM 是协同工作的技术，可帮助组织提供准确且情境感知的响应。这些回应涉及基于大量私人和内部企业数据的信息检索。通过使用 RAG、API、向量嵌入和高性能存储系统来查询包含公司数据的文档存储库，可以更快、更安全地处理数据。  NetApp AIPod Mini 将 NetApp 的智能数据基础架构与ONTAP数据管理功能以及 Intel Xeon 6 处理器、Intel AI for Enterprise RAG 和 OPEA 软件堆栈相结合，帮助部署高性能 RAG 应用程序并让组织走上 AI 领导之路。</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">致谢</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">本文档由NetApp解决方案工程团队成员 Sathish Thyagarajan 和 Michael Ogelsby 编写。作者还要感谢英特尔企业 AI 产品团队（Ajay Mungara、Mikolaj Zyczynski、Igor Konopko、Ramakrishna Karamsetty、Michal Prostko、Shreejan Mistry 和 Ned Fiori）以及NetApp的其他团队成员（Lawrence Bunka、Bobby Oommen 和 Jeff Liborio）在验证此解决方案期间给予的持续支持和帮助。</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">物料清单</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">以下是用于该解决方案功能验证的BOM，可供参考。可以使用符合以下配置的任何服务器或网络组件（甚至是最好具有 100GbE 带宽的现有网络）。</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">对于应用服务器：</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*零件编号*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*产品描述*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">超级服务器 SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">RAM</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D，80 毫米</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">WS-1K63A-1R(x2)1U 692W/1600W 冗余单输出电源。散热量为 2361 BTU/Hr，最高温度为 59 C（约）</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">对于控制服务器：</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">优化了 1U X13SCH-SYS、CSE-813MF2TS-R0RCNBP、PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">对于网络交换机：</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">Arista 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">NetApp AFF存储：</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">AFF A20 HA 系统，-C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">跳线 Crd，驾驶室内，C13-C14，-C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">电源，1600W，钛金，-C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">电缆，100GbE，QSFP28-QSFP28，铜，2米，-C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">电缆，25GbE，SFP28-SFP28，铜，0.5米，-C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">导轨，4 柱，薄，圆形/方孔，小，可调节，24-32，-C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">驱动器包 2X1.92TB，NVMe4，SED，-C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">IO 模块，2PT，100GbE，-C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">IO 模块，4PT，10/25GbE，-C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW、 ONTAP基础包、每 TB、闪存、A20、-C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">OPEA项目</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">OPEA Enterprise RAG 部署手册</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851：适用于自动驾驶工作负载的NetApp StorageGRID数据湖 - 解决方案设计</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">NetApp的 David Arnette</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 演示了如何使用NetApp StorageGRID对象存储作为机器学习 (ML) 和深度学习 (DL) 软件开发的数据存储库和管理系统。本文介绍了自动驾驶汽车软件开发中的数据流和要求以及简化数据生命周期的StorageGRID功能。该解决方案适用于 ML 和 DL 开发过程中典型的任何多阶段数据管道工作流。</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法律声明</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">法律声明提供对版权声明、商标、专利等的访问。</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">版权</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商标</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP、NETAPP 徽标和NetApp商标页面上列出的标志是NetApp, Inc. 的商标。其他公司和产品名称可能是其各自所有者的商标。</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">专利</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp拥有的专利的最新列表可以在以下位置找到：</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">隐私政策</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">为了进行此验证，我们使用一组原始图像对图像检测用例进行了推理。然后，我们对同一组图像执行相同的推理任务，并在推理之前添加了 Protopia 混淆。我们使用 Protopia 混淆组件的不同 ALPHA 值重复了该任务。</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">推理精度比较</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">为了进行此验证，我们使用一组原始图像对图像检测用例进行了推理。然后，我们对同一组图像执行相同的推理任务，并在推理之前添加了 Protopia 混淆。我们使用 Protopia 混淆组件的不同 ALPHA 值重复了该任务。在 Protopia 混淆的背景下，ALPHA 值表示所应用的混淆量，ALPHA 值越高表示混淆级别越高。然后，我们比较了这些不同运行的推理准确性。</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">以下两个表提供了有关我们的用例的详细信息并概述了结果。</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia 直接与客户合作，确定特定用例的适当 ALPHA 值。</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes（PyTorch）-</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB数据集</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">原始托邦的混淆</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">阿尔法</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">准确性</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">否</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">不适用</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">是</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">在哪里可以找到更多信息和致谢</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—机密推理</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">NVIDIA Triton 推理服务器</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton 推理服务器文档</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorch 中的 FaceBoxes</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">NetApp首席产品经理 Mark Cates</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad， NetApp技术营销工程师</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Protopia AI 首席技术官兼教授 Hadi Esmaeilzadeh</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">数据有三种状态 - 静止、传输和计算。任何人工智能推理服务的一个重要部分应该是在整个过程中保护数据免受威胁。在推理过程中保护数据至关重要，因为该过程可能会暴露有关外部客户和提供推理服务的企业的私人信息。</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">数据有三种状态：静止、传输和计算。任何人工智能推理服务的一个重要部分应该是在整个过程中保护数据免受威胁。在推理过程中保护数据至关重要，因为该过程可能会暴露有关外部客户和提供推理服务的企业的私人信息。 Protopia AI 是当今市场上用于机密 AI 推理的非侵入式纯软件解决方案。借助 Protopia，AI 仅接收数据记录中对于执行手头的 AI/ML 任务至关重要的转换信息，仅此而已。这种随机变换不是一种掩蔽形式，而是基于通过使用精心策划的噪声以数学方式改变数据的表示。</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">具有ONTAP功能的NetApp存储系统可提供与本地 SSD 存储相同或更佳的性能，并且与NetApp DataOps Toolkit 结合使用，可为数据科学家、数据工程师、AI/ML 开发人员以及业务或企业 IT 决策者带来以下优势：</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">针对灾难恢复、业务连续性和监管要求的企业级数据保护和数据治理。</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">简化数据管理操作的调用；从 Jupyter 笔记本中的NetApp DataOps Toolkit 快速获取数据科学家工作区的 Snapshot 副本以进行备份和追溯。</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetApp和 Protopia 解决方案提供了灵活的横向扩展架构，非常适合企业级 AI 推理部署。它可以实现数据保护并为敏感信息提供隐私，其中机密的 AI 推理要求可以通过内部部署和混合云部署中的负责任的 AI 实践来满足。</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">本节概述了解决方案设计验证环境。</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">下表概述了解决方案设计验证环境。</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">NetApp Trident CSI 驱动程序</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">适用于 Kubernetes 的NetApp DataOps 工具包</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">本文档描述了在三种不同场景下经过验证的设计解决方案，包括带有和不带有图像混淆的场景，这些场景与保护隐私和部署负责任的人工智能解决方案有关。</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928：负责任的 AI 和机密推理 - NetApp AI 与 Protopia 图像和数据转换</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp Byung Hoon Ahn、Jennifer Cwagenberg、Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">随着图像捕捉和图像处理技术的出现，视觉解读已经成为交流不可或缺的一部分。数字图像处理中的人工智能 (AI) 带来了新的商业机会，例如在医疗领域用于癌症和其他疾病的识别、在地理空间可视化分析中用于研究环境危害、在模式识别中、在视频处理中用于打击犯罪等等。然而，这一机遇也伴随着非凡的责任。</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">组织交给人工智能的决策越多，他们承担的与数据隐私和安全以及法律、道德和监管问题相关的风险就越大。负责任的人工智能使公司和政府组织能够建立信任和治理的实践，这对于大型企业大规模应用人工智能至关重要。本文档介绍了NetApp在三种不同场景下验证的 AI 推理解决方案，该解决方案使用NetApp数据管理技术与 Protopia 数据混淆软件来私有化敏感数据并降低风险和道德问题。</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">消费者和商业实体每天都会使用各种数字设备生成数百万张图像。随之而来的数据和计算工作量的激增使得企业转向云计算平台来实现规模和效率。同时，随着图像数据转移到公共云，人们对其所含敏感信息的隐私问题也产生了担忧。缺乏安全和隐私保障成为图像处理人工智能系统部署的主要障碍。</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">删除权</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">隐私法</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">此外，还有<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block>根据 GDPR，个人有权要求组织删除其所有个人数据。还有<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>，该法案制定了公平信息实践准则。根据 GDPR，照片等数字图像可以构成个人数据，GDPR 规定了数据的收集、处理和删除方式。不这样做就是不遵守 GDPR，这可能会导致违反合规性的巨额罚款，这可能会对组织造成严重损害。隐私原则是实施负责任的人工智能的支柱之一，它确保机器学习 (ML) 和深度学习 (DL) 模型预测的公平性，并降低违反隐私或法规遵从性相关的风险。</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">本文档描述了在三种不同场景下经过验证的设计解决方案，包括带有和不带有图像混淆，这些场景与保护隐私和部署负责任的 AI 解决方案有关：</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">场景 1.  Jupyter 笔记本中的按需推理。</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">场景 2.在 Kubernetes 上进行批量推理。</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">场景 3.  NVIDIA Triton 推理服务器。</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">对于该解决方案，我们使用人脸检测数据集和基准（FDDB），这是一个为研究无约束人脸检测问题而设计的人脸区域数据集，结合 PyTorch 机器学习框架来实现 FaceBoxes。该数据集包含 2845 张不同分辨率图像中 5171 张人脸的注释。此外，本技术报告还介绍了从NetApp客户和现场工程师那里收集的一些适用于该解决方案的解决方案领域和相关用例。</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">本技术报告面向以下受众：</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">希望设计和部署负责任的人工智能并解决公共场所面部图像处理的数据保护和隐私问题的商业领袖和企业架构师。</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">旨在保护和维护隐私的数据科学家、数据工程师、人工智能/机器学习 (ML) 研究人员以及人工智能/机器学习系统开发人员。</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">为符合 GDPR、CCPA 或国防部 (DoD) 和政府组织的隐私法等监管标准的 AI/ML 模型和应用程序设计数据混淆解决方案的企业架构师。</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">数据科学家和人工智能工程师正在寻找有效的方法来部署深度学习 (DL) 和 AI/ML/DL 推理模型来保护敏感信息。</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">该解决方案旨在利用 GPU 和传统 CPU 的处理能力来处理大型数据集上的实时和批量推理 AI 工作负载。此验证证明了寻求负责任的 AI 部署的组织所需的 ML 隐私保护推理和最佳数据管理。该解决方案提供了一种适用于单节点或多节点 Kubernetes 平台的架构，用于边缘和云计算，并通过 Jupyter Lab 和 CLI 界面与核心本地的NetApp ONTAP AI、 NetApp DataOps Toolkit 和 Protopia 混淆软件互连。下图显示了由NetApp提供支持、采用 DataOps Toolkit 和 Protopia 的数据结构的逻辑架构概览。</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia 混淆软件在NetApp DataOps Toolkit 上无缝运行，并在离开存储服务器之前转换数据。</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">本节概述了此解决方案中验证的三种场景。</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">测试和验证计划</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">对于此解决方案设计，验证了以下三种场景：</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">在 JupyterLab 工作区内，使用NetApp DataOps Toolkit for Kubernetes 进行编排的推理任务（有和没有 Protopia 混淆）。</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">在 Kubernetes 上执行批量推理作业（带和不带 Protopia 混淆），其数据卷是使用NetApp DataOps Toolkit for Kubernetes 进行编排的。</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">使用NVIDIA Triton 推理服务器实例的推理任务，该实例是通过使用NetApp DataOps Toolkit for Kubernetes 进行编排的。在调用 Triton 推理 API 之前，我们对图像应用了 Protopia 混淆，以模拟任何通过网络传输的数据都必须混淆的常见要求。此工作流程适用于在受信任区域内收集数据但必须传递到该受信任区域之外进行推理的用例。如果没有 Protopia 混淆，就不可能在敏感数据不离开受信任区域的情况下实现这种类型的工作流程。</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">本节描述完成验证所需的任务。</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">前提条件</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">要执行本节中概述的任务，您必须能够访问安装并配置了以下工具的 Linux 或 macOS 主机：</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl（配置用于访问现有的 Kubernetes 集群）</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">可以找到安装和配置说明<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>。</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">安装说明可以找到<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>。</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">场景 1 – JupyterLab 中的按需推理</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">为 AI/ML 推理工作负载创建 Kubernetes 命名空间。</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">使用NetApp DataOps Toolkit 配置持久卷，用于存储您将执行推理的数据。</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">使用NetApp DataOps Toolkit 创建新的 JupyterLab 工作区。使用上一步创建的持久卷<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block>选项。根据需要NVIDIA<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block>选项。</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">在以下示例中，持久卷<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block>被挂载到 JupyterLab 工作区容器中<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block>。使用官方 Project Jupyter 容器镜像时，<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block>在 JupyterLab Web 界面中显示为顶级目录。</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">使用输出中指定的 URL 访问 JupyterLab 工作区<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block>命令。数据目录代表挂载到工作区的持久卷。</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">打开<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block>目录并上传要执行推理的文件。当文件上传到数据目录时，它们会自动存储在挂载到工作区的持久卷上。要上传文件，请单击上传文件图标，如下图所示。</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">返回顶级目录并创建一个新的笔记本。</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">将推理代码添加到笔记本中。以下示例显示了图像检测用例的推理代码。</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">将 Protopia 混淆添加到您的推理代码中。 Protopia 直接与客户合作提供特定用例的文档，这超出了本技术报告的范围。以下示例展示了添加了 Protopia 混淆的图像检测用例的推理代码。</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">场景 2 – Kubernetes 上的批量推理</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">使用您将执行推理的数据填充新的持久卷。</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 Data Mover 功能</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">有几种方法可以将数据加载到 PVC 上。如果您的数据当前存储在与 S3 兼容的对象存储平台（例如NetApp StorageGRID或 Amazon S3）中，那么您可以使用<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>。另一种简单的方法是创建一个 JupyterLab 工作区，然后通过 JupyterLab Web 界面上传文件，如“<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> “</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">为您的批量推理任务创建一个 Kubernetes 作业。以下示例展示了图像检测用例的批量推理作业。此作业对一组图像中的每个图像执行推理，并将推理准确度指标写入标准输出。</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">确认推理作业已成功完成。</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">将 Protopia 混淆添加到您的推理工作中。您可以直接从 Protopia 找到有关添加 Protopia 混淆的特定用例说明，这超出了本技术报告的范围。以下示例展示了针对人脸检测用例的批量推理作业，其中添加了 Protopia 混淆，并使用 ALPHA 值 0.8。此作业在对一组图像中的每个图像执行推理之前应用 Protopia 混淆，然后将推理准确度指标写入标准输出。</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">推理准确性比较。</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">我们对 ALPHA 值 0.05、0.1、0.2、0.4、0.6、0.8、0.9 和 0.95 重复了此步骤。您可以在<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">场景 3 – NVIDIA Triton 推理服务器</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">使用NetApp DataOps Toolkit 配置持久卷，用作NVIDIA Triton 推理服务器的模型存储库。</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">格式</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">将您的模型存储在新的持久卷中<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block>NVIDIA Triton 推理服务器可以识别它。</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">有几种方法可以将数据加载到 PVC 上。一种简单的方法是创建一个 JupyterLab 工作区，然后通过 JupyterLab Web 界面上传文件，如“<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> 。"</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">使用NetApp DataOps Toolkit 部署新的NVIDIA Triton Inference Server 实例。</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">使用 Triton 客户端 SDK 执行推理任务。以下 Python 代码摘录使用 Triton Python 客户端 SDK 执行人脸检测用例的推理任务。此示例调用 Triton API 并传入图像进行推理。然后，Triton 推理服务器接收请求，调用模型，并将推理输出作为 API 结果的一部分返回。</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">将 Protopia 混淆添加到您的推理代码中。您可以直接从 Protopia 找到有关添加 Protopia 混淆的特定用例说明；但是，此过程超出了本技术报告的范围。以下示例显示了与前面步骤 5 中所示的相同的 Python 代码，但添加了 Protopia 混淆。</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">请注意，在将图像传递给 Triton API 之前，会对其进行 Protopia 混淆处理。因此，未混淆的图像永远不会离开本地机器。只有经过混淆的图像才会在网络上传递。此工作流程适用于在受信任区域内收集数据但随后需要传递到该受信任区域之外进行推理的用例。如果没有 Protopia 混淆技术，就不可能实现这种类型的工作流程，因为敏感数据永远不会离开受信任区域。</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">为了进行此验证，我们将 Protopia 混淆应用于 1920 x 1080 像素图像五次，并测量每次完成混淆步骤所需的时间。</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">混淆速度</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">我们使用在单个NVIDIA V100 GPU 上运行的 PyTorch 来应用混淆，并在运行之间清除了 GPU 缓存。在五次运行中，混淆步骤分别花费 5.47ms、5.27ms、4.54ms、5.24ms 和 4.84ms 完成。平均速度为5.072毫秒。</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">本节概述了完成此解决方案所需的各种技术组件。</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">普罗托邦</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI 为当今市场上的机密推理提供了一种不引人注目的纯软件解决方案。 Protopia 解决方案通过最大限度地减少敏感信息的暴露，为推理服务提供了无与伦比的保护。人工智能仅接收数据记录中对于执行手头任务真正必要的信息，仅此而已。大多数推理任务不会使用每个数据记录中存在的所有信息。无论您的 AI 使用的是图像、语音、视频还是结构化表格数据，Protopia 都只提供推理服务所需的内容。该专利核心技术使用数学策划的噪声来随机转换数据并混淆给定 ML 服务不需要的信息。该解决方案不会掩盖数据；相反，它通过使用精选的随机噪声来改变数据表示。</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia 解决方案将改变表示的问题表述为基于梯度的扰动最大化方法，该方法仍然保留与模型功能相关的输入特征空间中的信息。此发现过程在训练 ML 模型结束时作为微调过程运行。在传递过程自动生成一组概率分布之后，低开销数据转换会将这些分布中的噪声样本应用于数据，并在将其传递给模型进行推理之前对其进行混淆。</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">NetApp ONTAP AI 参考架构由 DGX A100 系统和NetApp云连接存储系统提供支持，由NetApp和NVIDIA开发和验证。它为 IT 组织提供了一种具有以下优势的架构：</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">消除设计复杂性</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">允许独立扩展计算和存储</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">支持客户从小规模起步，然后无缝扩展</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">提供广泛的存储选项，以满足各种性价比需求</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI 将 DGX A100 系统和NetApp AFF A800存储系统与最先进的网络紧密集成。 ONTAP AI 通过消除设计复杂性和猜测来简化 AI 部署。客户可以从小规模开始，然后无中断地发展，同时智能地管理从边缘到核心到云端再返回的数据。</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">下图显示了采用 DGX A100 系统的ONTAP AI 系列解决方案的几种变体。 AFF A800系统性能已通过最多八个 DGX A100 系统验证。通过向ONTAP集群添加存储控制器对，该架构可以扩展到多个机架，以支持许多 DGX A100 系统和具有线性性能的 PB 级存储容量。这种方法可以灵活地根据所使用的 DL 模型的大小和所需的性能指标独立地改变计算与存储的比率。</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153：带有NVIDIA DGX A100 系统和 Mellanox Spectrum 以太网交换机的NetApp ONTAP AI。</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">有关ONTAP AI 的更多信息，请参阅<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">ONTAP 9.11 是NetApp最新一代存储管理软件，它支持企业实现基础架构现代化并过渡到云就绪数据中心。 ONTAP利用业界领先的数据管理功能，只需一套工具即可管理和保护数据，无论数据位于何处。您还可以将数据自由移动到任何需要的地方：边缘、核心或云端。  ONTAP 9.11 包含许多功能，可简化数据管理、加速和保护关键数据，并支持跨混合云架构的下一代基础架构功能。</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit 是一个 Python 库，可帮助开发人员、数据科学家、DevOps 工程师和数据工程师轻松执行各种数据管理任务，例如近乎即时地配置新的数据卷或 JupyterLab 工作区、近乎即时地克隆数据卷或 JupyterLab 工作区，以及近乎即时地拍摄数据卷或 JupyterLab 工作区的快照以进行可追溯性或基准测试。这个 Python 库可以作为命令行实用程序或函数库，您可以将其导入到任何 Python 程序或 Jupyter 笔记本中。</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton 推理服务器是一款开源推理服务软件，可帮助标准化模型部署和执行，以在生产中提供快速且可扩展的 AI。  Triton Inference Server 通过使团队能够在任何基于 GPU 或 CPU 的基础架构上从任何框架部署、运行和扩展经过训练的 AI 模型，简化了 AI 推理。  Triton Inference Server 支持所有主流框架，例如 TensorFlow、 NVIDIA TensorRT、PyTorch、MXNet、OpenVINO 等。 Triton 与 Kubernetes 集成，可进行编排和扩展，您可以在所有主要的公共云 AI 和 Kubernetes 平台中使用它。它还与许多 MLOps 软件解决方案集成。</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>是一个开源的 ML 框架。它是一个针对使用 GPU 和 CPU 的深度学习而优化的张量库。 PyTorch 包包含多维张量的数据结构，它提供了许多实用程序，用于高效序列化张量以及其他有用的实用程序。它还有一个 CUDA 对应物，使您能够在具有计算能力的NVIDIA GPU 上运行张量计算。在本次验证中，我们使用 OpenCV-Python (cv2) 库来验证我们的模型，同时利用 Python 最直观的计算机视觉概念。</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">性能和更低的延迟。  ONTAP以尽可能低的延迟提供尽可能高的吞吐量。</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">数据保护。ONTAP提供内置数据保护功能，并在所有平台上提供通用管理。</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">多租户和多因素身份验证。  ONTAP支持以最高级别的安全性共享基础设施资源。</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">无缝扩展和无中断运行。 ONTAP支持无中断地向现有控制器和横向扩展集群添加容量。客户可以升级到最新技术，例如 NVMe 和 32Gb FC，而无需昂贵的数据迁移或中断。</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra控制</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra控制服务</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra产品系列由NetApp存储和数据管理技术提供支持，为本地和公共云中的 Kubernetes 应用程序提供存储和应用程序感知数据管理服务。它使您能够轻松备份 Kubernetes 应用程序，将数据迁移到不同的集群，并立即创建可运行的应用程序克隆。如果您需要管理在公共云中运行的 Kubernetes 应用程序，请参阅<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>。  Astra Control Service 是一项NetApp托管服务，可为 Google Kubernetes Engine (GKE) 和 Azure Kubernetes Service (AKS) 中的 Kubernetes 集群提供应用程序感知数据管理。</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block>NetApp推出的一款适用于 Docker 和 Kubernetes 的开源动态存储编排器，可简化持久存储的创建、管理和使用。  Trident是一个 Kubernetes 原生应用程序，直接在 Kubernetes 集群中运行。  Trident使客户能够将 DL 容器映像无缝部署到NetApp存储上，并为 AI 容器部署提供企业级体验。  Kubernetes 用户（ML 开发人员、数据科学家等）可以创建、管理和自动化编排和克隆，以利用由NetApp技术提供支持的高级数据管理功能。</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>是NetApp 的一项快速、安全的数据同步服务。无论您需要在本地 NFS 或 SMB 文件共享、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google Cloud Storage 或 IBM Cloud Object Storage 之间传输文件， BlueXP Copy and Sync 都能快速安全地将文件移动到您需要的位置。数据传输完成后，可在源端和目标端完全使用。  BlueXP Copy 和 Syncc 根据您预先定义的计划持续同步数据，仅移动增量，从而最大限度地减少数据复制所花费的时间和金钱。  BlueXP Copy and Sync 是一种软件即服务 (SaaS) 工具，其设置和使用极其简单。 BlueXP Copy 和 Sync 触发的数据传输由数据代理执行。您可以在 AWS、Azure、Google Cloud Platform 或本地部署BlueXP Copy 和 Sync 数据代理。</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP分类</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">在强大的AI算法驱动下，<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block>为您的整个数据资产提供自动化控制和数据治理。您可以轻松找到节省成本的方法、识别合规性和隐私问题并找到优化机会。  BlueXP分类仪表板可让您洞察重复数据以消除冗余，映射个人、非个人和敏感数据，并针对敏感数据和异常情况发出警报。</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">数字图像处理具有许多优点，使许多组织能够充分利用与视觉表示相关的数据。 NetApp和 Protopia 解决方案提供了独特的 AI 推理设计，以在整个 ML/DL 生命周期中保护和私有化 AI/ML 数据。它使客户能够保留敏感数据的所有权，通过缓解与隐私相关的担忧，使用公共或混合云部署模型实现规模和效率，并在边缘部署人工智能推理。</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">环境情报</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">在环境危害领域，各行各业可以多种方式利用地理空间分析。政府和公共工程部门可以就公共卫生和天气状况获得可行的见解，以便在流行病或野火等自然灾害期间更好地为公众提供建议。例如，您可以在公共场所（例如机场或医院）识别 COVID 阳性患者，而不会损害受影响个人的隐私，并提醒相关部门和附近公众采取必要的安全措施。</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">边缘设备可穿戴设备</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">在军事和战场上，您可以使用边缘 AI 推理作为可穿戴设备来跟踪士兵的健康状况、监控驾驶员行为并向当局发出接近军用车辆的安全和相关风险警报，同时保护士兵的隐私。军队的未来将走向高科技，战场物联网 (IoBT) 和军事物联网 (IoMT) 将应用于可穿戴作战装备，帮助士兵通过使用快速边缘计算识别敌人并在战斗中表现得更好。保护和保存从无人机和可穿戴设备等边缘设备收集的视觉数据对于阻止黑客和敌人至关重要。</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">非战斗人员撤离行动</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">非战斗人员撤离行动 (NEO) 由国防部执行，旨在协助将生命受到威胁的美国公民和国民、国防部文职人员以及指定人员（东道国 (HN) 和第三国国民 (TCN)）撤离到适当的安全避难所。现有的行政控制措施主要采用手动的撤离人员筛选流程。然而，通过使用高度自动化的 AI/ML 工具结合 AI/ML 视频混淆技术，可以提高撤离人员识别、撤离人员跟踪和威胁筛查的准确性、安全性和速度。</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">医疗保健和生物医学研究</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">图像处理用于根据计算机断层扫描 (CT) 或磁共振成像 (MRI) 获得的 3D 图像诊断手术规划的病理。 HIPAA 隐私规则规定了组织如何收集、处理和删除所有个人信息和照片等数字图像。根据 HIPAA 安全港规定，要使数据符合可共享条件，必须删除正面照片和任何类似图像。用于从结构 CT/MR 图像中隐藏个人面部特征的去识别或颅骨剥离算法等自动化技术已成为生物医学研究机构数据共享过程的重要组成部分。</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI/ML分析的云迁移</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">数据保护</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">企业客户传统上在本地训练和部署 AI/ML 模型。出于规模经济和效率的原因，这些客户正在扩展以将 AI/ML 功能转移到公共、混合或多云部署中。然而，它们受到可以向其他基础设施公开的数据的限制。  NetApp解决方案可应对各种网络安全威胁，<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block>和安全评估，并与 Protopia 数据转换相结合，最大限度地降低将图像处理 AI/ML 工作负载迁移到云端所带来的风险。</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 边缘人工智能推理</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">情报与隐私</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">有关其他行业的边缘计算和 AI 推理的更多用例，请参阅<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block>以及NetApp AI 博客，<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> 。</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">Domino Data Lab 和NetApp的混合多云 MLOps - 在哪里可以找到更多信息</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">如何查找更多信息</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">多米诺数据实验室</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">Domino Nexus</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">NetApp ONTAP数据管理软件</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp AI 解决方案</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Domino Data Lab 技术联盟 SA 总监 Josh Mineroff</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski，Domino 数据实验室现场首席技术官</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan， NetApp解决方案架构师</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">NetApp技术联盟合作伙伴全球联盟总监 Brian Young</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">Domino Data Lab 和NetApp的混合多云 MLOps - 架构</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">该解决方案将 Domino Nexus 的混合多云工作负载调度功能与NetApp数据服务相结合，以创建统一的混合云 MLOps 平台。请参阅下表以了解详情。</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">环境</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps 控制平面</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Domino Enterprise AI 平台与 Domino Nexus</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">MLOps 平台计算环境</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus 数据平面</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS，本地数据中心</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">本地计算平台</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>和<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">本地数据中心</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">云计算平台</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">亚马逊弹性 Kubernetes 服务 (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>和<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">本地数据平台</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetApp存储设备</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>供电<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">云数据平台</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">Domino Data Lab 和NetApp的混合多云 MLOps - 跨不同环境访问相同数据</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">跨不同环境访问相同数据</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">本节描述了为了跨不同的计算环境访问相同数据需要执行的任务。在 Domino MLOps 平台中，计算环境被称为“数据平面”。如果您的数据驻留在一个数据平面的NetApp卷上，但您需要在另一个数据平面中访问它，请按照本节中概述的任务进行操作。这种场景通常被称为“爆发”，或者当目标环境是云时，被称为“云爆发”。在处理受限或超额订阅的计算资源时通常需要此功能。例如，如果您的本地计算集群超额订阅，您可能希望将工作负载安排到云端，以便立即启动它们。</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">有两种推荐的选项可用于访问位于不同数据平面的NetApp卷。这些选项在下面的小节中概述。根据您的具体要求选择其中一个选项。下表描述了这两个选项的优点和缺点。</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">选项</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">受益</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">缺点</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">选项 1 - 缓存</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- 更简单的工作流程 - 能够根据需要缓存数据子集 - 能够将数据写回源 - 无需管理远程副本</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- 由于缓存被水化，初始数据访问的延迟增加。</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">选项 2 - 镜像</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- 源卷的完整副本 - 不会因缓存混合而增加延迟（镜像操作完成后）</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- 必须等待镜像操作完成后才能访问数据 - 必须管理远程副本 - 无法写回源</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">选项 1 - 创建位于不同数据平面的卷的缓存</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCache 技术</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">和<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block>，您可以创建位于不同数据平面的NetApp卷的缓存。例如，如果您的本地数据平面中有一个NetApp卷，并且您需要在 AWS 数据平面中访问该卷，则可以在 AWS 中创建该卷的缓存。本节概述了创建位于不同数据平面的NetApp卷的缓存所需执行的任务。</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">在目标环境中创建FlexCache卷</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">如果目标环境是您的本地数据中心，您将在本地ONTAP系统上创建FlexCache卷。如果目标环境是 AWS，您将在Amazon FSx ONTAP实例上创建FlexCache卷。</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">首先，您必须在目标环境中创建一个FlexCache卷。</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP volume caching文档</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">我们建议使用BlueXP来创建FlexCache卷。要使用BlueXP创建FlexCache卷，请按照<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block>。</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">如果您不想使用BlueXP，则可以使用ONTAP System Manager 或ONTAP CLI 来创建FlexCache卷。要使用 System Manager 创建FlexCache卷，请参阅<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block>。要使用ONTAP CLI 创建FlexCache卷，请参阅<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block>。</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP Ansible 集合</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">如果您希望自动执行此过程，您可以使用<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block>， 这<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block>或<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block>。</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">系统管理器在Amazon FSx ONTAP中不可用。</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">将FlexCache卷公开给 Domino</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">“将现有NetApp卷公开给 Domino”部分</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">接下来，您必须将FlexCache卷公开给 Domino MLOps 平台。要将FlexCache卷公开给 Domino，请按照“公开未由Trident提供的现有 NFS 卷”子部分中概述的说明进行操作<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>此解决方案。</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">现在，您将能够在目标数据平面启动作业和工作区时挂载FlexCache卷，如以下屏幕截图所示。</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">创建FlexCache卷之前</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">将FlexCache卷暴露给 Domino 后</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">选项 2 - 复制位于不同数据平面的卷</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirror数据复制技术</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">和<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block>，您可以创建位于不同数据平面的NetApp卷的副本。例如，如果您的本地数据平面中有一个NetApp卷，并且您需要在 AWS 数据平面中访问该卷，则可以在 AWS 中创建该卷的副本。本节概述了创建位于不同数据平面的NetApp卷副本所需执行的任务。</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">创建 SnapMirror 关系</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">首先，您必须在源卷和目标环境中的新目标卷之间创建SnapMirror关系。请注意，目标卷将作为创建SnapMirror关系过程的一部分进行创建。</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP replication文档</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">我们建议使用BlueXP来创建SnapMirror关系。要与BlueXP创建SnapMirror关系，请按照<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block>。</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">如果您不想使用BlueXP，则可以使用ONTAP System Manager 或ONTAP CLI 来创建SnapMirror关系。要与 System Manager 创建SnapMirror关系，请参阅<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block>。要使用ONTAP CLI 创建SnapMirror关系，请参阅<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block>。</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">中断SnapMirror关系</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">接下来，您必须中断SnapMirror关系才能激活目标卷进行数据访问。等到初始复制完成后再执行此步骤。</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">您可以通过检查BlueXP、 ONTAP系统管理器或ONTAP CLI 中的镜像状态来确定复制是否完成。当复制完成后，镜像状态将为“snapmirrored”。</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">我们建议使用BlueXP来中断SnapMirror关系。要断开与BlueXP 的SnapMirror关系，请按照<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block>。</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">如果您不想使用BlueXP，则可以使用ONTAP System Manager 或ONTAP CLI 来中断SnapMirror关系。要断开与 System Manager 的SnapMirror关系，请参阅<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block>。要使用ONTAP CLI 断开SnapMirror关系，请参阅<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block>。</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">将目标卷公开给 Domino</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">接下来，您必须将目标卷公开给 Domino MLOps 平台。要将目标卷公开给 Domino，请按照“公开未由Trident提供的现有 NFS 卷”子部分中概述的说明进行操作<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>此解决方案。</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">现在，您将能够在目标数据平面启动作业和工作区时挂载目标卷，如下面的屏幕截图所示。</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">创建SnapMirror关系之前</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">将目标卷暴露给 Domino 后</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus 是一个单一玻璃窗格，可让您在任何计算集群（任何云、区域或本地）运行数据科学和机器学习工作负载。</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">Domino Data Lab 和NetApp的混合多云 MLOps</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">NetApp的 Mike Oglesby</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">目前，世界各地的组织都在采用人工智能来转变其业务和流程。因此，支持人工智能的计算基础设施通常供不应求。企业正在采用混合多云 MLOps 架构，以便利用不同区域、数据中心和云中的可用计算环境，平衡成本、可用性和性能。</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Data Lab 的 Domino Nexus 是一个统一的 MLOps 控制平面，可让您在任何计算集群（任何云、区域或本地）运行数据科学和机器学习工作负载。它统一了整个企业的数据科学孤岛，因此您可以在一个地方构建、部署和监控模型。同样，NetApp 的混合云数据管理功能使您能够将数据带到您的作业和工作区，无论它们在何处运行。将 Domino Nexus 与NetApp配对后，您可以灵活地跨环境安排工作负载，而不必担心数据可用性。换句话说，您可以将工作负载和数据发送到适当的计算环境，从而加速您的 AI 部署，同时遵守有关数据隐私和主权的法规。</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">该解决方案演示了统一 MLOps 控制平面的部署，该控制平面结合了本地 Kubernetes 集群和在 Amazon Web Services (AWS) 中运行的 Elastic Kubernetes Service (EKS) 集群。</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">采用 Domino Data Lab 和NetApp 的混合多云 MLOps - 初始设置</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">初始设置</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">本节介绍在包含本地数据中心和 AWS 的混合环境中使用 Domino Nexus 和NetApp数据服务所需执行的初始设置任务。</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">在执行本节中概述的步骤之前，我们假设您已经执行了以下任务：</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">您已经部署并配置了内部部署NetApp ONTAP存储平台。欲了解更多信息，请参阅<block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> 。</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Amazon FSx ONTAP产品页面</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">您已在 AWS 中配置了Amazon FSx ONTAP实例。欲了解更多信息，请参阅<block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> 。</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino 管理指南</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">您已经在本地数据中心配置了 Kubernetes 集群。欲了解更多信息，请参阅<block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">您已在 AWS 中配置了 Amazon EKS 集群。欲了解更多信息，请参阅<block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">NetApp Trident文档</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">您已在本地 Kubernetes 集群中安装了NetApp Trident 。此外，您已配置此Trident实例以在配置和管理存储资源时使用您的内部NetApp ONTAP存储平台。欲了解更多信息，请参阅<block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">您已在 Amazon EKS 集群中安装了NetApp Trident 。此外，您已配置此Trident实例以在配置和管理存储资源时使用您的Amazon FSx ONTAP实例。欲了解更多信息，请参阅<block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon 虚拟专用网络 (VPN) 文档</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">您的本地数据中心和 AWS 中的虚拟私有云 (VPC) 之间必须具有双向网络连接。有关实现此目的的各种选项的更多详细信息，请参阅<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block>。</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">在 AWS 中安装 Domino Enterprise AI 平台</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">要在 AWS 中安装 Domino Enterprise MLOps 平台，请按照<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block>。您必须在之前配置的同一 Amazon EKS 集群中部署 Domino。此外，必须已经在此 EKS 集群中安装和配置NetApp Trident ，并且您必须在 domino.yml 安装配置文件中指定 Trident 管理的存储类作为共享存储类。</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Domino 安装配置参考指南</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">请参阅<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block>有关如何在 domino.yml 安装配置文件中指定共享存储类的详细信息。</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">技术报告 TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>介绍如何使用Amazon FSx ONTAP在 AWS 中部署 Domino，这可以作为解决出现的任何问题的有用参考。</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">启用 Domino Nexus</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">接下来，您必须启用 Domino Nexus。请参阅<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block>了解详情。</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">在本地数据中心部署 Domino 数据平面</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">接下来，您必须在本地数据中心部署 Domino 数据平面。您必须在之前配置的本地 Kubernetes 集群中部署此数据平面。此外，必须已经在此 Kubernetes 集群中安装并配置了NetApp Trident 。请参阅<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block>了解详情。</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">Domino Data Lab 和NetApp的混合多云 MLOps - 技术概述</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">技术概述</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">本节提供了 Domino Data Lab 和NetApp的混合多云 MLOps 技术概述。</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab 通过其领先的企业 AI 平台为模型驱动型企业提供支持，该平台受到超过 20% 的财富 100 强企业的信赖。 Domino 加速了数据科学工作的开发和部署，同时增强了协作和治理。借助多米诺骨牌，世界各地的企业可以开发更好的药品、种植更高产的作物、制造更好的汽车等等。  Domino 成立于 2013 年，由 Coatue Management、Great Hill Partners、Highland Capital、Sequoia Capital 和其他领先投资者提供支持。</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino 让企业及其数据科学家能够在统一的端到端平台上快速、负责且经济高效地构建、部署和管理 AI。团队可以在任何环境中访问他们所需的所有数据、工具、计算、模型和项目，以便他们可以协作、重复使用过去的工作、跟踪生产中的模型以提高准确性、使用最佳实践进行标准化，并使 AI 负责任且受到管理。</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*开放且灵活：*访问最广泛的开源和商业工具及基础设施生态系统，获得最佳创新且不受供应商锁定。</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*记录系统*：整个企业的人工智能操作和知识的中心枢纽，支持最佳实践、跨职能协作、更快的创新和效率。</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*集成*：集成的工作流和自动化——专为企业流程、控制和治理而构建——满足您的合规性和监管需求。</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*混合多云：*在任何地方（本地、混合、任何云或多云）运行靠近数据的 AI 工作负载，以降低成本、实现最佳性能和合规性。</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus 是一个单一玻璃窗格，可让您在任何计算集群（任何云、区域或本地）运行数据科学和机器学习工作负载。它统一了整个企业的数据科学孤岛，因此您可以在一个地方构建、部署和监控模型。</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP将 NetApp 的所有存储和数据服务统一到一个工具中，让您可以构建、保护和管理混合多云数据资产。它为本地和云环境中的存储和数据服务提供统一的体验，并通过 AIOps 的强大功能实现操作简化，具有当今云主导世界所需的灵活消费参数和集成保护。</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">云连接。  ONTAP是与云连接最紧密的存储管理软件，在所有公共云中提供软件定义存储和云原生实例的选项。</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP是第一方完全托管的 AWS 服务，它基于 NetApp 流行的ONTAP文件系统构建，提供高度可靠、可扩展、高性能且功能丰富的文件存储。FSx ONTAP将NetApp文件系统的熟悉功能、性能、功能和 API 操作与完全托管的 AWS 服务的灵活性、可扩展性和简单性相结合。</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident支持在所有流行的NetApp存储平台上（无论是在公共云还是在本地）使用和管理存储资源，包括ONTAP （AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP）、Element 软件（NetApp HCI、 SolidFire）、 Azure NetApp Files服务和 Google Cloud 上的Google Cloud NetApp Volumes 。  Trident是一个符合容器存储接口 (CSI) 的动态存储编排器，可与 Kubernetes 原生集成。</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes 是一个开源的、分布式的容器编排平台，最初由 Google 设计，现在由云原生计算基金会 (CNCF) 维护。  Kubernetes 实现了容器化应用程序的部署、管理和扩展功能的自动化，是企业环境中占主导地位的容器编排平台。</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) 是 AWS 云中的托管 Kubernetes 服务。 Amazon EKS 自动管理负责调度容器、管理应用程序可用性、存储集群数据和其他关键任务的 Kubernetes 控制平面节点的可用性和可扩展性。借助 Amazon EKS，您可以利用 AWS 基础设施的所有性能、规模、可靠性和可用性，以及与 AWS 网络和安全服务的集成。</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">Domino Data Lab 和NetApp的混合多云 MLOps - 将现有NetApp卷暴露给 Domino</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">将现有NetApp卷公开给 Domino</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">本节介绍将现有NetApp ONTAP NFS 卷公开给 Domino MLOps 平台所需执行的任务。这些相同的步骤适用于本地和 AWS。</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">为什么要将NetApp ONTAP卷公开给 Domino？</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">将NetApp卷与 Domino 结合使用可带来以下好处：</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">您可以利用NetApp ONTAP 的横向扩展功能针对极大数据集执行工作负载。</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">您可以在多个计算节点上执行工作负载，而无需将数据复制到各个节点。</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">您可以利用 NetApp 的混合多云数据移动和同步功能来跨多个数据中心和/或云访问您的数据。</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">您希望能够快速轻松地在不同的数据中心或云中创建数据缓存。</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">公开未由Trident配置的现有 NFS 卷</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">如果您现有的NetApp ONTAP NFS 卷不是由Trident配置的，请按照本小节中概述的步骤进行操作。</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">在 Kubernetes 中创建 PV 和 PVC</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">对于本地卷，在本地 Kubernetes 集群中创建 PV 和 PVC。对于Amazon FSx ONTAP卷，在 Amazon EKS 中创建 PV 和 PVC。</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC 示例</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">首先，您必须在 Kubernetes 集群中创建持久卷 (PV) 和持久卷声明 (PVC)。要创建 PV 和 PVC，请使用<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block>从 Domino 管理指南中更新值以反映您的环境。确保为<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block>，<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> ， 和<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block>字段。此外，我们建议为您的 PV 和 PVC 提供唯一的名称，以代表存储在相应ONTAP NFS 卷上的数据的性质。例如，如果卷包含制造缺陷的图像，您可以将 PV 命名为<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block>以及 PVC，<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> 。</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">在 Domino 中注册外部数据卷</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">指示</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">接下来，您必须在 Domino 中注册一个外部数据卷。要注册外部数据卷，请参阅<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block>在 Domino 管理指南中。注册卷时，请确保从“卷类型”下拉菜单中选择“NFS”。选择“NFS”后，您应该会在“可用卷”列表中看到您的 PVC。</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">公开由Trident提供的现有卷</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">如果您现有的卷是由Trident配置的，请按照本小节中概述的步骤进行操作。</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">编辑现有 PVC</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">如果您的卷是由Trident配置的，那么您已经拥有与您的卷相对应的持久卷声明 (PVC)。为了将此卷公开给 Domino，您必须编辑 PVC 并将以下标签添加到<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block>场地：</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">接下来，您必须在 Domino 中注册一个外部数据卷。要注册外部数据卷，请参阅<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block>在 Domino 管理指南中。注册卷时，请务必从“卷类型”下拉菜单中选择“通用”。选择“通用”后，您应该会在“可用卷”列表中看到您的 PVC。</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware 合作 - 在哪里可以找到更多信息</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise 与 VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen， NetApp高级经理</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac， NetApp系统管理员</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">NetApp技术营销工程师 Roney Daniel</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware 合作 - 架构</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">该解决方案建立在经过验证且熟悉的架构之上，具有NetApp、VMware 和NVIDIA认证的系统。请参阅下表以了解详情。</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">人工智能和数据分析软件</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">适用于 VMware 的NVIDIA AI Enterprise</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">虚拟化平台</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">计算平台</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA认证系统</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">数据管理平台</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise 是一款端到端、云原生的 AI 和数据分析软件套件，经过优化，每个组织都可以借助 AI 取得成功。</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise 与NetApp和 VMware 合作</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">对于 IT 架构师和管理员来说，AI 工具可能很复杂且陌生。此外，许多人工智能平台尚未为企业做好准备。  NVIDIA AI Enterprise 由NetApp和 VMware 提供支持，旨在提供精简的企业级 AI 架构。</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware - 利用NVIDIA NGC 软件 - 设置</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">设置</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">本节介绍在NVIDIA AI Enterprise 环境中使用NVIDIA NGC 企业软件所需执行的初始设置任务。</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">在执行本节中概述的步骤之前，NVIDIA假设您已经按照<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block>页。</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">使用 vGPU 创建 Ubuntu Guest VM</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI 企业部署指南</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">首先，您必须创建一个带有 vGPU 的 Ubuntu 20.04 客户虚拟机。要创建带有 vGPU 的 Ubuntu 20.04 来宾虚拟机，请按照<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block>。</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">下载并安装NVIDIA客户软件</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise 快速入门指南</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">接下来，您必须在上一步创建的客户虚拟机中安装所需的NVIDIA客户软件。要在客户虚拟机中下载并安装所需的NVIDIA客户软件，请按照<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">执行第 5.4 节中概述的验证任务时，您可能需要使用不同的 CUDA 容器映像版本标签，因为自编写指南以来 CUDA 容器映像已更新。在我们的验证中，我们使用了“nvidia/cuda:11.0.3-base-ubuntu20.04”。</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">下载 AI/分析框架容器</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">接下来，您必须从NVIDIA NGC 下载所需的 AI 或分析框架容器映像，以便它们可以在您的客户虚拟机中使用。要在客户虚拟机中下载框架容器，请按照<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block>。</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">安装和配置NetApp DataOps 工具包</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">接下来，您必须在来宾虚拟机中安装适用于传统环境的NetApp DataOps Toolkit。 NetApp DataOps Toolkit 可用于直接从客户虚拟机内的终端管理ONTAP系统上的横向扩展数据卷。要在客户虚拟机中安装NetApp DataOps Toolkit，请执行以下任务。</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">安装 pip。</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">注销客户 VM 终端，然后重新登录。</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">配置NetApp DataOps 工具包。为了完成此步骤，您将需要ONTAP系统的 API 访问详细信息。您可能需要从存储管理员处获取这些信息。</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">创建来宾虚拟机模板</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">最后，您必须根据您的客户虚拟机创建一个虚拟机模板。您将能够使用此模板快速创建用于利用NVIDIA NGC 软件的客户虚拟机。</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">要根据您的来宾 VM 创建 VM 模板，请登录 VMware vSphere，右键单击来宾 VM 名称，选择“克隆”，选择“克隆到模板...”，然后按照向导进行操作。</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware - 初始设置</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">本节介绍了将NVIDIA AI Enterprise 与NetApp和 VMware 结合使用所需执行的初始设置任务。</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise 产品支持矩阵</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetApp和 VMware 解决方案文档</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">在执行本节概述的步骤之前，我们假设您已经部署了 VMware vSphere 和NetApp ONTAP。请参阅<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block>有关受支持的 vSphere 版本的详细信息。请参阅<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block>有关使用NetApp ONTAP部署 VMware vSphere 的详细信息。</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">安装NVIDIA AI Enterprise Host 软件</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">要安装NVIDIA AI Entrprise 主机软件，请按照<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>。</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware 合作 - 技术概述</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">本节概述了NVIDIA AI Enterprise 与NetApp和 VMware 的技术。</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise 是一款端到端、云原生的 AI 和数据分析软件套件，经过NVIDIA优化、认证和支持，可在具有NVIDIA认证系统的 VMware vSphere 上运行。该软件有助于在现代混合云环境中简单、快速地部署、管理和扩展 AI 工作负载。</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC 为 AI 从业者提供了一系列针对 GPU 优化的软件，以开发他们的 AI 解决方案。它还提供对各种 AI 服务的访问，包括用于模型训练的NVIDIA Base Command、用于部署和监控模型的NVIDIA Fleet Command 以及用于安全访问和管理专有 AI 软件的 NGC Private Registry。此外， NVIDIA AI Enterprise 客户可以通过 NGC 门户请求支持。</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere 是 VMware 的虚拟化平台，它将数据中心转变为包含 CPU、存储和网络资源的聚合计算基础架构。vSphere 将这些基础架构作为统一的操作环境进行管理，并为管理员提供管理该环境中数据中心的工具。</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere 的两个核心组件是 ESXi 和 vCenter Server。  ESXi 是管理员创建和运行虚拟机及虚拟设备的虚拟化平台。vCenter Server 是管理员管理网络中连接的多台主机并池化主机资源的服务。</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit 是一款基于 Python 的工具，可简化由高性能、横向扩展NetApp存储支持的开发/培训工作区和推理服务器的管理。主要功能包括：</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">近乎即时地克隆高容量的 JupyterLab 工作区，以实现实验或快速迭代。</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">近乎即时地保存高容量 JupyterLab 工作区的快照，以用于备份和/或可追溯性/基准测试。</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">近乎即时地提供、克隆和快照大容量、高性能数据卷。</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NVIDIA AI Enterprise 与NetApp和 VMware 合作 - 利用NVIDIA NGC 软件 - 示例用例 - TensorFlow 训练作业</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">示例用例 - TensorFlow 训练作业</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">本节介绍在NVIDIA AI Enterprise 环境中执行 TensorFlow 训练作业需要执行的任务。</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">在执行本节中概述的步骤之前，我们假设您已经按照<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block>页。</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">从模板创建来宾虚拟机</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">首先，您必须根据上一节中创建的模板创建一个新的客户虚拟机。要从模板创建新的客户虚拟机，请登录 VMware vSphere，右键单击模板名称，选择“从此模板新建虚拟机...”，然后按照向导操作。</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">创建并挂载数据卷</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">接下来，您必须创建一个新的数据卷来存储您的训练数据集。您可以使用NetApp DataOps Toolkit 快速创建新的数据卷。下面的示例命令显示创建一个名为“imagenet”、容量为 2 TB 的卷。</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">在您用数据填充数据卷之前，您必须将其安装在来宾虚拟机中。您可以使用NetApp DataOps Toolkit 快速安装数据卷。下面的示例命令显示了上一步中创建的卷的安装。</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">填充数据量</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">在配置并安装新卷后，可以从源位置检索训练数据集并将其放置在新卷上。这通常涉及从 S3 或 Hadoop 数据湖中提取数据，有时还需要数据工程师的帮助。</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">执行 TensorFlow 训练作业</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">现在，您已准备好执行 TensorFlow 训练作业。要执行 TensorFlow 训练作业，请执行以下任务。</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">拉取NVIDIA NGC 企业 TensorFlow 容器镜像。</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">启动NVIDIA NGC 企业 TensorFlow 容器的实例。使用“-v”选项将数据卷附加到容器。</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">在容器内执行您的 TensorFlow 训练程序。下面的示例命令展示了容器镜像中包含的示例 ResNet-50 训练程序的执行。</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">NetApp开源 MLOps - Apache Airflow 部署</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow 部署</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">本节介绍在 Kubernetes 集群中部署 Airflow 必须完成的任务。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">可以在 Kubernetes 以外的平台上部署 Airflow。在 Kubernetes 以外的平台上部署 Airflow 超出了本解决方案的范围。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">在执行本节概述的部署练习之前，我们假设您已经执行了以下任务：</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">您已经有一个可以运行的 Kubernetes 集群。</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Trident文档</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">您已经在 Kubernetes 集群中安装并配置了NetApp Trident 。有关Trident的更多详细信息，请参阅<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block>。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">安装 Helm</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">安装说明</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow 使用 Helm（Kubernetes 的流行包管理器）进行部署。在部署 Airflow 之前，必须在部署跳转主机上安装 Helm。要在部署跳转主机上安装 Helm，请按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文档中。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">设置默认 Kubernetes StorageClass</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow部署</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">在部署 Airflow 之前，您必须在 Kubernetes 集群中指定一个默认 StorageClass。 Airflow 部署过程尝试使用默认 StorageClass 来配置新的持久卷。如果没有指定 StorageClass 作为默认 StorageClass，则部署失败。要在集群中指定默认 StorageClass，请按照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已经在集群中指定了默认 StorageClass，则可以跳过此步骤。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">使用 Helm 部署 Airflow</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">要使用 Helm 在 Kubernetes 集群中部署 Airflow，请从部署跳转主机执行以下任务：</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">部署说明</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">按照以下说明使用 Helm 部署 Airflow<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block>查看 Artifact Hub 上的官方 Airflow 图表。下面的示例命令展示了使用 Helm 部署 Airflow。修改、添加和/或删除<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block>根据您的环境和所需配置，根据需要创建文件。</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">确认所有 Airflow pod 均已启动并正在运行。所有 pod 启动可能需要几分钟时间。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">按照步骤 1 中使用 Helm 部署 Airflow 时打印到控制台的说明获取 Airflow Web 服务 URL。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">确认您可以访问 Airflow Web 服务。</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">NetApp的开源 MLOps - 将NetApp DataOps 工具包与 Airflow 结合使用</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">将NetApp DataOps 工具包与 Airflow 结合使用</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">这<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block>可以与 Airflow 结合使用。将NetApp DataOps Toolkit 与 Airflow 结合使用，您可以将NetApp数据管理操作（例如创建快照和克隆）合并到由 Airflow 协调的自动化工作流程中。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">气流示例</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">请参阅<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block>有关将该工具包与 Airflow 结合使用的详细信息，请参阅NetApp DataOps Toolkit GitHub 存储库中的部分。</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">NetApp的开源 MLOps - 架构</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">该解决方案不依赖于特定的硬件。该解决方案与NetApp Trident支持的任何NetApp物理存储设备、软件定义实例或云服务兼容。示例包括NetApp AFF存储系统、 Amazon FSx ONTAP、 Azure NetApp Files、 Google Cloud NetApp Volumes或NetApp Cloud Volumes ONTAP实例。此外，只要所使用的 Kubernetes 版本受到NetApp Trident和正在实施的其他解决方案组件的支持，该解决方案就可以在任何 Kubernetes 集群上实施。有关Trident支持的 Kubernetes 版本列表，请参阅<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block>。有关用于验证此解决方案的各个组件的环境的详细信息，请参阅下表。</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Apache Airflow 验证环境</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">软件组件</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apache Airflow</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Apache Airflow Helm 图表</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1，通过以下方式部署<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block>8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1.18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21.01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">JupyterHub 验证环境</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">JupyterHub</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">JupyterHub Helm 图表</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5，通过部署<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block>3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1.29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24.02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">MLflow 验证环境</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">机器学习流</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">MLflow Helm 图表</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1，通过部署<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block>1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Kubeflow 验证环境</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">部署KF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7，通过部署<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block>0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1.26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23.07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">支持</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">联系NetApp</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp不为 Apache Airflow、JupyterHub、MLflow、Kubeflow 或 Kubernetes 提供企业支持。如果您对完全支持的 MLOps 平台感兴趣，<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block>了解NetApp与合作伙伴联合提供的全面支持的 MLOps 解决方案。</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">NetApp的开源 MLOps - 技术概述</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">本节重点介绍NetApp的 OpenSource MLOps 技术概述。</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工智能</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">人工智能是一门计算机科学学科，其中计算机经过训练可以模仿人类思维的认知功能。人工智能开发人员训练计算机以类似于人类甚至优于人类的方式学习和解决问题。深度学习和机器学习是人工智能的子领域。越来越多的组织采用 AI、ML 和 DL 来支持其关键业务需求。以下是一些示例：</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">分析大量数据以发掘以前未知的商业见解</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">使用自然语言处理直接与客户互动</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">自动化各种业务流程和功能</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">现代人工智能训练和推理工作负载需要大规模并行计算能力。因此，GPU 越来越多地被用于执行 AI 操作，因为 GPU 的并行处理能力远远优于通用 CPU。</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">容器</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">容器是在共享主机操作系统内核上运行的隔离的用户空间实例。容器的采用正在迅速增加。容器提供许多与虚拟机 (VM) 相同的应用程序沙盒优势。然而，由于虚拟机所依赖的虚拟机管理程序和客户操作系统层已被消除，因此容器变得更加轻量级。下图描述了虚拟机与容器的可视化。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 网站</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">容器还允许直接将应用程序依赖项、运行时间等与应用程序高效地打包在一起。最常用的容器打包格式是Docker容器。以 Docker 容器格式容器化的应用程序可以在任何可以运行 Docker 容器的机器上执行。即使应用程序的依赖项不存在于机器上，情况也是如此，因为所有依赖项都打包在容器本身中。欲了解更多信息，请访问<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>。</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes 网站</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes 是一个开源的、分布式的容器编排平台，最初由 Google 设计，现在由云原生计算基金会 (CNCF) 维护。 Kubernetes 支持容器化应用程序的部署、管理和扩展功能的自动化。近年来，Kubernetes 已经成为主流的容器编排平台。欲了解更多信息，请访问<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>。</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>支持在所有流行的NetApp存储平台上（公共云或内部）使用和管理存储资源，包括ONTAP （AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP）、 Azure NetApp Files服务和Google Cloud NetApp Volumes。  Trident是一个符合容器存储接口 (CSI) 的动态存储编排器，可与 Kubernetes 原生集成。</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">这<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block>是一个基于 Python 的工具，可简化由高性能、横向扩展NetApp存储支持的开发/培训工作区和推理服务器的管理。主要功能包括：</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">快速配置由高性能、横向扩展NetApp存储支持的全新高容量工作区。</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">近乎即时地克隆高容量工作区，以实现实验或快速迭代。</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">近乎即时地保存高容量工作区的快照，以用于备份和/或可追溯性/基准测试。</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow 是一个开源工作流管理平台，支持以编程方式编写、调度和监控复杂的企业工作流。它通常用于自动化 ETL 和数据管道工作流程，但并不局限于这些类型的工作流程。  Airflow 项目由 Airbnb 发起，但后来在业界变得非常流行，现在由 Apache 软件基金会赞助。 Airflow 是用 Python 编写的，Airflow 工作流是通过 Python 脚本创建的，并且 Airflow 是在“配置即代码”的原则下设计的。许多企业 Airflow 用户现在在 Kubernetes 上运行 Airflow。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">有向无环图（DAG）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">在 Airflow 中，工作流被称为有向无环图 (DAG)。  DAG 由按顺序、并行或两者结合执行的任务组成，具体取决于 DAG 定义。  Airflow 调度程序在一组工作器上执行各个任务，遵守 DAG 定义中指定的任务级依赖关系。  DAG 是通过 Python 脚本定义和创建的。</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Jupyter 笔记本</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter 网站</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Jupyter Notebooks 是类似 wiki 的文档，包含实时代码和描述性文本。 Jupyter Notebooks 在 AI 和 ML 社区中被广泛用作记录、存储和共享 AI 和 ML 项目的一种方式。有关 Jupyter Notebooks 的更多信息，请访问<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>。</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter Notebook 服务器</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Jupyter Notebook 服务器是一个开源 Web 应用程序，允许用户创建 Jupyter Notebook。</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">JupyterHub 网站</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub 是一个多用户应用程序，允许个人用户配置和访问他们自己的 Jupyter Notebook 服务器。有关 JupyterHub 的更多信息，请访问<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block>。</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">MLflow 网站</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow 是一个流行的开源 AI 生命周期管理平台。 MLflow 的主要功能包括 AI/ML 实验跟踪和 AI/ML 模型库。有关 MLflow 的更多信息，请访问<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block>。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 网站</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow 是 Kubernetes 的开源 AI 和 ML 工具包，最初由 Google 开发。  Kubeflow 项目使 Kubernetes 上 AI 和 ML 工作流的部署变得简单、可移植且可扩展。 Kubeflow 抽象了 Kubernetes 的复杂性，使数据科学家能够专注于他们最了解的领域——数据科学。请参见下图以了解可视化效果。对于喜欢一体化 MLOps 平台的组织来说，Kubeflow 是一个不错的开源选择。欲了解更多信息，请访问<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>。</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow 管道</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow 官方文档</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Kubeflow Pipelines 是 Kubeflow 的关键组件。 Kubeflow Pipelines 是一个用于定义和部署可移植、可扩展的 AI 和 ML 工作流的平台和标准。有关详细信息，请参阅<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block>。</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Kubeflow 笔记本</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow 简化了 Kubernetes 上 Jupyter Notebook 服务器的配置和部署。有关 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，请参阅<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block>。</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">卡提布</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib 是一个用于自动化机器学习 (AutoML) 的 Kubernetes 原生项目。  Katib 支持超参数调整、早期停止和神经架构搜索 (NAS)。 Katib 是一个与机器学习 (ML) 框架无关的项目。它可以调整用户选择的任何语言编写的应用程序的超参数，并且原生支持许多 ML 框架，例如 TensorFlow、MXNet、PyTorch、XGBoost 等。 Katib 支持许多不同的 AutoML 算法，例如贝叶斯优化、Parzen 估计器树、随机搜索、协方差矩阵自适应进化策略、超频、高效神经架构搜索、可微分架构搜索等等。有关 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，请参阅<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block>。</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">无缝扩展和无中断运行。 ONTAP支持无中断地向现有控制器和横向扩展集群添加容量。客户可以升级到最新技术，而无需昂贵的数据迁移或中断。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot 副本</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp Snapshot 副本是卷的只读、时间点映像。该图像占用的存储空间极小，并且产生的性能开销可以忽略不计，因为它仅记录自上次 Snapshot 副本创建以来对文件的更改，如下图所示。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">Snapshot 副本的效率归功于核心ONTAP存储虚拟化技术，即任意位置写入文件布局 (WAFL)。与数据库一样， WAFL使用元数据指向磁盘上的实际数据块。但是，与数据库不同， WAFL不会覆盖现有块。它将更新的数据写入新块并更改元数据。这是因为ONTAP在创建 Snapshot 副本时引用元数据，而不是复制数据块，所以 Snapshot 副本非常高效。这样做可以消除其他系统在定位要复制的块时产生的寻道时间，以及复制本身的成本。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">您可以使用 Snapshot 副本来恢复单个文件或 LUN，或者还原卷的全部内容。  ONTAP将 Snapshot 副本中的指针信息与磁盘上的数据进行比较，以重建丢失或损坏的对象，而无需停机或造成显著的性能成本。</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone 技术</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone技术参考 Snapshot 元数据来创建卷的可写时间点副本。副本与其父级共享数据块，除了元数据所需的存储空间外，不消耗任何存储空间，直到将更改写入副本为止，如下图所示。传统的复制可能需要几分钟甚至几小时才能创建，而FlexClone软件可以让您几乎立即复制最大的数据集。这使得它非常适合需要相同数据集的多个副本（例如，开发工作区）或数据集的临时副本（针对生产数据集测试应用程序）的情况。</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror数据复制技术</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror软件是一种跨数据结构的经济高效、易于使用的统一复制解决方案。它通过 LAN 或 WAN 高速复制数据。它为所有类型的应用程序（包括虚拟和传统环境中的关键业务应用程序）提供高数据可用性和快速数据复制。当您将数据复制到一个或多个NetApp存储系统并不断更新辅助数据时，您的数据将保持最新状态并可随时使用。不需要外部复制服务器。下图是利用SnapMirror技术的架构示例。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror软件通过网络仅发送更改的块来利用NetApp ONTAP存储效率。 SnapMirror软件还使用内置网络压缩来加速数据传输并将网络带宽利用率降低高达 70%。借助SnapMirror技术，您可以利用一个精简复制数据流来创建一个存储库，该存储库同时维护活动镜像和之前的时间点副本，从而将网络流量减少高达 50%。</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>是NetApp 的一项快速、安全的数据同步服务。无论您需要在本地 NFS 或 SMB 文件共享、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、AWS S3、AWS EFS、Azure Blob、Google Cloud Storage 还是 IBM Cloud Object Storage 之间传输文件， BlueXP Copy and Sync 都能快速安全地将文件移动到您需要的位置。</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">数据传输完成后，可在源端和目标端完全使用。 BlueXP Copy and Sync 可以在触发更新时按需同步数据，或者根据预定义的时间表连续同步数据。无论如何， BlueXP Copy and Sync 仅移动增量，因此在数据复制上花费的时间和金钱被最小化。</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync 是一种软件即服务 (SaaS) 工具，其设置和使用极其简单。  BlueXP Copy 和 Sync 触发的数据传输由数据代理执行。  BlueXP Copy 和 Sync 数据代理可以部署在 AWS、Azure、Google Cloud Platform 或本地。</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>是一款基于客户端的软件，用于任意到NetApp和NetApp到NetApp 的数据迁移和文件系统洞察。  XCP 旨在通过利用所有可用的系统资源来处理大容量数据集和高性能迁移，从而实现扩展并实现最大性能。  XCP 可帮助您全面了解文件系统，并提供生成报告的选项。</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup卷</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">训练数据集可能包含数十亿个文件。文件可以包括文本、音频、视频和其他形式的非结构化数据，这些数据必须存储和处理才能并行读取。存储系统必须存储大量小文件，并且必须并行读取这些文件以实现顺序和随机 I/O。</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup卷是一个由多个组成成员卷组成的单一命名空间，如下图所示。从存储管理员的角度来看， FlexGroup卷的管理和行为类似于NetApp FlexVol volume。 FlexGroup卷中的文件被分配给各个成员卷，并且不会跨卷或节点进行条带化。它们支持以下功能：</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup卷为高元数据工作负载提供了数 PB 的容量和可预测的低延迟。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">它们支持同一命名空间中最多 4000 亿个文件。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">它们支持跨 CPU、节点、聚合体和组成FlexVol卷的 NAS 工作负载的并行操作。</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">该解决方案旨在演示可纳入 MLOps 工作流的几种不同的开源工具和框架。根据需求和用例，这些不同的工具和框架可以一起使用或单独使用。</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">NetApp的开源 MLOps</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby， NetApp Sufian Ahmad， NetApp Rick Huang， NetApp Mohan Acharya， NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">各种规模和各个行业的公司和组织都在转向人工智能 (AI) 来解决现实世界的问题、提供创新的产品和服务，并在竞争日益激烈的市场中占据优势。许多组织正在转向开源 MLOps 工具，以跟上行业快速创新的步伐。这些开源工具提供了先进的功能和尖端的特性，但通常不考虑数据可用性和数据安全性。不幸的是，这意味着高技能的数据科学家被迫花费大量时间等待获取数据或等待基本的数据相关操作完成。通过将流行的开源 MLOps 工具与NetApp的智能数据基础架构相结合，组织可以加速其数据管道，从而加速其 AI 计划。他们可以从数据中释放价值，同时确保数据受到保护且安全。该解决方案展示了NetApp数据管理功能与几种流行的开源工具和框架的配对，以应对这些挑战。</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">以下列表重点介绍了此解决方案支持的一些关键功能：</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">用户可以快速配置由高性能、横向扩展NetApp存储支持的新的高容量数据卷和开发工作区。</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">用户可以几乎即时地克隆大容量数据卷和开发工作区，以便进行实验或快速迭代。</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">用户可以几乎即时保存大容量数据卷和开发工作区的快照，以进行备份和/或可追溯性/基准测试。</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Jupyter 笔记本</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">典型的 MLOps 工作流程包含开发工作区，通常采用以下形式<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block>；实验跟踪；自动化训练管道；数据管道；以及推理/部署。该解决方案重点介绍了几种不同的工具和框架，它们可以独立使用或结合使用来解决工作流程的不同方面。我们还展示了NetApp数据管理功能与每种工具的配对。该解决方案旨在提供构建模块，组织可据此构建针对其用例和要求的定制 MLOps 工作流程。</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">此解决方案涵盖以下工具/框架：</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">以下列表描述了独立或联合部署这些工具的常见模式。</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">联合部署 JupyterHub、MLflow 和 Apache Airflow - JupyterHub<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、用于实验跟踪的 MLflow 以及用于自动化训练和数据管道的 Apache Airflow。</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">联合部署 Kubeflow 和 Apache Airflow - Kubeflow<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、实验跟踪、自动化训练管道和推理；以及用于数据管道的 Apache Airflow。</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">将 Kubeflow 部署为一体化 MLOps 平台解决方案<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block>、实验跟踪、自动化训练和数据管道以及推理。</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">NetApp开源 MLOps - JupyterHub 部署</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">JupyterHub 部署</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">本节介绍在 Kubernetes 集群中部署 JupyterHub 必须完成的任务。</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">可以在 Kubernetes 以外的平台上部署 JupyterHub。在 Kubernetes 以外的平台上部署 JupyterHub 超出了本解决方案的范围。</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">您已经在 Kubernetes 集群中安装并配置了NetApp Trident 。有关Trident的更多详细信息，请参阅<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub 使用 Helm（Kubernetes 的流行包管理器）进行部署。在部署 JupyterHub 之前，您必须在 Kubernetes 控制节点上安装 Helm。要安装 Helm，请按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文档中。</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">在部署 JupyterHub 之前，您必须在 Kubernetes 集群中指定一个默认 StorageClass。要在集群中指定默认 StorageClass，请按照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已经在集群中指定了默认 StorageClass，则可以跳过此步骤。</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">部署 JupyterHub</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">完成上述步骤后，您现在可以部署 JupyterHub。  JupyterHub 部署需要以下步骤：</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">配置 JupyterHub 部署</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">在部署之前，最好针对各自的环境优化 JupyterHub 部署。您可以创建一个 *config.yaml* 文件并在使用 Helm 图表部署期间使用它。</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">可以在以下位置找到示例 *config.yaml* 文件<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">在此 config.yaml 文件中，您可以为NetApp Trident StorageClass 设置 *(singleuser.storage.dynamic.storageClass)* 参数。这是用于为各个用户工作区配置卷的存储类。</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">添加共享卷</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">如果您想为所有 JupyterHub 用户使用共享卷，您可以相应地调整您的 *config.yaml*。例如，如果您有一个名为 jupyterhub-shared-volume 的共享 PersistentVolumeClaim，则可以将其作为 /home/shared 挂载在所有用户 pod 中，如下所示：</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">这是可选步骤，您可以根据需要调整这些参数。</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">使用 Helm Chart 部署 JupyterHub</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">让 Helm 了解 JupyterHub Helm 图表存储库。</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">这应该显示如下输出：</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">现在通过从包含您的 config.yaml 的目录运行以下命令来安装由您的 config.yaml 配置的图表：</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">在此示例中：</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; 设置为 my-jupyterhub，这将是您的 JupyterHub 版本的名称。 &lt;k8s-namespace&gt; 设置为 my-namespace，这是您要安装 JupyterHub 的命名空间。如果命名空间不存在，则使用 --create-namespace 标志来创建命名空间。  --values 标志指定包含所需配置选项的 config.yaml 文件。</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">检查部署</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">在步骤 2 运行时，您可以通过以下命令看到正在创建的 pod：</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">等待 hub 和 proxy pod 进入 Running 状态。</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">访问 JupyterHub</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">找到我们可以用来访问 JupyterHub 的 IP。运行以下命令，直到代理公共服务的 EXTERNAL-IP 可用，如示例输出所示。</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">我们在 config.yaml 文件中使用了 NodePort 服务，您可以根据您的设置（例如 LoadBalancer）调整您的环境。</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">要使用 JupyterHub，请在浏览器中输入代理公共服务的外部 IP。</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">NetApp的开源 MLOps - 将NetApp DataOps 工具包与 JupyterHub 结合使用</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">将NetApp DataOps 工具包与 JupyterHub 结合使用</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">这<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>可以与 JupyterHub 结合使用。通过将NetApp DataOps Toolkit 与 JupyterHub 结合使用，最终用户可以直接在 Jupyter Notebook 中创建用于工作区备份和/或数据集到模型可追溯性的卷快照。</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">在将 DataOps Toolkit 与 JupyterHub 一起使用之前，您必须向 JupyterHub 分配给各个用户 Jupyter Notebook Server pod 的 Kubernetes 服务帐户授予适当的权限。  JupyterHub 使用由<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block>JupyterHub Helm 图表配置文件中的变量。</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">为 DataOps Toolkit 创建集群角色</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">首先，创建一个名为“netapp-dataops”的集群角色，该角色具有创建卷快照所需的 Kubernetes API 权限。</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">将集群角色分配给笔记本服务器服务帐户</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">创建一个角色绑定，将“netapp-dataops-snapshots”集群角色分配给适当命名空间中的适当服务帐户。例如，如果您在“jupyterhub”命名空间中安装了 JupyterHub，并且通过以下方式指定了“默认”服务帐户<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block>变量，您需要将“netapp-dataops-snapshots”集群角色分配给“jupyterhub”命名空间中的“默认”服务帐户，如下例所示。</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">在 Jupyter Notebook 中创建卷快照</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">现在，JupyterHub 用户可以使用NetApp DataOps Toolkit 直接从 Jupyter Notebook 中创建卷快照，如下例所示。</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">使用NetApp SnapMirror提取数据</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">使用NetApp SnapMirror将数据导入 JupyterHub</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror是一种复制技术，可让您在NetApp存储系统之间复制数据。  SnapMirror可用于将数据从远程环境提取到 JupyterHub。</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">示例工作流程和演示</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">此 Tech ONTAP博客文章</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">参考<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block>有关使用NetApp SnapMirror将数据导入 JupyterHub 的详细示例工作流程和演示。</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">NetApp开源 MLOps - Kubeflow 部署</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">本节介绍在 Kubernetes 集群中部署 Kubeflow 必须完成的任务。</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">您已经有一个可运行的 Kubernetes 集群，并且您正在运行您打算部署的 Kubeflow 版本支持的 Kubernetes 版本。有关受支持的 Kubernetes 版本列表，请参阅 Kubeflow 版本的依赖项<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block>。</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">在部署 Kubeflow 之前，我们建议在 Kubernetes 集群中指定一个默认 StorageClass。 Kubeflow 部署过程可能会尝试使用默认 StorageClass 配置新的持久卷。如果没有指定 StorageClass 作为默认 StorageClass，则部署可能会失败。要在集群中指定默认 StorageClass，请从部署跳转主机执行以下任务。如果您已经在集群中指定了默认 StorageClass，则可以跳过此步骤。</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">将现有 StorageClass 之一指定为默认 StorageClass。以下示例命令显示了名为<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block>作为默认的 StorageClass。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">这<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>Trident Backend 类型的最小 PVC 尺寸相当大。默认情况下，Kubeflow 尝试配置大小仅为几 GB 的 PVC。因此，您不应该指定使用<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>后端类型作为 Kubeflow 部署的默认 StorageClass。</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Kubeflow部署选项</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">部署 Kubeflow 有很多不同的选择。请参阅<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block>获取部署选项列表，然后选择最适合您需求的选项。</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">为了验证目的，我们使用以下方式部署了 Kubeflow 1.7<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1。</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">NetApp开源 MLOps - 将NetApp DataOps 工具包与 Kubeflow 结合使用</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">将NetApp DataOps 工具包与 Kubeflow 结合使用</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">适用于 Kubernetes 的NetApp数据科学工具包</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">这<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block>可以与Kubeflow结合使用。将NetApp数据科学工具包与 Kubeflow 结合使用可带来以下好处：</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">数据科学家可以直接在 Jupyter Notebook 中执行高级NetApp数据管理操作，例如创建快照和克隆。</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">可以使用 Kubeflow Pipelines 框架将高级NetApp数据管理操作（例如创建快照和克隆）纳入自动化工作流程。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 示例</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">请参阅<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block>有关将该工具包与 Kubeflow 结合使用的详细信息，请参阅NetApp数据科学工具包 GitHub 存储库中的部分。</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">NetApp的开源 MLOps - 为数据科学家或开发人员提供 Jupyter Notebook 工作区</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">为数据科学家或开发人员提供 Jupyter Notebook 工作区</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow 能够快速配置新的 Jupyter Notebook 服务器作为数据科学家工作区。有关 Kubeflow 上下文中的 Jupyter Notebooks 的更多信息，请参阅<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>。</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">NetApp开源 MLOps - 示例工作流程 - 使用 Kubeflow 和NetApp DataOps 工具包训练图像识别模型</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">示例工作流程 - 使用 Kubeflow 和NetApp DataOps 工具包训练图像识别模型</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">本节介绍使用 Kubeflow 和NetApp DataOps Toolkit 训练和部署用于图像识别的神经网络的步骤。这旨在作为示例来展示结合NetApp存储的训练作业。</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">创建一个包含所需配置的 Dockerfile，用于 Kubeflow 管道内的训练和测试步骤。以下是 Dockerfile 的一个示例 -</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">根据您的要求，安装运行程序所需的所有必需库和包。在训练机器学习模型之前，假设您已经有一个可运行的 Kubeflow 部署。</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">使用 PyTorch 和 Kubeflow Pipelines 在 MNIST 数据上训练小型 NN</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">我们使用在 MNIST 数据上训练的小型神经网络作为示例。 MNIST 数据集由 0-9 的手写数字图像组成。图像尺寸为 28x28 像素。该数据集分为 60,000 张训练图像和 10,000 张验证图像。本实验所采用的神经网络是一个2层前馈网络。训练是使用 Kubeflow Pipelines 执行的。请参阅文档<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block>了解更多信息。我们的 Kubeflow 管道包含了先决条件部分的 docker 镜像。</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Kubeflow 管道运行可视化</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">使用 Tensorboard 可视化结果</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">Tensorboard</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">一旦模型训练完成，我们就可以使用 Tensorboard 将结果可视化。<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block>作为 Kubeflow 仪表板上的一项功能提供。您可以为您的工作创建自定义张量板。下面的示例展示了训练准确度与时期数以及训练损失与时期数的关系图。</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">训练损失和准确率的 Tensorboard 图表</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">使用 Katib 进行超参数实验</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>是 Kubeflow 中的一个工具，可用于试验模型超参数。要创建实验，首先要定义所需的指标/目标。这通常是测试准确度。一旦定义了指标，选择您想要使用的超参数（优化器/学习率/层数）。 Katib 使用用户定义的值进行超参数扫描，以找到满足所需指标的最佳参数组合。您可以在 UI 的每个部分中定义这些参数。或者，您可以定义一个具有必要规范的 *YAML* 文件。以下是 Katib 实验的说明 -</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">带有超参数的 Katib 实验仪表板</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">试运行成功</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">使用NetApp快照保存数据以实现可追溯性</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">在模型训练期间，我们可能希望保存训练数据集的快照以便于追溯。为此，我们可以向管道添加快照步骤，如下所示。要创建快照，我们可以使用<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>。</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">在 Kubeflow 中构建快照管道的代码</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">适用于 Kubeflow 的NetApp DataOps Toolkit 示例</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">请参阅<block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block>了解更多信息。</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">NetApp开源 MLOps - MLflow 部署</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">MLflow部署</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">本节介绍在 Kubernetes 集群中部署 MLflow 必须完成的任务。</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">可以在 Kubernetes 以外的平台上部署 MLflow。在 Kubernetes 以外的平台上部署 MLflow 超出了本解决方案的范围。</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow 使用 Helm（Kubernetes 的流行包管理器）进行部署。在部署 MLflow 之前，必须在 Kubernetes 控制节点上安装 Helm。要安装 Helm，请按照<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>在 Helm 官方文档中。</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">在部署 MLflow 之前，您必须在 Kubernetes 集群中指定一个默认 StorageClass。要在集群中指定默认 StorageClass，请按照<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>部分。如果您已经在集群中指定了默认 StorageClass，则可以跳过此步骤。</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">部署 MLflow</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">满足先决条件后，您就可以使用 Helm Chart 开始 MLflow 部署。</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">配置 MLflow Helm Chart 部署。</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">在使用 Helm 图表部署 MLflow 之前，我们可以使用 *config.yaml* 文件将部署配置为使用NetApp Trident存储类并更改其他参数以满足我们的需求。您可以在以下位置找到 *config.yaml* 文件的示例：<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">您可以在 config.yaml 文件中的 *global.defaultStorageClass* 参数下设置Trident storageClass（例如 storageClass：“ontap-flexvol”）。</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">安装 Helm Chart</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">可以使用以下命令将 Helm 图表与 MLflow 的自定义 *config.yaml* 文件一起安装：</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">该命令通过提供的*config.yaml*文件在自定义配置中的 Kubernetes 集群上部署 MLflow。  MLflow 部署在给定的命名空间中，并通过 kubernetes 为该版本提供一个随机发布名称。</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Helm 图表部署完成后，您可以使用以下命令检查服务是否可访问：</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">将 *jupyterhub* 替换为您在部署期间使用的命名空间。</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">您应该会看到以下服务：</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">我们编辑了 config.yaml 文件以使用 NodePort 服务访问端口 30002 上的 MLflow。</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">访问 MLflow</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">一旦与 MLflow 相关的所有服务都启动并运行，您就可以使用给定的 NodePort 或 LoadBalancer IP 地址访问它（例如<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block>)</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">NetApp开源 MLOps - 使用NetApp和 MLflow 实现数据集到模型的可追溯性</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">使用NetApp和 MLflow 实现数据集到模型的可追溯性</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">这<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>可以与 MLflow 的实验跟踪功能结合使用，以实现数据集到模型或工作区到模型的可追溯性。</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">要实现数据集到模型或工作区到模型的可追溯性，只需在训练运行过程中使用 DataOps Toolkit 创建数据集或工作区卷的快照，如以下示例代码片段所示。此代码将数据卷名称和快照名称保存为与您记录到 MLflow 实验跟踪服务器的特定训练运行相关的标签。</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">NetApp开源 MLOps - 执行同步分布式 AI 工作负载</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">执行同步分布式 AI 工作负载</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">要在 Kubernetes 集群中执行同步多节点 AI 和 ML 作业，请在部署跳转主机上执行以下任务。此过程使您能够利用存储在NetApp卷上的数据，并使用比单个工作节点所能提供的更多的 GPU。请参阅下图了解同步分布式 AI 作业的描述。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">与异步分布式作业相比，同步分布式作业可以帮助提高性能和训练准确性。关于同步作业与异步作业的优缺点的讨论超出了本文档的范围。</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">执行单节点 AI 工作负载</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">以下示例命令显示了如何创建一个工作器，该工作器参与本节示例中在单个节点上执行的同一 TensorFlow 基准测试作业的同步分布式执行<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block>。在这个特定的例子中，只部署了一个工作器，因为作业是在两个工作器节点上执行的。</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes 官方文档</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">此示例工作器部署请求八个 GPU，因此可以在具有八个或更多 GPU 的单个 GPU 工作器节点上运行。如果您的 GPU 工作节点具有超过 8 个 GPU，为了最大限度地提高性能，您可能需要将此数字增加到等于您的工作节点所具有的 GPU 数量。有关 Kubernetes 部署的更多信息，请参阅<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>。</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">在此示例中创建了 Kubernetes 部署，因为这个特定的容器化工作程序永远无法自行完成。因此，使用 Kubernetes 作业构造来部署它是没有意义的。如果您的工作者被设计或编写为自行完成，那么使用作业构造来部署您的工作者可能是有意义的。</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">此示例部署规范中指定的 pod 被赋予<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的价值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。此值意味着 pod 使用主机工作节点的网络堆栈，而不是 Kubernetes 通常为每个 pod 创建的虚拟网络堆栈。在这种情况下使用此注释，因为特定的工作负载依赖于 Open MPI、NCCL 和 Horovod 以同步分布式方式执行工作负载。因此，它需要访问主机网络堆栈。有关 Open MPI、NCCL 和 Horovod 的讨论超出了本文档的范围。不管这是否<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block>注释是否必要取决于您正在执行的特定工作负载的要求。有关<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>字段，请参阅<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">确认您在步骤 1 中创建的工作程序部署已成功启动。以下示例命令确认已为部署创建了一个工作程序 pod（如部署定义中所示），并且该 pod 当前正在其中一个 GPU 工作程序节点上运行。</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">为主服务器创建一个 Kubernetes 作业，该主服务器启动、参与并跟踪同步多节点作业的执行。以下示例命令创建一个主服务器，该主服务器启动、参与并跟踪在本节示例中在单个节点上执行的相同 TensorFlow 基准测试作业的同步分布式执行<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block>。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">此示例主作业请求八个 GPU，因此可以在具有八个或更多 GPU 的单个 GPU 工作节点上运行。如果您的 GPU 工作节点具有超过 8 个 GPU，为了最大限度地提高性能，您可能需要将此数字增加到等于您的工作节点所具有的 GPU 数量。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">此示例作业定义中指定的主 Pod 被赋予<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的价值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>就像工作舱被赋予了<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>的价值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>在步骤 1 中。有关为什么需要此值的详细信息，请参阅步骤 1。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">确认您在步骤 3 中创建的主作业正在正确运行。以下示例命令确认已为该作业创建了一个主 pod（如作业定义中所示），并且该 pod 当前正在其中一个 GPU 工作节点上运行。您还应该看到，您在步骤 1 中最初看到的工作 pod 仍在运行，并且主 pod 和工作 pod 在不同的节点上运行。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">确认您在步骤 3 中创建的主作业已成功完成。以下示例命令确认作业已成功完成。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">当您不再需要工作部署时，请删除它。以下示例命令显示删除在步骤 1 中创建的工作程序部署对象。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">当您删除工作部署对象时，Kubernetes 会自动删除任何关联的工作容器。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*可选：*清理主作业工件。以下示例命令显示删除在步骤 3 中创建的主作业对象。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">当您删除主作业对象时，Kubernetes 会自动删除任何关联的主 pod。</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">NetApp开源 MLOps - 执行单节点 AI 工作负载</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">要在 Kubernetes 集群中执行单节点 AI 和 ML 作业，请从部署跳转主机执行以下任务。使用Trident，您可以快速轻松地创建可能包含 PB 级数据的数据卷，以供 Kubernetes 工作负载访问。为了使此类数据卷可从 Kubernetes pod 内部访问，只需在 pod 定义中指定 PVC。</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">本节假设您已经将尝试在 Kubernetes 集群中执行的特定 AI 和 ML 工作负载容器化（以 Docker 容器格式）。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 网站</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">以下示例命令展示了如何为使用 ImageNet 数据集的 TensorFlow 基准工作负载创建 Kubernetes 作业。有关 ImageNet 数据集的更多信息，请参阅<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">此示例作业请求八个 GPU，因此可以在具有八个或更多 GPU 的单个 GPU 工作节点上运行。此示例作业可以在集群中提交，该集群中不存在具有八个或更多 GPU 的工作节点，或者当前正被另一个工作负载占用。如果是，那么该作业将保持待处理状态，直到有这样的工作节点可用。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">此外，为了最大限度地提高存储带宽，包含所需训练数据的卷在该作业创建的 pod 中被安装了两次。另一个卷也安装在 pod 中。第二卷将用于存储结果和指标。这些卷在作业定义中通过使用 PVC 的名称来引用。有关 Kubernetes 作业的更多信息，请参阅<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>。</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">一个<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>音量<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block>的价值<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block>安装到<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>在此示例作业创建的 pod 中。默认大小<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>Docker 容器运行时自动创建的虚拟卷有时无法满足 TensorFlow 的需求。安装<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>如下例所示，音量提供了足够大的<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>虚拟卷。有关更多信息<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>卷，参见<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">此示例作业定义中指定的单个容器被赋予<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block>的价值<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。该值意味着容器实际上在主机上具有 root 访问权限。在这种情况下使用此注释，因为正在执行的特定工作负载需要 root 访问权限。具体来说，工作负载执行的清除缓存操作需要 root 访问权限。不管这是否<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block>注释是否必要取决于您正在执行的特定工作负载的要求。</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">确认您在步骤 1 中创建的作业正在正确运行。以下示例命令确认已为该作业创建了一个 pod（如作业定义中所指定），并且该 pod 当前正在其中一个 GPU 工作节点上运行。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">确认您在步骤 1 中创建的作业已成功完成。以下示例命令确认作业已成功完成。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*可选：*清理工作成果。以下示例命令显示删除在步骤 1 中创建的作业对象。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">当您删除作业对象时，Kubernetes 会自动删除任何关联的 pod。</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">NetApp开源 MLOps - NetApp AIPod部署的Trident后端示例</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">NetApp AIPod部署的Trident后端示例</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">在使用Trident在 Kubernetes 集群中动态配置存储资源之前，您必须创建一个或多个Trident后端。以下示例代表了如果您要在以下位置部署此解决方案的组件，您可能需要创建的不同类型的后端：<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。有关后端的更多信息，以及其他平台/环境的后端示例，请参阅<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp建议为您的AIPod创建支持FlexGroup的Trident Backend。</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">下面的示例命令展示了如何为AIPod存储虚拟机 (SVM) 创建支持FlexGroup的Trident Backend。此后端使用<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>存储驱动程序。  ONTAP支持两种主要数据卷类型： FlexVol和FlexGroup。 FlexVol卷的大小受到限制（截至撰写本文时，最大大小取决于具体的部署）。另一方面， FlexGroup卷可以线性扩展到最多 20PB 和 4000 亿个文件，从而提供单一命名空间，大大简化数据管理。因此， FlexGroup卷最适合依赖大量数据的 AI 和 ML 工作负载。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">如果您处理的数据量较小，并且想要使用FlexVol卷而不是FlexGroup卷，则可以创建使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>存储驱动程序，而不是<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>存储驱动程序。</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp还建议创建支持FlexVol的Trident Backend。您可能希望使用FlexVol卷来托管持久应用程序、存储结果、输出、调试信息等。如果要使用FlexVol卷，则必须创建一个或多个启用FlexVol的Trident后端。下面的示例命令显示如何创建启用单个FlexVol的Trident后端。</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">NetApp的开源 MLOps - Trident操作示例</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident操作示例</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">本节包含您可能想要使用Trident执行的各种操作的示例。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">导入现有卷</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">如果您的NetApp存储系统/平台上存在现有卷，并且您想要将其安装在 Kubernetes 集群内的容器上，但这些卷未与集群中的 PVC 绑定，则必须导入这些卷。您可以使用Trident卷导入功能来导入这些卷。</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">以下示例命令显示导入名为<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block>。有关 PVC 的更多信息，请参阅<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。有关卷导入功能的更多信息，请参阅<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block>。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">一个<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>的价值<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block>在示例 PVC 规范文件中指定。有关<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>字段，请参阅<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">提供新卷</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">您可以使用Trident在NetApp存储系统或平台上配置新卷。</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">使用 kubectl 配置新卷</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">以下示例命令显示使用 kubectl 配置新的FlexVol volume。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">一个<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>的价值<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>在下面的示例 PVC 定义文件中指定。有关<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>字段，请参阅<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>。</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">使用NetApp DataOps 工具包配置新卷</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">文档</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">您还可以使用NetApp DataOps Toolkit for Kubernetes 在NetApp存储系统或平台上配置新卷。 NetApp DataOps Toolkit for Kubernetes 利用Trident来配置卷，但简化了用户的流程。请参阅<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block>了解详情。</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">NetApp开源 MLOps - NetApp AIPod部署的 Kubernetes 存储类示例</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">NetApp AIPod部署的 Kubernetes 存储类示例</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">在使用Trident在 Kubernetes 集群中动态配置存储资源之前，您必须创建一个或多个 Kubernetes StorageClasses。以下示例代表了如果您在以下位置部署此解决方案的组件，则可能需要创建的不同类型的 StorageClasses：<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。有关 StorageClasses 的更多信息，以及其他平台/环境的 StorageClasses 示例，请参阅<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block>。</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">基于 RDMA 的 NFS</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp建议为您在本节中创建的支持FlexGroup的Trident Backend 创建 StorageClass<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block>中，步骤 1。下面的示例命令显示了如何创建多个 StorageClasses，这些 StorageClasses 与本节中创建的示例 Backend 相对应<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block>，步骤 1 - 利用<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block>还有一个则不然。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes 文档</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">为了确保持久卷在删除相应的 PersistentVolumeClaim (PVC) 时不会被删除，以下示例使用<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>的价值<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>。有关<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>字段，请参阅官方<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">注意：以下示例 StorageClasses 使用的最大传输大小为 262144。要使用此最大传输大小，您必须在ONTAP系统上相应地配置最大传输大小。请参阅<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block>了解详情。</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">注：要使用 NFS over RDMA，您必须在ONTAP系统上配置 NFS over RDMA。请参阅<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block>了解详情。</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">注意：以下示例中，StorageClass 定义文件中的 storagePool 字段指定了具体的 Backend。</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">用于AIPod部署的Trident后端示例</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp还建议创建一个与您在本节中创建的支持FlexVol的Trident Backend 相对应的 StorageClass<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block>中，步骤 2。下面的示例命令显示如何为FlexVol卷创建单个 StorageClass。</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">注意：在下面的示例中，StorageClass 定义文件中的 storagePool 字段未指定特定的 Backend。当你使用 Kubernetes 来管理使用此 StorageClass 的卷时， Trident会尝试使用任何可用的后端，该后端使用<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>司机。</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">近乎即时地克隆高容量的 JupyterLab 工作区，以便进行实验或快速迭代。</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">几乎即时保存高容量 JupyterLab 工作区的快照，以用于备份和/或可追溯性/基准测试。</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">近乎即时地提供、克隆和快照大容量、高性能数据卷。</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">结论 - NetApp 的矢量数据库解决方案</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">本节总结了NetApp的矢量数据库解决方案。</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">总而言之，本文档全面概述了在NetApp存储解决方案上部署和管理矢量数据库（例如 Milvus 和 pgvector）。我们讨论了利用NetApp ONTAP和StorageGRID对象存储的基础设施指南，并通过文件和对象存储验证了 AWS FSx ONTAP中的 Milvus 数据库。</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">我们探索了 NetApp 的文件对象二元性，证明了它不仅适用于矢量数据库中的数据，也适用于其他应用程序。我们还重点介绍了 NetApp 的企业管理产品SnapCenter如何为矢量数据库数据提供备份、恢复和克隆功能，确保数据的完整性和可用性。</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">该文档还深入探讨了 NetApp 的混合云解决方案如何在本地和云环境中提供数据复制和保护，从而提供无缝、安全的数据管理体验。我们对NetApp ONTAP上 Milvus 和 pgvecto 等矢量数据库的性能验证提供了见解，并提供了有关其效率和可扩展性的宝贵信息。</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">最后，我们讨论了两个生成式 AI 用例：带有 LLM 的 RAG 和 NetApp 的内部 ChatAI。这些实际示例强调了本文档中概述的概念和实践的实际应用和好处。总的来说，对于任何希望利用 NetApp 强大的存储解决方案来管理矢量数据库的人来说，本文档都是一份全面的指南。</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">作者衷心感谢以下贡献者以及其他提供反馈和评论的人，使本文对NetApp客户和NetApp领域具有价值。</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan， NetApp ONTAP AI 与分析技术营销工程师</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">NetApp技术营销工程师 Mike Oglesby</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">NetApp高级总监 AJ Mahajan</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">NetApp工作负载性能工程经理 Joe Scott</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">NetApp Fsx 产品管理高级总监 Puneet Dhawan</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">NetApp FSx 产品团队高级产品经理 Yuval Kalderon</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Milvus 文档 -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Milvus 独立文档 -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">NetApp产品文档<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">installclustr 文档</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">instaclustr -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">2024年4月</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">为 NetApp 的矢量数据库解决方案准备数据</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">附录 B：prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">本节提供用于准备矢量数据库数据的Python脚本示例。</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">矢量数据库部署程序 - NetApp 矢量数据库解决方案</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">本节讨论NetApp矢量数据库解决方案的部署过程。</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">部署过程</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">在本部署部分中，我们使用 milvus 矢量数据库和 Kubernetes 进行如下实验设置。</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">NetApp 存储为集群提供存储，以保存客户数据和 Milvus 集群数据。</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">NetApp存储设置 – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">对于 NFS（网络文件系统），请按照以下步骤操作：</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">为 NFSv4 创建FlexGroup卷。在我们为此次验证所做的设置中，我们使用了 48 个 SSD，其中 1 个 SSD 专用于控制器的根卷，另外 47 个 SSD 分布用于 NFSv4]].验证FlexGroup卷的 NFS 导出策略是否对 Kubernetes（K8s）节点网络具有读/写权限。如果没有这些权限，请授予 K8s 节点网络的读/写 (rw) 权限。</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">在所有 K8s 节点上，创建一个文件夹，并通过每个 K8s 节点上的逻辑接口 (LIF) 将FlexGroup卷挂载到该文件夹上。</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">对于 NAS S3（网络附加存储简单存储服务），请按照以下步骤操作：</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">为 NFS 创建FlexGroup卷。</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">通过将其类型设置为“nas”并提供 NFSv3 卷的路径来创建 NAS 存储桶。也可以利用 S3 存储桶来实现此目的。</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">NetApp存储设置 – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">安装 storageGRID 软件。</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">创建租户和存储桶。</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">创建具有所需权限的用户。</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">请查看更多详细信息<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - Netapp 的矢量数据库解决方案</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">附录 D：docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">本节包含NetApp矢量数据库解决方案的示例 YAML 代码。</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">使用 Snapcenter 进行矢量数据库保护 - NetApp 的矢量数据库解决方案</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">使用SnapCenter进行矢量数据库保护</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">本节介绍如何使用NetApp SnapCenter为矢量数据库提供数据保护。</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">使用NetApp SnapCenter进行矢量数据库保护。</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">例如，在电影制作行业，客户通常拥有关键的嵌入式数据，如视频和音频文件。由于硬盘故障等问题而导致的数据丢失可能会对其运营产生重大影响，甚至可能危及价值数百万美元的企业。我们曾遇到过宝贵内容丢失的情况，造成严重的混乱和经济损失。因此，确保这些重要数据的安全性和完整性对该行业至关重要。在本节中，我们将深入探讨SnapCenter如何保护驻留在ONTAP中的矢量数据库数据和 Milvus 数据。在此示例中，我们使用了从 NFS ONTAP卷 (vol1) 派生的 NAS 存储桶 (milvusdbvol1) 来存储客户数据，并使用了单独的 NFS 卷 (vectordbpv) 来存储 Milvus 集群配置数据。请查看<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block>Snapcenter 备份工作流程</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">设置将用于执行SnapCenter命令的主机。</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">NetApp自动化商店</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">安装并配置存储插件。从添加的主机中，选择“更多选项”。导航到并选择下载的存储插件<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block>。安装插件并保存配置。</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">设置存储系统和卷：在“存储系统”下添加存储系统，并选择SVM（存储虚拟机）。在这个例子中，我们选择了“vs_nvidia”。</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">为矢量数据库建立资源，包含备份策略和自定义快照名称。</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">使用默认值启用一致性组备份，并启用不具有文件系统一致性的SnapCenter 。</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">在存储占用空间部分，选择与矢量数据库客户数据和 Milvus 集群数据关联的卷。在我们的示例中，这些是“vol1”和“vectordbpv”。</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">创建矢量数据库保护策略，并利用该策略保护矢量数据库资源。</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">使用 Python 脚本将数据插入 S3 NAS 存储桶。在我们的案例中，我们修改了 Milvus 提供的备份脚本，即“prepare_data_netapp.py”，并执行“sync”命令从操作系统中刷新数据。</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">验证 S3 NAS 存储桶中的数据。在我们的示例中，带有时间戳“2024-04-08 21:22”的文件是由“prepare_data_netapp.py”脚本创建的。</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">使用“milvusdb”资源中的一致性组 (CG) 快照启动备份</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">为了测试备份功能，我们在备份过程后添加了一个新表，或者从 NFS（S3 NAS 存储桶）中删除了一些数据。</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">对于此测试，想象一下有人在备份后创建了新的、不必要的或不适当的集合的场景。在这种情况下，我们需要将矢量数据库恢复到添加新集合之前的状态。例如，已插入“hello_milvus_netapp_sc_testnew”和“hello_milvus_netapp_sc_testnew2”等新集合。</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">从上一个快照执行 S3 NAS 存储桶的完整恢复。</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">使用 Python 脚本验证来自“hello_milvus_netapp_sc_test”和“hello_milvus_netapp_sc_test2”集合的数据。</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">验证数据库中不再存在不必要或不适当的集合。</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">总之，使用 NetApp 的SnapCenter来保护驻留在ONTAP中的矢量数据库数据和 Milvus 数据可以为客户带来显著的优势，特别是在数据完整性至关重要的行业，例如电影制作。 SnapCenter 能够创建一致的备份并执行完整的数据恢复，确保关键数据（例如嵌入式视频和音频文件）不会因硬盘故障或其他问题而丢失。这不仅可以防止运营中断，还可以防止重大财务损失。</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">在本节中，我们演示了如何配置SnapCenter来保护驻留在ONTAP中的数据，包括主机的设置、存储插件的安装和配置，以及使用自定义快照名称为矢量数据库创建资源。我们还展示了如何使用一致性组快照执行备份并验证 S3 NAS 存储桶中的数据。</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">此外，我们模拟了备份后创建不必要或不适当的集合的情况。在这种情况下，SnapCenter 从以前的快照执行完整恢复的能力可确保矢量数据库可以恢复到添加新集合之前的状态，从而保持数据库的完整性。这种将数据恢复到特定时间点的功能对于客户来说非常宝贵，它为他们提供了保证，确保他们的数据不仅安全，而且得到正确的维护。因此，NetApp 的SnapCenter产品为客户提供了强大而可靠的数据保护和管理解决方案。</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">使用NetApp SnapMirror进行灾难恢复 - NetApp 的矢量数据库解决方案</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">使用NetApp SnapMirror进行灾难恢复</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">本节讨论使用SnapMirror为NetApp实现矢量数据库解决方案的 DR（灾难恢复）。</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">灾难恢复对于维护矢量数据库的完整性和可用性至关重要，尤其是考虑到其在管理高维数据和执行复杂相似性搜索中的作用。精心规划和实施的灾难恢复策略可确保在发生硬件故障、自然灾害或网络攻击等不可预见的事件时数据不会丢失或受到损害。这对于依赖矢量数据库的应用程序尤其重要，因为数据的丢失或损坏可能导致严重的运营中断和财务损失。此外，强大的灾难恢复计划还可以最大限度地减少停机时间并允许快速恢复服务，从而确保业务连续性。这是通过NetApp数据复制产品 SnapMirror 跨不同地理位置、定期备份和故障转移机制实现的。因此，灾难恢复不仅仅是一种保护措施，而且是负责任、高效的矢量数据库管理的重要组成部分。</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">NetApp 的SnapMirror提供从一个NetApp ONTAP存储控制器到另一个存储控制器的数据复制，主要用于灾难恢复 (DR) 和混合解决方案。在矢量数据库的背景下，该工具有助于实现数据在本地和云环境之间的平稳过渡。这种转变无需任何数据转换或应用程序重构即可实现，从而提高了跨多个平台数据管理的效率和灵活性。</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">NetApp Hybrid解决方案在矢量数据库场景下可以带来更多优势：</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">可扩展性：NetApp 的混合云解决方案能够根据您的需求扩展您的资源。您可以利用本地资源来处理常规、可预测的工作负载，并利用云资源（例如Amazon FSx ONTAP for NetApp ONTAP和 Google Cloud NetApp Volume（NetApp Volumes））来应对高峰时段或意外负载。</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">成本效益：NetApp 的混合云模型允许您通过使用内部资源来处理常规工作负载并仅在需要时支付云资源费用，从而优化成本。这种按需付费模式通过NetApp instaclustr 服务产品可以实现相当高的成本效益。对于本地和主要云服务提供商，instaclustr 提供支持和咨询。</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">灵活性：NetApp 的混合云让您可以灵活地选择在何处处理数据。例如，您可能选择在拥有更强大硬件的本地执行复杂的矢量操作，而在云中执行不太密集的操作。</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">业务连续性：如果发生灾难，将数据保存在NetApp混合云中可以确保业务连续性。如果您的本地资源受到影响，您可以快速切换到云端。我们可以利用NetApp SnapMirror将数据从本地移动到云端，反之亦然。</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">创新：NetApp 的混合云解决方案还可以通过提供对尖端云服务和技术的访问来实现更快的创新。  NetApp在云领域的创新，例如Amazon FSx ONTAP for NetApp ONTAP、 Azure NetApp Files和Google Cloud NetApp Volumes都是云服务提供商的创新产品和首选 NAS。</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr 与 pgvector - Netapp 的矢量数据库解决方案</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">使用 PostgreSQL 的 Instaclustr 矢量数据库：pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">本节讨论 instaclustr 产品如何与NetApp矢量数据库解决方案中的 postgreSQL 的 pgvector 功能集成的具体细节。</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">博客</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">在本节中，我们将深入探讨 instaclustr 产品如何在 pgvector 功能上与 postgreSQL 集成的具体细节。我们有一个例子“如何使用 PGVector 和 PostgreSQL 提高 LLM 准确性和性能：嵌入简介和 PGVector 的作用”。请检查<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block>以获取更多信息。</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">NetApp矢量数据库解决方案介绍</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">本节介绍NetApp的矢量数据库解决方案。</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">向量数据库有效地解决了旨在处理大型语言模型 (LLM) 和生成人工智能 (AI) 中的语义搜索复杂性的挑战。与传统的数据管理系统不同，矢量数据库能够使用数据本身的内容而不是标签或标记来处理和搜索各种类型的数据，包括图像、视频、文本、音频和其他形式的非结构化数据。</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">关系数据库管理系统 (RDBMS) 的局限性是有据可查的，尤其是它们在处理人工智能应用中常见的高维数据表示和非结构化数据时遇到的困难。 RDBMS 通常需要将数据扁平化为更易于管理的结构，这一过程既耗时又容易出错，从而导致搜索延迟和效率低下。矢量数据库的出现解决了这些问题，为复杂高维数据的管理和搜索提供了更高效、更准确的解决方案，从而促进了人工智能应用的发展。</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">本文档为当前正在使用或计划使用向量数据库的客户提供全面的指南，详细介绍了在NetApp ONTAP、 NetApp StorageGRID、 Amazon FSx ONTAP for NetApp ONTAP和SnapCenter等平台上使用向量数据库的最佳实践。本文提供的内容涵盖了一系列主题：</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">NetApp存储通过NetApp ONTAP和StorageGRID对象存储为 Milvus 等矢量数据库提供基础设施指南。</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">通过文件和对象存储验证 AWS FSx ONTAP中的 Milvus 数据库。</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">深入研究 NetApp 的文件对象二元性，展示其对矢量数据库以及其他应用程序中的数据的实用性。</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">NetApp 的数据保护管理产品SnapCenter如何为矢量数据库数据提供备份和恢复功能。</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">NetApp 的混合云如何在本地和云环境中提供数据复制和保护。</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">提供有关NetApp ONTAP上 Milvus 和 pgvector 等矢量数据库的性能验证的见解。</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">两个具体的用例：具有大型语言模型 (LLM) 的检索增强生成 (RAG) 和NetApp IT 团队的 ChatAI，从而提供所概述的概念和实践的实际示例。</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">矢量数据库 - NetApp 的矢量数据库解决方案</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">矢量数据库</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">本节介绍NetApp AI 解决方案中向量数据库的定义和使用。</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">矢量数据库是一种特殊类型的数据库，旨在使用机器学习模型的嵌入来处理、索引和搜索非结构化数据。它不以传统的表格格式组织数据，而是将数据排列为高维向量，也称为向量嵌入。这种独特的结构使得数据库能够更高效、更准确地处理复杂、多维的数据。</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">矢量数据库的关键功能之一是使用生成式人工智能进行分析。这包括相似性搜索，其中数据库识别类似于给定输入的数据点，以及异常检测，其中它可以发现与常态有显著偏差的数据点。</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">此外，矢量数据库非常适合处理时间数据或带时间戳的数据。这种类型的数据提供了有关“发生了什么”以及何时发生的信息，按顺序以及与给定 IT 系统中所有其他事件的关系。这种处理和分析时间数据的能力使得矢量数据库对于需要了解随时间推移的事件的应用程序特别有用。</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">矢量数据库对于ML和AI的优势：</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">高维搜索：向量数据库擅长管理和检索高维数据，这些数据通常在 AI 和 ML 应用程序中生成。</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">可扩展性：它们可以有效扩展以处理大量数据，支持 AI 和 ML 项目的增长和扩展。</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">灵活性：矢量数据库具有高度的灵活性，可以适应多种数据类型和结构。</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">性能：它们提供高性能数据管理和检索，这对于 AI 和 ML 操作的速度和效率至关重要。</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">可定制的索引：矢量数据库提供可定制的索引选项，从而能够根据特定需求优化数据组织和检索。</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">矢量数据库和用例。</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">本节提供各种矢量数据库及其用例详细信息。</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">Faiss和ScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">它们是向量搜索领域中的重要工具库。这些库提供的功能有助于管理和搜索矢量数据，使其成为数据管理这一专业领域的宝贵资源。</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">它是一种广泛使用的搜索和分析引擎，最近加入了矢量搜索功能。此新功能增强了其功能，使其能够更有效地处理和搜索矢量数据。</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">松果</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">它是一个具有一组独特功能的强大矢量数据库。它的索引功能同时支持密集和稀疏向量，从而增强了其灵活性和适应性。它的主要优势之一在于能够将传统搜索方法与基于人工智能的密集矢量搜索相结合，从而创造出一种兼具两全其美的混合搜索方法。</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone 主要基于云，专为机器学习应用而设计，可与各种平台良好集成，包括 GCP、AWS、Open AI、GPT-3、GPT-3.5、GPT-4、Catgut Plus、Elasticsearch、Haystack 等。值得注意的是，Pinecone 是一个闭源平台，可作为软件即服务 (SaaS) 产品使用。</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">鉴于其先进的功能，Pinecone 特别适合网络安全行业，其高维搜索和混合搜索功能可以有效地利用来检测和应对威胁。</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">色度</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">它是一个矢量数据库，具有包含四个主要功能的核心 API，其中一个功能包括内存文档矢量存储。它还利用 Face Transformers 库来矢量化文档，增强其功能和多功能性。 Chroma 的设计可在云端和本地运行，可根据用户需求提供灵活性。特别是在音频相关应用方面表现出色，使其成为基于音频的搜索引擎、音乐推荐系统和其他音频相关用例的绝佳选择。</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">威维特</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">它是一个多功能矢量数据库，允许用户使用其内置模块或自定义模块矢量化其内容，根据特定需求提供灵活性。它提供完全托管和自托管解决方案，满足各种部署偏好。</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Weaviate 的主要功能之一是它能够同时存储矢量和对象，从而增强其数据处理能力。它广泛应用于一系列应用，包括 ERP 系统中的语义搜索和数据分类。在电子商务领域，它为搜索和推荐引擎提供支持。  Weaviate 还用于图像搜索、异常检测、自动数据协调和网络安全威胁分析，展示了其在多个领域的多功能性。</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">Redis</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis 是一种高性能矢量数据库，以其快速的内存存储而闻名，可为读写操作提供低延迟。这使其成为需要快速数据访问的推荐系统、搜索引擎和数据分析应用程序的绝佳选择。</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis 支持向量的各种数据结构，包括列表、集合和有序集。它还提供矢量运算，例如计算矢量之间的距离或查找交集和并集。这些功能对于相似性搜索、聚类和基于内容的推荐系统特别有用。</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">在可扩展性和可用性方面，Redis 擅长处理高吞吐量工作负载并提供数据复制。它还可以与其他数据类型很好地集成，包括传统的关系数据库（RDBMS）。 Redis 包含一个用于实时更新的发布/订阅（Pub/Sub）功能，这有利于管理实时向量。此外，Redis 轻量级且易于使用，使其成为管理矢量数据的用户友好型解决方案。</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">Milvus</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">它是一个多功能的矢量数据库，提供类似文档存储的 API，非常类似于 MongoDB。它因支持多种数据类型而脱颖而出，成为数据科学和机器学习领域的热门选择。</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Milvus 的独特功能之一是其多矢量化功能，它允许用户在运行时指定用于搜索的矢量类型。此外，它利用 Knowwhere（一个位于 Faiss 等其他库之上的库）来管理查询和向量搜索算法之间的通信。</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">由于与 PyTorch 和 TensorFlow 兼容，Milvus 还提供与机器学习工作流程的无缝集成。这使其成为一系列应用的绝佳工具，包括电子商务、图像和视频分析、对象识别、图像相似性搜索和基于内容的图像检索。在自然语言处理领域，Milvus 用于文档聚类、语义搜索和问答系统。</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">对于这个解决方案，我们选择了 milvus 进行解决方案验证。为了提高性能，我们同时使用了 milvus 和 postgres（pgvecto.rs）。</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">为什么我们选择 milvus 作为这个解决方案？</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">开源：Milvus 是一个开源矢量数据库，鼓励社区驱动的开发和改进。</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">AI 集成：它利用嵌入相似性搜索和 AI 应用程序来增强矢量数据库功能。</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">大容量处理：Milvus 有能力存储、索引和管理由深度神经网络 (DNN) 和机器学习 (ML) 模型生成的超过十亿个嵌入向量。</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">用户友好：易于使用，设置只需不到一分钟。  Milvus 还为不同的编程语言提供 SDK。</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">速度：它提供极快的检索速度，比一些替代方案快 10 倍。</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">可扩展性和可用性：Milvus 具有高度可扩展性，可以根据需要进行扩展和缩小。</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">功能丰富：它支持不同的数据类型、属性过滤、用户定义函数 (UDF) 支持、可配置的一致性级别和旅行时间，使其成为各种应用的多功能工具。</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Milvus 架构概述</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">本节提供 Milvus 架构中使用的更高级别的组件和服务。  * 访问层——由一组无状态代理组成，作为系统的前端层和用户的端点。 * 协调器服务——它将任务分配给工作节点并充当系统的大脑。它有三种协调器类型：根协调器、数据协调器和查询协调器。  * 工作节点：它遵循协调服务的指令并执行用户触发的DML / DDL命令。它有三种类型的工作节点，例如查询节点，数据节点和索引节点。 * 存储：负责数据持久化。它包括元存储、日志代理和对象存储。  NetApp存储（例如ONTAP和StorageGRID）为 Milvus 提供对象存储和基于文件的存储，用于客户数据和矢量数据库数据。</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvus 与Amazon FSx ONTAP for NetApp ONTAP - NetApp 的矢量数据库解决方案</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus 与Amazon FSx ONTAP for NetApp ONTAP - 文件和对象二元性</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">本节讨论使用Amazon FSx ONTAP为NetApp提供矢量数据库解决方案的 milvus 集群设置。</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus 与Amazon FSx ONTAP for NetApp ONTAP – 文件和对象二元性</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">在本节中，我们将介绍为什么需要在云中部署矢量数据库，以及在 Docker 容器中的Amazon FSx ONTAP for NetApp ONTAP中部署矢量数据库（milvus 独立版）的步骤。</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">在云中部署矢量数据库有几个显著的好处，特别是对于需要处理高维数据和执行相似性搜索的应用程序。首先，基于云的部署提供了可扩展性，允许轻松调整资源以适应不断增长的数据量和查询负载。这确保数据库能够有效地处理增加的需求，同时保持高性能。其次，云部署提供了高可用性和灾难恢复，因为数据可以在不同的地理位置复制，最大限度地降低数据丢失的风险，并确保即使在意外事件期间也能持续提供服务。第三，它具有成本效益，因为您只需为您使用的资源付费，并且可以根据需求扩大或缩小规模，从而无需在硬件上进行大量的前期投资。最后，在云中部署矢量数据库可以增强协作，因为可以从任何地方访问和共享数据，从而促进基于团队的工作和数据驱动的决策。请使用Amazon FSx ONTAP for NetApp ONTAP检查此验证中使用的 milvus 独立架构。</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">为NetApp ONTAP实例创建Amazon FSx ONTAP ，并记下 VPC、VPC 安全组和子网的详细信息。创建 EC2 实例时需要此信息。您可以在此处找到更多详细信息 -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">创建一个 EC2 实例，确保 VPC、安全组和子网与Amazon FSx ONTAP for NetApp ONTAP实例的 VPC、安全组和子网匹配。</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">使用命令“apt-get install nfs-common”安装 nfs-common，并使用“sudo apt-get update”更新包信息。</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">创建一个挂载文件夹并在其上挂载适用于NetApp ONTAP 的Amazon FSx ONTAP 。</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">使用“apt-get install”安装 Docker 和 Docker Compose。</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">根据 docker-compose.yaml 文件搭建 Milvus 集群，该文件可以从 Milvus 网站下载。</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">在 docker-compose.yml 文件的“volumes”部分中，将NetApp NFS 挂载点映射到相应的 Milvus 容器路径，具体在 etcd、minio 和 standalone 中。检查<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block>有关 yml 更改的详细信息</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">验证已安装的文件夹和文件。</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">从包含 docker-compose.yml 文件的目录运行“docker-compose up -d”。</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">检查 Milvus 容器的状态。</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">为了验证Amazon FSx ONTAP for NetApp ONTAP中矢量数据库及其数据的读写功能，我们使用了 Python Milvus SDK 和来自 PyMilvus 的示例程序。使用“apt-get install python3-numpy python3-pip”安装必要的软件包，并使用“pip3 install pymilvus”安装 PyMilvus。</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">验证向量数据库中Amazon FSx ONTAP for NetApp ONTAP的数据写入和读取操作。</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">使用verify_data_netapp.py脚本检查读取操作。</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">如果客户想要通过 S3 协议访问（读取）矢量数据库中测试的 NFS 数据以用于 AI 工作负载，则可以使用简单的 Python 程序进行验证。一个例子可以是来自另一个应用程序的图像的相似性搜索，如本节开头的图片中提到的那样。</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">本节有效地演示了客户如何在 Docker 容器中部署和操作独立的 Milvus 设置，并利用 Amazon 的NetApp FSx ONTAP进行NetApp ONTAP数据存储。此设置允许客户利用矢量数据库的强大功能来处理高维数据和执行复杂查询，所有这些都可以在可扩展且高效的 Docker 容器环境中完成。通过创建适用于NetApp ONTAP实例和匹配的 EC2 实例的Amazon FSx ONTAP ，客户可以确保最佳的资源利用率和数据管理。 FSx ONTAP在矢量数据库中数据写入和读取操作的成功验证为客户提供了可靠、一致的数据操作的保证。此外，通过 S3 协议列出（读取）来自 AI 工作负载的数据的能力增强了数据可访问性。因此，这一全面的流程为客户提供了一个强大而高效的解决方案，用于管理他们的大规模数据操作，并利用了 Amazon FSx ONTAP for NetApp ONTAP的功能。</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">milvus 集群设置 - NetApp 的矢量数据库解决方案</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">在本地使用 Kubernetes 设置 Milvus 集群</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">本节讨论针对NetApp矢量数据库解决方案的 milvus 集群设置。</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">在本地使用 Kubernetes 设置 Milvus 集群</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">客户面临的挑战是在存储和计算上独立扩展、有效的基础设施管理和数据管理，Kubernetes 和矢量数据库共同构成了管理大数据操作的强大、可扩展的解决方案。 Kubernetes 优化资源并管理容器，而矢量数据库则高效处理高维数据和相似性搜索。这种组合能够快速处理大型数据集上的复杂查询，并随着数据量的增加而无缝扩展，使其成为大数据应用程序和人工智能工作负载的理想选择。</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">在本节中，我们详细介绍了在 Kubernetes 上安装 Milvus 集群的过程，并利用NetApp存储控制器存储集群数据和客户数据。</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">要安装 Milvus 集群，需要持久卷 (PV) 来存储来自各个 Milvus 集群组件的数据。这些组件包括 etcd（三个实例）、pulsar-bookie-journal（三个实例）、pulsar-bookie-ledgers（三个实例）和 pulsar-zookeeper-data（三个实例）。</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">此链接</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">在 milvus 集群中，我们可以使用 pulsar 或者 kafka 作为支撑 Milvus 集群可靠存储以及消息流发布/订阅的底层引擎。对于使用 NFS 的 Kafka， NetApp在ONTAP 9.12.1 及更高版本中做出了改进，这些增强功能以及 RHEL 8.7 或 9.1 及更高版本中包含的 NFSv4.1 和 Linux 更改解决了在 NFS 上运行 Kafka 时可能出现的“愚蠢重命名”问题。如果您对使用 NetApp NFS 解决方案运行 Kafka 主题的更多深入信息感兴趣，请查看 -<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> 。</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">我们从NetApp ONTAP创建了一个 NFS 卷，并建立了 12 个持久卷，每个卷具有 250GB 的存储空间。存储大小可能因集群大小而异；例如，我们有另一个集群，其中每个 PV 有 50GB。请参阅下面的 PV YAML 文件之一以了解更多详细信息；我们总共有 12 个这样的文件。在每个文件中，storageClassName 设置为“default”，并且存储和路径对于每个 PV 都是唯一的。</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">对每个 PV YAML 文件执行“kubectl apply”命令来创建持久卷，然后使用“kubectl get pv”验证其创建</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">为了存储客户数据，Milvus 支持对象存储解决方案，例如 MinIO、Azure Blob 和 S3。在本指南中，我们使用 S3。以下步骤适用于ONTAP S3 和StorageGRID对象存储。我们使用 Helm 来部署 Milvus 集群。从 Milvus 下载位置下载配置文件 values.yaml。有关我们在本文档中使用的 values.yaml 文件，请参阅附录。</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">确保每个部分中的“storageClass”设置为“default”，包括日志、etcd、zookeeper 和 bookkeeper。</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">在 MinIO 部分，禁用 MinIO。</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">从ONTAP或StorageGRID对象存储创建 NAS 存储桶，并使用对象存储凭据将其包含在外部 S3 中。</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">在创建 Milvus 集群之前，请确保 PersistentVolumeClaim（PVC）没有任何预先存在的资源。</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">利用 Helm 和 values.yaml 配置文件安装并启动 Milvus 集群。</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">验证 PersistentVolumeClaims (PVC) 的状态。</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">检查 pod 的状态。</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">请确保 Pod 状态为“正在运行”且按预期工作</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">测试在 Milvus 和NetApp对象存储中写入和读取数据。</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">使用“prepare_data_netapp_new.py”Python 程序写入数据。</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">使用“verify_data_netapp.py”Python 文件读取数据。</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">基于以上验证，Kubernetes 与矢量数据库的集成，通过使用NetApp存储控制器在 Kubernetes 上部署 Milvus 集群，为客户提供了强大、可扩展且高效的大规模数据操作管理解决方案。此设置为客户提供了处理高维数据和快速高效地执行复杂查询的能力，使其成为大数据应用和人工智能工作负载的理想解决方案。对各种集群组件使用持久卷 (PV)，以及从NetApp ONTAP创建单个 NFS 卷，可确保最佳资源利用率和数据管理。验证 PersistentVolumeClaims (PVC) 和 pod 的状态以及测试数据写入和读取的过程为客户提供了可靠且一致的数据操作的保证。使用ONTAP或StorageGRID对象存储客户数据进一步增强了数据的可访问性和安全性。总体而言，这种设置为客户提供了一种有弹性且高性能的数据管理解决方案，可以随着客户不断增长的数据需求而无缝扩展。</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">NetApp 矢量数据库解决方案概述</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">本节概述了NetApp矢量数据库解决方案。</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">该解决方案展示了NetApp为应对矢量数据库客户面临的挑战所提供的独特优势和功能。通过利用NetApp ONTAP、 StorageGRID、NetApp 的云解决方案和SnapCenter，客户可以为其业务运营增加显著的价值。这些工具不仅解决了现有的问题，还提高了效率和生产力，从而促进了整体业务增长。</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">为什么选择NetApp？</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">NetApp 的产品（例如ONTAP和StorageGRID）允许分离存储和计算，从而能够根据特定需求实现最佳资源利用率。这种灵活性使客户能够使用NetApp存储解决方案独立扩展其存储。</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP为 AWS、Azure 和 Google Cloud 等领先的云服务提供商提供对 NAS 和对象存储的原生支持。这种广泛的兼容性确保了无缝集成，实现了客户数据移动性、全球可访问性、灾难恢复、动态可扩展性和高性能。</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">借助 NetApp 强大的数据管理功能，客户可以放心，因为他们的数据受到良好的保护，不会受到潜在风险和威胁。  NetApp优先考虑数据安全，让客户对其宝贵信息的安全性和完整性感到放心。</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">矢量数据库性能验证 - NetApp 矢量数据库解决方案</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">矢量数据库性能验证</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">本节重点介绍在矢量数据库上执行的性能验证。</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">性能验证</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">性能验证在矢量数据库和存储系统中都起着至关重要的作用，是确保最佳运行和高效资源利用的关键因素。矢量数据库以处理高维数据和执行相似性搜索而闻名，需要保持高性能水平才能快速准确地处理复杂查询。性能验证有助于识别瓶颈、微调配置并确保系统能够处理预期负载而不会降低服务质量。同样，在存储系统中，性能验证对于确保数据高效存储和检索至关重要，不会出现可能影响整体系统性能的延迟问题或瓶颈。它还有助于对存储基础设施的必要升级或变更做出明智的决策。因此，性能验证是系统管理的一个重要方面，对维持高服务质量、运行效率和整体系统可靠性有重要贡献。</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">在本节中，我们旨在深入研究矢量数据库（例如 Milvus 和 pgvecto.rs）的性能验证，重点关注它们的存储性能特征，例如 I/O 配置文件和 NetApp 存储控制器在 LLM 生命周期内支持 RAG 和推理工作负载的行为。当这些数据库与ONTAP存储解决方案结合时，我们将评估并识别任何性能差异因素。我们的分析将基于关键性能指标，例如每秒处理的查询数（QPS）。</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">请检查下面用于 milvus 和进度的方法。</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus（单机和集群）</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres（pgvecto.rs）#</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">version</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Filesystem</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">iSCSI LUN 上的 XFS</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">工作负载生成器</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-Bench</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">数据集</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">LAION 数据集 * 1000 万个嵌入 * 768 个维度 * 数据集大小约为 300GB</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * 版本 — 9.14.1 * 4 x 100GbE — 用于 milvus，2x 100GbE 用于 postgres * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">带有 Milvus 独立集群的 VectorDB-Bench</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">我们使用vectorDB-Bench在milvus独立集群上进行了以下性能验证。  milvus 独立集群的网络和服务器连接如下。</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">在本节中，我们分享测试 Milvus 独立数据库的观察和结果。。我们选择 DiskANN 作为这些测试的索引类型。。提取、优化和创建大约 100GB 数据集的索引大约需要 5 个小时。在此持续时间的大部分时间里，配备 20 个内核（启用超线程时相当于 40 个 vCPU）的 Milvus 服务器都以其最大 CPU 容量 100% 运行。我们发现 DiskANN 对于超过系统内存大小的大型数据集尤为重要。。在查询阶段，我们观察到每秒查询次数 (QPS) 为 10.93，召回率为 0.9987。查询的第 99 个百分位延迟测量为 708.2 毫秒。</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">从存储角度来看，数据库在摄取、插入后优化和索引创建阶段发出大约 1,000 个操作/秒。在查询阶段，它要求每秒 32,000 次操作。</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">以下部分介绍存储性能指标。</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">工作负载阶段</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">指标</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">数据提取和插入后优化</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1,000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">延迟</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400 微秒</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">工作量</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">读/写混合，主要是写入</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">IO 大小</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">查询</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">峰值为32,000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100% 缓存读取</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">主要为8KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">VectorDB-bench 结果如下。</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">从独立 Milvus 实例的性能验证来看，当前的设置不足以支持 500 万个向量、维度为 1536 的数据集。我们已确定存储拥有足够的资源，不会构成系统的瓶颈。</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">带有 milvus 集群的 VectorDB-Bench</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">在本节中，我们讨论在 Kubernetes 环境中部署 Milvus 集群。此 Kubernetes 设置构建于 VMware vSphere 部署之上，该部署托管 Kubernetes 主节点和工作节点。</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">以下部分介绍 VMware vSphere 和 Kubernetes 部署的详细信息。</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">在本节中，我们介绍了测试 Milvus 数据库的观察结果和结果。  * 使用的索引类型是 DiskANN。 * 下表比较了在处理 500 万个向量（维度为 1536）时独立部署和集群部署的差异。我们观察到，在集群部署中，数据提取和插入后优化所需的时间较短。与独立设置相比，集群部署中查询的第 99 个百分位延迟减少了六倍。  * 尽管集群部署中的每秒查询数 (QPS) 率较高，但并未达到预期水平。</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">下图提供了各种存储指标的视图，包括存储集群延迟和总 IOPS（每秒输入/输出操作）。</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">以下部分介绍关键的存储性能指标。</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">峰值为147,000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">基于独立 Milvus 和 Milvus 集群的性能验证，我们展示了存储 I/O 配置文件的详细信息。  * 我们观察到 I/O 配置文件在独立部署和集群部署中保持一致。  * 峰值 IOPS 的观察到的差异可以归因于集群部署中的客户端数量较多。</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">带有 Postgres 的vectorDB-Bench（pgvecto.rs）</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">我们使用 VectorDB-Bench 对 PostgreSQL（pgvecto.rs）进行了如下操作：PostgreSQL（具体来说，pgvecto.rs）的网络和服务器连接详情如下：</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">在本节中，我们分享测试 PostgreSQL 数据库（特别是使用 pgvecto.rs）的观察和结果。  * 我们选择 HNSW 作为这些测试的索引类型，因为在测试时，DiskANN 不适用于 pgvecto.rs。 * 在数据提取阶段，我们加载了 Cohere 数据集，该数据集包含 1000 万个向量，维度为 768。该过程大约耗时 4.5 小时。 * 在查询阶段，我们观察到每秒查询次数 (QPS) 为 1,068，召回率为 0.6344。查询的第 99 个百分位延迟测量为 20 毫秒。在大部分运行时间内，客户端 CPU 都以 100% 的容量运行。</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">下图提供了各种存储指标的视图，包括存储集群延迟总 IOPS（每秒输入/输出操作）。</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">milvus 与 postgres 在 Vector DB Bench 上的性能对比</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">根据我们使用 VectorDBBench 对 Milvus 和 PostgreSQL 进行的性能验证，我们观察到以下情况：</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">索引类型：HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">数据集：包含 768 个维度的 1000 万个向量</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">我们发现 pgvecto.rs 的每秒查询数 (QPS) 达到 1,068，召回率为 0.6344，而 Milvus 的每秒查询数 (QPS) 达到 106，召回率为 0.9842。</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">如果您优先考虑查询的高精度，那么 Milvus 的性能优于 pgvecto.rs，因为它在每个查询中检索到更高比例的相关项目。但是，如果每秒查询次数是一个更关键的因素，那么 pgvecto.rs 就超过了 Milvus。但值得注意的是，通过 pgvecto.rs 检索的数据质量较低，大约 37% 的搜索结果是不相关的项目。</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">根据我们的性能验证得出的观察结果：</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">根据我们的性能验证，我们做出了以下观察：</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">在 Milvus 中，I/O 配置文件与 OLTP 工作负载非常相似，例如 Oracle SLOB 中的工作负载。基准测试包括三个阶段：数据提取、后优化和查询。初始阶段主要以 64KB 写入操作为特征，而查询阶段主要涉及 8KB 读取。我们希望ONTAP能够熟练地处理 Milvus I/O 负载。</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">PostgreSQL I/O 配置文件不会带来具有挑战性的存储工作负载。鉴于目前正在进行的内存实现，我们在查询阶段没有观察到任何磁盘 I/O。</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN 成为存储区分的关键技术。它使得向量数据库搜索能够超越系统内存边界进行有效扩展。然而，不太可能通过内存中的向量数据库索引（例如 HNSW）建立存储性能差异。</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">还值得注意的是，当索引类型为 HSNW 时，存储在查询阶段并不起关键作用，而查询阶段是支持 RAG 应用的矢量数据库最重要的操作阶段。这里的含义是存储性能不会显著影响这些应用程序的整体性能。</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">这是 Netapp 矢量数据库解决方案的摘要页面。</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">NetApp的矢量数据库解决方案</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam 和 Rodrigo Nascimento， NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">本文档深入探讨了使用 NetApp 存储解决方案部署和管理矢量数据库（例如 Milvus 和开源 PostgreSQL 扩展 pgvecto）的方法。它详细介绍了使用NetApp ONTAP和StorageGRID对象存储的基础设施指南，并验证了 Milvus 数据库在 AWS FSx ONTAP中的应用。该文档阐明了 NetApp 的文件对象二元性及其对支持矢量嵌入的矢量数据库和应用程序的实用性。它强调了 NetApp 企业管理产品SnapCenter的功能，为矢量数据库提供备份和恢复功能，确保数据的完整性和可用性。该文档进一步深入探讨了 NetApp 的混合云解决方案，讨论了其在本地和云环境中的数据复制和保护中的作用。它包括对NetApp ONTAP上矢量数据库性能验证的见解，并总结了生成 AI 的两个实际用例：带有 LLM 的 RAG 和 NetApp 的内部 ChatAI。本文档是利用 NetApp 存储解决方案管理矢量数据库的综合指南。</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">参考架构重点关注以下内容：</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">技术要求</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">解决方案验证概述</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">Milvus 与Amazon FSx FSx ONTAP for NetApp ONTAP –ONTAP和对象二元NetApp</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">矢量数据库用例</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">附录 A：values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">附录C：verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">技术要求-NetApp 的矢量数据库解决方案</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">本节概述了NetApp矢量数据库解决方案的要求。</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">除性能外，下面概述的硬件和软件配置用于本文档中执行的大部分验证。这些配置可作为帮助您设置环境的指南。但请注意，具体组件可能会因个别客户的要求而有所不同。</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3.49TB SSD-NVM * 两个灵活组卷：元数据和数据。  * 元数据 NFS 卷有 12 个持久卷，每个卷为 250GB。  * 数据是ONTAP NAS S3 卷</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">6台富士通PRIMERGY RX2540 M4</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64 个 CPU * Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz * 256 GM 物理内存 * 1 x 100GbE 网络端口</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100，3xSGF6024 * 3 x 24 x 7.68TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">Milvus 集群</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* 图表 - milvus-4.1.11。  * APP 版本 – 2.3.4 * 依赖的 bundles，例如 bookkeeper、zookeeper、pulsar、etcd、proxy、querynode、worker</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* 5 节点 K8s 集群 * 1 个主节点和 4 个工作节点 * 版本 – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">用例 - NetApp 的矢量数据库解决方案</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">本节概述了NetApp矢量数据库解决方案的用例。</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">在本节中，我们讨论两个用例，例如使用大型语言模型的检索增强生成和NetApp IT 聊天机器人。</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">使用大型语言模型 (LLM) 进行检索增强生成 (RAG)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">NVIDIA Enterprise RAG LLM Operator 是在企业中实施 RAG 的有用工具。该操作员可用于部署完整的 RAG 管道。 RAG 管道可以定制为使用 Milvus 或 pgvecto 作为存储知识库嵌入的向量数据库。有关详细信息，请参阅文档。</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">图 1) 由NVIDIA NeMo 微服务和NetApp提供支持的企业 RAG</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">NetApp IT 聊天机器人用例</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">NetApp 的聊天机器人是矢量数据库的另一个实时用例。在这种情况下， NetApp Private OpenAI Sandbox 为管理来自 NetApp 内部用户的查询提供了一个有效、安全且高效的平台。通过结合严格的安全协议、高效的数据管理系统和复杂的人工智能处理能力，它保证通过 SSO 身份验证根据组织中用户的角色和职责为他们提供高质量、精确的响应。这种架构凸显了融合先进技术以创建以用户为中心的智能系统的潜力。</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">用例可以分为四个主要部分。</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">用户身份验证和验证：</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">用户查询首先经过NetApp单点登录 (SSO) 流程来确认用户的身份。</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">身份验证成功后，系统会检查VPN连接以确保数据传输的安全。</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">数据传输和处理：</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">一旦 VPN 验证通过，数据就会通过 NetAIChat 或 NetAICreate Web 应用程序发送到 MariaDB。  MariaDB 是一个快速高效的数据库系统，用于管理和存储用户数据。</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">然后，MariaDB 将信息发送到NetApp Azure 实例，该实例将用户数据连接到 AI 处理单元。</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">与 OpenAI 和内容过滤的交互：</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">Azure 实例将用户的问题发送到内容过滤系统。该系统清理查询并准备进行处理。</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">清理后的输入随后被发送到 Azure OpenAI 基础模型，该模型根据输入生成响应。</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">响应生成和审核：</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">首先检查基础模型的响应，以确保其准确性并符合内容标准。</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">检查通过后，将响应发送回用户。此过程可确保用户收到对其查询的清晰、准确和适当的答案。</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - Netapp 的矢量数据库解决方案</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">附录 A：Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">本节提供NetApp矢量数据库解决方案中使用的值的示例 YAML 代码。</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">解决方案验证概述 - NetApp 的矢量数据库解决方案</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">我们针对五个关键领域进行了全面的解决方案验证，具体细节概述如下。每个部分都深入探讨了客户面临的挑战、 NetApp提供的解决方案以及随后给客户带来的好处。</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>客户面临的挑战是独立扩展存储和计算、有效的基础设施管理和数据管理。在本节中，我们详细介绍了在 Kubernetes 上安装 Milvus 集群的过程，并利用NetApp存储控制器存储集群数据和客户数据。</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">milvus 与 Amazon FSx ONTAP for NetApp ONTAP – 文件和对象二元性 在本节中，我们将介绍为什么ONTAP在云中部署矢量数据库，以及在NetApp Amazon FSxAmazon FSxONTAPNetAppONTAP（milvus 独立版）的步骤。</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>在本节中，我们将深入探讨SnapCenter如何保护驻留在ONTAP中的矢量数据库数据和 Milvus 数据。在此示例中，我们利用源自 NFS ONTAP卷（vol1）的 NAS 存储桶（milvusdbvol1）来存储客户数据，并使用单独的 NFS 卷（vectordbpv）来存储 Milvus 集群配置数据。</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>在本节中，我们讨论灾难恢复（DR）对于矢量数据库的重要性以及NetApp灾难恢复产品SnapMirror如何为矢量数据库提供DR解决方案。</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>在本节中，我们旨在深入研究矢量数据库（例如 Milvus 和 pgvecto.rs）的性能验证，重点关注它们的存储性能特征，例如 I/O 配置文件和 NetApp 存储控制器在 LLM 生命周期内支持 RAG 和推理工作负载的行为。当这些数据库与ONTAP存储解决方案结合时，我们将评估并识别任何性能差异因素。我们的分析将基于关键性能指标，例如每秒处理的查询数（QPS）。</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - netapp 的矢量数据库解决方案</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">本节包含一个示例 Python 脚本，可用于验证NetApp矢量数据库解决方案中的矢量数据库。</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">观看有关NetApp的 AI 解决方案的视频</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">了解NetApp如何支持 AI 和机器学习计划。这些精选的视频播放列表展示了NetApp AI 解决方案和 MLOps 工作流程，重点介绍了高级分析的部署策略、自动化和数据管理。</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">NetApp AI 解决方案</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">观看NetApp AI 解决方案播放列表</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">全面的视频播放列表，涵盖 AI 基础设施、融合系统和企业 AI 部署。<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">机器学习操作 (MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">观看 MLOps 播放列表</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">有关 MLOps 工作流、数据管道和最佳操作实践的视频系列。<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">一系列视频和演示讨论了 NetApp 众多解决方案的功能</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp解决方案：视频和演示</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">概述视频和演示，重点介绍 NetApp 的许多解决方案的具体功能。</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">NetApp人工智能解决方案附件的最新变更日志。</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">NetApp人工智能解决方案的新功能</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">了解人工智能解决方案的最新动态。</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">2025年8月18日</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">NetApp解决方案系列</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">NetApp解决方案网站现在是<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block>，其中包括以下网站：</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">NetApp人工智能解决方案</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">NetApp容器解决方案</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">NetApp数据管理解决方案</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">NetApp数据库解决方案</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">NetApp公共云和混合云解决方案</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">适用于 SAP 的NetApp解决方案</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">NetApp虚拟化解决方案</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp提供全面的 AI 解决方案，结合企业级数据管理、经过验证的参考架构和战略合作伙伴关系，以加速您的 AI 计划并支持关键业务成果。从基础设施部署到 MLOps 自动化，我们的解决方案可在边缘、数据中心和混合云环境之间无缝扩展。</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">开始使用</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">什么是新的</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">博客</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">视频和演示</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">人工智能基础设施和融合系统</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">搭载NVIDIA DGX 系统的NetApp AIPod</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">搭载 EF 系列的NVIDIA DGX SuperPOD</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NetApp AIPod与联想携手为NVIDIA OVX 提供支持</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">E系列的BeeGFS并行文件系统</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">人工智能用例和应用</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">用于 RAG 推理的AIPod Mini</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">边缘人工智能推理</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">矢量数据库解决方案</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">自动驾驶工作负载</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">昆腾 StorNext E 系列</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps 和数据管理</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">NetApp的开源 MLOps</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">Domino Data Lab 的混合多云 MLOps</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">适用于 MLOps 的 FSx ONTAP</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">大数据和混合云AI解决方案</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">混合云数据解决方案</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Apache Spark 解决方案</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">Confluent Kafka 与NetApp ONTAP存储</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">NetApp StorageGRID与 Splunk SmartStore</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">配备NetApp存储的 Dremio Lakehouse</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">解决方案请求和反馈</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">请求自动化</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">提出新的解决方案</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">提供解决方案反馈</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">利用 NetApp 全面的 MLOps 和数据管理解决方案简化您的 AI/ML 工作流程。从开源平台到企业级工具，我们的解决方案能够在混合云环境中实现高效的模型开发、部署和扩展，同时确保数据一致性和性能。</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">NetApp MLOps 和数据管理解决方案</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">开源 MLOps 平台</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">针对AIPod 的NetApp Trident配置</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Apache Airflow 部署和集成</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">JupyterHub部署和数据操作</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">MLflow 部署和可追溯性</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">高级 MLOps 工作流程</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Kubeflow 部署和笔记本</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">使用 Kubeflow 训练图像识别模型</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">单节点 AI 工作负载执行</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">分布式 AI 工作负载执行</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">使用SnapMirror进行数据提取</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">企业 MLOps 解决方案</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">Domino Data Lab 的混合 MLOps</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">使用 Domino 进行跨环境数据访问</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">NVIDIA NGC 软件集成</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">Cloud MLOps 和 AWS 集成</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">适用于ONTAP MLOps 的Amazon FSx</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">将 FSx ONTAP作为私有 S3 集成到 SageMaker 中</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">用于 SageMaker 模型训练的 FSx ONTAP</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">使用 FSx 构建简化的 MLOps 管道</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">矢量数据库和人工智能应用</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">NetApp的矢量数据库解决方案</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">使用 Kubernetes 设置 Milvus 集群</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">使用SnapCenter进行矢量数据库保护</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">矢量数据库性能验证</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">矢量数据库用例</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">数据管理工具和存储</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">用于自动驾驶的StorageGRID数据湖</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">使用SnapMirror进行灾难恢复</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">利用 NetApp 经过验证的参考架构和融合系统部署企业级 AI 基础架构。从NetApp AIPod解决方案到高性能存储平台，我们的设计可提供要求苛刻的 AI/ML 工作负载所需的性能、可扩展性和可靠性。</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">NetApp AI 基础架构和融合系统</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">NetApp AIPod参考架构</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">AIPod架构</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">AIPod部署细节</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">AIPod验证和尺寸指南</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">适用于 AI 工作负载的高性能存储</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">搭载 EF 系列存储的NVIDIA DGX SuperPOD</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">配备 E 系列存储的 IBM Spectrum Scale</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAP与联想 ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">使用NetApp解决方案探索现实世界的 AI 实施，从企业 RAG 系统和边缘推理到负责任的 AI 实践和数据迁移策略。这些用例展示了NetApp如何帮助组织在不同环境中部署 AI 应用程序，同时保持安全性、性能和可扩展性。</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">NetApp AI 用例和应用程序</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">使用NetApp解决方案探索现实世界的 AI 实施，从企业 RAG 系统和边缘推理到负责任的 AI 实践和数据迁移策略。这些用例展示了NetApp如何在保持安全性、性能和可扩展性的同时，在不同环境中支持 AI 应用程序。</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">企业 AI 应用和用例</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">适用于企业 RAG 的NetApp AIPod Mini</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">生成式人工智能和NetApp价值</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">NetApp和联想合作的边缘 AI 推理</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">大数据分析向人工智能迁移</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">负责任的人工智能</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">Protopia 图像转换的负责任的 AI</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">AI存储和基础设施解决方案</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">采用 E 系列系统设计 Quantum StorNext</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">使用 E 系列系统部署 Quantum StorNext</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">利用 NetApp 针对大数据工作负载的成熟解决方案（包括 Apache Spark、Hadoop、Kafka 以及从边缘扩展到云的现代数据湖架构）转变您的数据分析基础架构。</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">NetApp现代数据分析解决方案</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">NetApp现代数据分析解决方案是一套战略和技术能力，展示了NetApp存储在 AI 领域的能力。</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Apache Kafka 解决方案</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">使用NetApp NFS 存储的 Apache Kafka 工作负载</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">Confluent Kafka 与NetApp ONTAP存储控制器</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 的最佳实践</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">使用 AWS 验证 Kafka 性能</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Apache Spark 和 Hadoop 解决方案</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">适用于 Apache Spark 的NetApp存储解决方案</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">使用NetApp存储部署 Apache Spark 工作负载</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">适用于 Spark 和 Hadoop 的NetApp混合云数据解决方案</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">用例和架构</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Apache Spark 测试结果</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">云数据管理和人工智能</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">利用NetApp文件对象二元性和 AWS SageMaker 进行云数据管理</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">大数据分析到人工智能</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">Amazon FSx for NetApp ONTAP （适用于 MLOps）</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Apache Spark 混合云解决方案</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">现代数据湖和分析平台</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">NetApp和 Dremio 的下一代混合冰山湖屋解决方案</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E系列E5700和Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">其他资源</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">针对不同分析策略的不同解决方案</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">博客：Apache Spark 在NetApp数据分析实践中大显身手</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">博客：使用 XCP 将数据从数据湖和 HPC 迁移到ONTAP NFS</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV：大数据分析播放列表</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">人工智能解决方案</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">视频</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">NetApp Trident配置</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">用于AIPod部署的Trident后端</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">用于AIPod部署的 Kubernetes StorageClasses</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Apache Airflow 部署</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">JupyterHub 部署</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">使用NetApp SnapMirror提取数据</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">MLflow 部署</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">使用NetApp和 MLflow 实现数据集到模型的可追溯性</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Kubeflow 部署</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">预配 Jupyter Notebook 工作区</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">训练图像识别模型 - 示例工作流程</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Trident操作示例</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">AIPod部署的高性能作业示例</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">执行单节点 AI 工作负载</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">执行同步分布式 AI 工作负载</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">Domino Data Lab 和NetApp的混合 MLOps</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">初始设置</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">将现有的NetApp卷公开给 Domino</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">跨不同环境访问相同数据</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">追加信息</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">使用NVIDIA NGC 软件</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">用例示例 - TensorFlow 训练作业</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">第 1 部分 - 将Amazon FSx for NetApp ONTAP作为私有 S3 存储桶集成到 AWS SageMaker</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">第 2 部分 - 利用Amazon FSx for NetApp ONTAP作为 SageMaker 中模型训练的数据源</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">第 3 部分 - 构建简化的 MLOps 管道</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">适用于自动驾驶工作负载的NetApp StorageGRID数据湖</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">NetApp的矢量数据库解决方案</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">矢量数据库</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">技术要求</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">使用SnapCenter进行矢量数据库保护</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">使用SnapMirror进行灾难恢复</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">使用 PostGreSQL 的 Instaclustr 矢量数据库：pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">附录 B：prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">附录 D：docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">人工智能融合基础设施</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">搭载NVIDIA DGX 系统的 NVA-1173 NetApp AIPod</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">硬件组件</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">软件组件</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">示例部署详细信息</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">验证和尺寸指导</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">结论和补充信息</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">搭载NetApp EF 系列的NVIDIA DGX SuperPOD</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">NetApp上的 BeeGFS 与 E 系列存储</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">使用 E 系列存储部署 IBM Spectrum Scale</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">ONTAP和联想 ThinkSystem 的 AI 解决方案</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">NetApp ONTAP和联想 ThinkSystem SR670 助力 AI</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">人工智能用例</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">适用于 RAG 推理的NetApp AIPod Mini</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">负责任的 AI 和机密推理 - NetApp AI 与 Protopia 图像转换</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">将数据从大数据环境迁移到人工智能环境</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">边缘 AI 推理 - NetApp与联想 ThinkSystem - 解决方案设计</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Quantum StorNext 与NetApp E 系列系统设计指南</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Quantum StorNext 与NetApp E 系列系统部署指南</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">现代数据分析</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NetApp针对 NFS 到 Kafka 工作负载中愚蠢重命名问题的解决方案</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">AWS 中的性能概述和验证 - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">AWS 中的性能概述和验证 - FSx for NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">使用AFF本地进行性能概述和验证</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">汇合性能验证</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">用例摘要</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS 到 NFS - 详细步骤</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Confluent 自我再平衡集群</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp混合云数据解决方案 - 基于客户用例的 Spark 和 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">用例 1 - 备份 Hadoop 数据</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">用例 2 - 从云到本地的备份和灾难恢复</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">用例 3 - 在现有 Hadoop 数据上启用 DevTest</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">用例 4 - 数据保护和多云连接</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">用例 5 - 加速分析工作负载</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">NetApp和 Dremio 的下一代混合 Iceberg Lakehouse 解决方案</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">客户用例</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">针对不同分析策略的不同解决方案解决方案简介</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Splunk SmartStore 的StorageGRID功能</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">分层和成本节省</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">单站点 SmartStore 性能</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">Apache Spark 工作负载与NetApp存储解决方案（部署指南）</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">英特尔至强 6980P 2P 128C 2G 504M 500W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
  <block id="fe1394c0024b947430d8383108eb2177" category="summary">搭载NetApp AFF A90 的NVIDIA DGX SuperPOD</block>
  <block id="bf8899c5267692573fb1304655fb765a" category="doc">搭载NVIDIA DGX SuperPOD 的NetApp AFF A90存储系统</block>
  <block id="7fa0ca2a0d7f53f3c8e59fc6c3e9ed2e" category="section-title">NVA 部署</block>
  <block id="8be806d9daf2bc32156e83bc0d005ec1" category="paragraph">搭载NetApp AFF A90存储系统的NVIDIA DGX SuperPOD将NVIDIA DGX 系统的世界一流计算性能与NetApp云连接存储系统相结合，为机器学习 (ML)、人工智能 (AI) 和高性能技术计算 (HPC) 提供数据驱动的工作流程。本文档介绍了将AFF A90存储系统集成到 DGX SuperPOD 架构的配置和部署细节。</block>
  <block id="9b418007fd18dc2176e46adcd30db45f" category="inline-image-macro">nvidia 标志</block>
  <block id="c94ba3511d0db1d6babbf53090c19530" category="paragraph"><block ref="c94ba3511d0db1d6babbf53090c19530" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6091ca16495cdce90805252a1c12f4e6" category="section-title">项目摘要</block>
  <block id="c6f9b4ccfaf7da44e6c0c60854f0949d" category="paragraph">NVIDIA DGX SuperPOD™ 为组织提供交钥匙 AI 数据中心解决方案，无缝提供世界一流的计算、软件工具、专业知识和持续创新。 DGX SuperPOD 可为客户提供部署 AI/ML 和 HPC 工作负载所需的一切，同时最大程度地缩短设置时间并提高生产力。图 1 显示了 DGX SuperPOD 的高级组件。</block>
  <block id="d144add61531a9bfe79e667824356b40" category="paragraph">图 1) 带有NetApp AFF A90存储系统的NVIDIA DGX SuperPOD 。</block>
  <block id="bbd4822469057d9beafe8509a7ebee14" category="paragraph"><block ref="bbd4822469057d9beafe8509a7ebee14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283d31c0198ed7454a249b3e2b6eb174" category="paragraph">DGX SuperPOD 具有以下优势：</block>
  <block id="3ff8aa027f2fe1f296899270ebbb43fd" category="list-text">经过验证的 AI/ML 和 HPC 工作负载性能</block>
  <block id="ca127ea10cbbac4cda1fefa3e946e9ba" category="list-text">从基础设施管理和监控到预先构建的深度学习模型和工具的集成硬件和软件堆栈。</block>
  <block id="a4cb23a9ac5d711552fe29021242bf26" category="list-text">从安装和基础设施管理到扩展工作负载和简化生产 AI 的专用服务。</block>
  <block id="96cffe8fd08355ee862ba83cb15407d9" category="paragraph">随着各组织采用人工智能 (AI) 和机器学习 (ML) 计划，对强大、可扩展且高效的基础设施解决方案的需求从未如此强烈。这些举措的核心在于管理和训练日益复杂的人工智能模型，同时确保数据安全、可访问性和资源优化。 </block>
  <block id="61b865c697c4f21886d14a618df70f6d" category="paragraph">该解决方案具有以下主要优势：</block>
  <block id="aa88ccfa825dadd9cbb9acc84e508b2c" category="list-text">可扩展性</block>
  <block id="4738ea23a01f5635ce1c45dabb47da5c" category="list-text">*数据管理和访问*</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="list-text">*安全*</block>
  <block id="3c858853158f1a99c39a781718ec762c" category="inline-link">NVA-1175 设计指南</block>
  <block id="bc3456dcc61fc69ddf5057eb2521a503" category="inline-link">+++ NVIDIA DGX SuperPOD参考架构+++</block>
  <block id="0db7341d4a6ac5f5ae439217ea22f2cf" category="paragraph">NVIDIA DGX SuperPOD包含必要的服务器、网络和存储，可为要求苛刻的 AI 工作负载提供经过验证的性能。 NVIDIA DGX™ H200 和 B200 系统提供世界一流的计算能力， NVIDIA Quantum InfiniBand 和 Spectrum™ 以太网网络交换机提供超低延迟和业界领先的网络性能。借助NetApp ONTAP存储业界领先的数据管理和性能功能，客户可以更快地实现 AI/ML 计划，并减少数据迁移和管理开销。有关此解决方案中特定组件的更多信息，请参阅<block ref="a5c1176c129a896b2b922e5580efc58f" category="inline-link-rx"></block>和<block ref="1910ffa640b224c818fe3ba99c94129a" category="inline-link-rx"></block>文档。</block>
  <block id="c18232c17d0f8ffeae2d726834c91f89" category="paragraph">NVIDIA DGX SuperPOD旨在满足最苛刻的工作负载的性能和规模要求。</block>
  <block id="36ff5f6df178e197d3123e478db8410b" category="list-text">使用传统分析工具进行大规模机器学习。</block>
  <block id="2d12f254287ce40df1f66968734498ba" category="list-text">针对大型语言模型、计算机视觉/图像分类、欺诈检测和无数其他用例的人工智能模型训练。</block>
  <block id="d8f31668d0cecb0b54a6d01e2f76c6cf" category="list-text">高性能计算，如地震分析、计算流体动力学和大规模可视化。</block>
  <block id="f0414b39a05dd4079562350e267bf1b3" category="inline-link">+++ NVIDIA DGX SuperPOD参考架构+++</block>
  <block id="5f5d88c3d3b4a5616e3937b4fe349866" category="paragraph">DGX SuperPOD 基于可扩展单元 (SU) 的概念，它包含提供所需连接和性能以及消除基础设施中任何瓶颈所需的所有组件。客户可以从一个或多个 SU 开始，然后根据需要添加其他 SU 来满足其要求。更多信息请参阅<block ref="b3bda9bcc3402290297547b224b66efa" category="inline-link-rx"></block>。本文档介绍了单个 SU 的存储组件和配置。</block>
  <block id="353fc344c9bee691edbf50c13067653c" category="paragraph">表 1 列出了实现 1SU 存储组件所需的硬件组件。有关 1-4 个可扩展单元的具体零件和数量，请参阅附录 A。</block>
  <block id="6cef63cf1d59b401d88755cbea01a416" category="paragraph">表 1) 硬件要求。</block>
  <block id="46f0306a597ab13c222e7d6551ce9f96" category="cell">NetApp AFF A90存储系统</block>
  <block id="c28cb49992003622546cc5f9509cfcff" category="cell">NetApp存储集群互连交换机</block>
  <block id="9097f0013a59ba655e2c83bd26ae1ce7" category="cell">NVIDIA 800GB -&gt; 4x 200Gb 分离器电缆</block>
  <block id="aec453803363ab0e5ca6f6df8d465def" category="inline-link">+++DGX SuperPOD 发行说明+++</block>
  <block id="b6ffed0f516d3b52a4910321a2a889ba" category="paragraph">表 2 列出了将AFF A90存储系统与 DGX SuperPOD 集成所需的最低软件组件和版本。 DGX SuperPOD 还涉及此处未列出的其他软件组件。请参阅<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block>了解完整详情。</block>
  <block id="c50cf4cacfaa91c82ab6a24e939cbaca" category="paragraph">表 2) 软件要求。</block>
  <block id="518f98e82df6bde3bef11b7aa885a289" category="cell">9.16.1 或更高版本</block>
  <block id="df6c5bc905afa2504396faf036b87927" category="cell">NVIDIA BaseCommand 管理器</block>
  <block id="6fe49606da6092b118e02ef2d0ef0d6c" category="cell">10.24.11 或更高版本</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX 操作系统</block>
  <block id="ba2b41c4ccfe23325bd590218a62fa8a" category="cell">6.3.1 或以上</block>
  <block id="be49cc02b8372e6202cf52fbe8204ead" category="cell">NVIDIA OFED 驱动程序</block>
  <block id="cf439b0da4b623c11f90db3c956758b1" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS 或更高版本</block>
  <block id="c220bcc9beaaaf29d1905f9819577f0b" category="cell">NVIDIA Cumulus 操作系统</block>
  <block id="f7bfb037c565dcf0f80631851ee87307" category="cell">5.10或以上</block>
  <block id="ea1eee49815915fc6500c0bfc1fcef31" category="paragraph">将NetApp ONTAP存储与 DGX SuperPOD 集成涉及以下任务：</block>
  <block id="dc8a828d28f4f811808cdb82b54453ec" category="list-text">带有 RoCE 的NetApp AFF A90存储系统的网络配置</block>
  <block id="37c6bfb67043d31447903c4665d6ed11" category="list-text">存储系统的安装和配置</block>
  <block id="4cafd7b33984b4cb34f95fe4314e4a49" category="list-text">使用NVIDIA Base Command™ Manager 进行 DGX 客户端配置</block>
  <block id="b8088d3f2b3972d6f986cf0a37543617" category="section-title">场地准备和基本安装</block>
  <block id="bf0615788eed920e4e9f1a96749cfb34" category="inline-link">+++ AFF A90硬件安装文档+++</block>
  <block id="e1006e935ca66a5f59a3fd40689fff46" category="paragraph">作为标准部署服务的一部分， NetApp专业服务将为所有 DGX SuperPOD 部署执行AFF A90存储集群的场地准备和基本安装。 NetApp PS 将确认现场条件是否适合安装，并将硬件安装在指定的机架中。他们还将连接 OOB 网络连接并使用客户提供的网络信息完成基本集群设置。附录 A – 物料清单和机架立面图包括标准机架立面图以供参考。有关 A90 安装的更多信息，请参阅<block ref="7ddd605a062e7b77012eccf1c4bcffd7" category="inline-link-rx"></block>。</block>
  <block id="321c92980ad0e1d922d02a2f704ca782" category="paragraph">标准部署完成后， NetApp PS 将使用以下步骤完成存储解决方案的高级配置，包括与 Base Command Manager 集成以实现客户端连接和调整。</block>
  <block id="00720789d4f50564af280240dfe0c1a0" category="section-title">将存储系统布线到 DGX SuperPOD 存储结构</block>
  <block id="93f38c7fefe0798b27b29ac2727c9aff" category="paragraph">AFF A90存储系统使用每个控制器四个 200Gb 以太网端口连接到存储结构叶交换机，每个交换机有两个连接。 NVIDIA Spectrum SN5600 交换机上的 800Gb 交换机端口使用附录 A 中列出的适当 DAC 或光分路器配置分成 4 个 200Gb 端口。每个交换机端口的各个端口分布在存储控制器上，以消除单点故障。下面的图 2 显示了存储结构连接的布线：</block>
  <block id="428c881d379aed620164886a529bf2ac" category="paragraph">图 2) 存储网络布线。</block>
  <block id="e97080670de5db4003a6abdd37d81eb5" category="paragraph"><block ref="e97080670de5db4003a6abdd37d81eb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb83bbea93dbe46008125af94bc508be" category="section-title">将存储系统布线到 DGX SuperPOD 带内网络</block>
  <block id="3c4e3bd6ddc8a3cd692e2866674ec982" category="paragraph">NetApp ONTAP包含业界领先的多租户功能，使其既可以作为 DGX SuperPOD 架构中的高性能存储系统运行，又可以支持主目录、组文件共享和基本命令管理器集群工件。为了在带内网络上使用，每个AFF A90控制器都连接到带内网络交换机，每个控制器有一个 200Gb 以太网连接，并且端口配置为 LACP MLAG 配置。下面的图 3 显示了存储系统到带内和 OOB 网络的布线。</block>
  <block id="651c2d0bd757128b4d9ed91fc5026a3d" category="paragraph">图 3) 带内和 OOB 网络布线。</block>
  <block id="92bf4c084f930281026def79beae3794" category="paragraph"><block ref="92bf4c084f930281026def79beae3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76edc3dadc8deca645fd525182eaad33" category="section-title">为 DGX SuperPOD 配置ONTAP</block>
  <block id="41905234b7d34b88a1559733c741d5aa" category="inline-link">+++ ONTAP文档+++</block>
  <block id="d4b2d66f490475665ea833d8f89c2cfd" category="paragraph">该解决方案利用多个存储虚拟机 (SVM) 来托管卷，以实现高性能存储访问以及管理 SVM 上的用户主目录和其他集群工件。每个 SVM 都配置了存储或带内网络上的网络接口，以及用于数据存储的FlexGroup卷。为了确保数据 SVM 的性能，实施了存储 QoS 策略。有关 FlexGroups、存储虚拟机和ONTAP QoS 功能的更多信息，请参阅<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block>。</block>
  <block id="fec48034cdf04f518f58b4f727f55543" category="section-title">配置基本存储</block>
  <block id="7e4b30d10f60fcb3bdf4c3382d601615" category="section-title">在每个控制器上配置单个聚合</block>
  <block id="3c6858e020c27b4eb574d124f73c04d3" category="paragraph">对集群中的每个节点重复上述步骤。</block>
  <block id="241ba9d616774bbadf9c9f28ee386505" category="section-title">在每个控制器上配置 ifgrps 以实现带内网络</block>
  <block id="610c7975125c56dc62b000999926f4d8" category="section-title">为 RoCE 配置物理端口</block>
  <block id="ff00a412cfca01b43041104775ac8460" category="paragraph">启用 NFS over RDMA 需要进行配置以确保网络流量在客户端和服务器上都被适当标记，然后由网络使用 RDMA over Converged Ethernet (RoCE) 进行适当处理。这包括配置优先流量控制 (PFC) 和配置要使用的 PFC CoS 队列。执行以下命令时， NetApp ONTAP还会自动配置 DSCP 代码 26 以与网络 QoS 配置保持一致。</block>
  <block id="e9dc479a2f60169b39fb74cc86d13a43" category="section-title">创建管理 SVM</block>
  <block id="ce25292d4b04b878f74951ed7b5fb173" category="section-title">创建并配置管理 SVM</block>
  <block id="c110d2ffde8993db523c41f0c524e68e" category="section-title">在管理 SVM 上配置 NFS 服务</block>
  <block id="5441effcbbef51defcc1340e745e28ad" category="section-title">为带内网络接口创建 IP 子网</block>
  <block id="919d6feabfd1e5f5f04bedfd487f50c8" category="paragraph">*注意：*客户需在部署时提供 IP 子网信息，以便集成到现有客户网络中。</block>
  <block id="2bc9e41900e064c3368d9eca2dba546c" category="section-title">在每个节点上为带内 SVM 创建网络接口</block>
  <block id="44db41cf8b74978388680587aa8b7d55" category="section-title">为管理 SVM 创建FlexGroup卷</block>
  <block id="20d5f1ad8803160edb381217d776701e" category="section-title">为管理 SVM 创建导出策略</block>
  <block id="1624c693fdd8f06e52c87d0b2b576a19" category="section-title">创建数据 SVM</block>
  <block id="9ff068915b90e059d15444fe8dc13aaa" category="section-title">创建并配置数据 SVM</block>
  <block id="cb7d25e4139e72b33ef687ed8a0ae945" category="section-title">在启用 RDMA 的数据 SVM 上配置 NFS 服务</block>
  <block id="ca1f913932acc2aad423357d56f86ea7" category="section-title">为 Data SVM 网络接口创建 IP 子网</block>
  <block id="3c2060cdeb230d3f42a725b2a9ca7e23" category="section-title">在每个节点上为 Data SVM 创建网络接口</block>
  <block id="ca648b8fb4bf1f54cbf7a626468eada3" category="section-title">为 RDMA 配置数据 SVM 网络接口</block>
  <block id="afb51d28a404c42df2a054df2c6da14b" category="section-title">在数据 SVM 上创建导出策略</block>
  <block id="d9a6b253dd081b231d9d1a14cec7a227" category="section-title">在数据 SVM 上创建静态路由</block>
  <block id="4f3e59209435398e52c0df85d0034275" category="section-title">使用 GDD 为数据 SVM 创建FlexGroup卷</block>
  <block id="08ec3810f1dcb452442911f8d8173b1a" category="paragraph">粒度数据分布 (GDD) 支持将大型数据文件分布在多个FlexGroup组成卷和控制器上，以实现单文件工作负载的最高性能。  NetApp建议在所有 DGX SuperPOD 部署的数据卷上启用 GDD。</block>
  <block id="7eb2bd842a06eb48d9bbfe4f644731d9" category="section-title">禁用主数据卷的存储效率</block>
  <block id="8a0cdebf4e36c1af6ac542485413a77b" category="paragraph">卷效率关闭-vserver spod_data-volume spod_data</block>
  <block id="46e5a2d41b69706b3dcd5e89c34e7c5e" category="section-title">为数据 SVM 创建 QoS 最小策略</block>
  <block id="065d35d3d9a4319f54773a754b2c0e6c" category="section-title">为数据 SVM 应用 QoS 策略</block>
  <block id="2cc5056a61a5f1643bf387d49d197728" category="section-title">使用NVIDIA Base Command Manager 配置 DGX 服务器</block>
  <block id="e546e9d0da56999b5973de8a7ad71572" category="paragraph">要准备 DGX 客户端使用AFF A90存储系统，请完成以下任务。此过程假定已在 DGX 系统节点上配置了存储结构的网络接口和静态路由。以下任务将由NetApp专业服务作为高级配置过程的一部分完成。</block>
  <block id="f9a9381a56f728d139ee191de307ef5f" category="section-title">使用所需的内核参数和其他设置配置 DGX 服务器映像</block>
  <block id="256b6f56d994f129832d2b7567bb951f" category="paragraph">NetApp ONTAP使用行业标准 NFS 协议，不需要在 DGX 系统上安装任何其他软件。为了使客户端系统获得最佳性能，需要对 DGX 系统映像进行一些修改。使用以下命令进入 BCM 映像 chroot 模式后执行以下两个步骤：</block>
  <block id="45fb2f19f77fc1d9d4dfdd092f805b42" category="section-title">在 /etc/sysctl.conf 中配置系统虚拟内存设置</block>
  <block id="13b4c0be439ee4875352c0ff2a039c13" category="paragraph">默认的 Linux 系统配置提供的虚拟内存设置不一定能提供最佳性能。对于具有 2TB RAM 的 DGX B200 系统，默认设置允许 40GB 的缓冲区空间，这会创建不一致的 I/O 模式，并允许客户端在刷新缓冲区时使存储系统过载。以下设置将客户端缓冲区空间限制为 5GB，并强制更频繁地刷新以创建不会使存储系统过载的一致 I/O 流。</block>
  <block id="c35419f49457a55135a16f4a73d4fb6b" category="paragraph">进入镜像chroot模式后，编辑/etc/sysctl.s/90-cm-sysctl.conf文件，添加以下几行：</block>
  <block id="4caebde52be0001b1e59098dd149b653" category="paragraph">保存并关闭 /etc/sysctl.conf 文件。</block>
  <block id="d05565dbb5b9175c4df06e8d9d029a18" category="section-title">使用重启后执行的脚本配置其他系统设置</block>
  <block id="4e1ff13d493c47a47dde7cb5a24aceeb" category="paragraph">某些设置需要操作系统完全在线才能执行，并且在重启后不会持久。要在 Base Command Manager 环境中执行这些设置，请创建文件 /root/ntap_dgx_config.sh 并输入以下行：</block>
  <block id="191be9d79602632b279bc3126e49847d" category="paragraph">*保存并关闭文件。更改文件的权限，使其可执行：*</block>
  <block id="13036c88d00af2d37c1d8e1ae332f79e" category="paragraph">通过编辑以下行，创建由 root 在启动时执行的 cron 作业：</block>
  <block id="a4d911dee959cadc8c53c92d6361fc05" category="paragraph">请参阅下面的示例 crontab 文件：</block>
  <block id="e813523727c040149e1ecad0358d60b8" category="paragraph">输入 exit 或 Ctrl-D 退出 BCM 图像 chroot 模式。</block>
  <block id="70f4c658a41ea1900dd94027c0ffa103" category="section-title">为客户端挂载点配置 BaseCommand Manager DGX 类别</block>
  <block id="9df3dcf41d131b1d0097435f6b290ba4" category="paragraph">要配置 DGX 客户端安装AFF A90存储系统，应修改 DGX 系统使用的 BCM 客户端类别以包含相关信息和选项。以下步骤描述如何配置 NFS 挂载点。</block>
  <block id="dcde3a7bf8f0a03f480df9078bfa9297" category="paragraph">搭载NetApp * AFF A90存储系统* 的NVIDIA DGX SuperPOD代表了 AI 基础设施解决方案的重大进步。通过解决安全性、数据管理、资源利用率和可扩展性方面的关键挑战，它使组织能够加速其人工智能计划，同时保持运营效率、数据保护和协作。该解决方案的集成方法消除了人工智能开发流程中的常见瓶颈，使数据科学家和工程师能够专注于创新而不是基础设施管理。</block>
  <block id="77b69988a6b247bd3829a8e03ff332a6" category="inline-link">NVA-1175 NVIDIA DGX SuperPOD与NetApp AFF A90存储系统设计指南</block>
  <block id="78200c657113173ee4bd06de792e86af" category="list-text"><block ref="78200c657113173ee4bd06de792e86af" category="inline-link-rx"></block></block>
  <block id="4b70410b9d727a1fc1d60d4483d86325" category="inline-link">NVIDIA DGX B200 SuperPOD 参考架构</block>
  <block id="54dbc563049b479cfef99d1d872020e4" category="list-text"><block ref="54dbc563049b479cfef99d1d872020e4" category="inline-link-rx"></block></block>
  <block id="d5023dae85155f754c6bfd520cbdc150" category="inline-link">+++ NVIDIA DGX H200 SuperPOD 参考架构+++</block>
  <block id="5d4678ba7793147c6b3109fcdbe3294f" category="list-text"><block ref="5d4678ba7793147c6b3109fcdbe3294f" category="inline-link-rx"></block></block>
  <block id="0018465bd63e2711758aea9e68126f6d" category="inline-link">+++ NVIDIA BaseCommand 软件+++</block>
  <block id="dd2a70a6cd8d74ddbed24590bf9efd37" category="list-text"><block ref="dd2a70a6cd8d74ddbed24590bf9efd37" category="inline-link-rx"></block></block>
  <block id="a2433670a2f11bda41782875f82e4c0e" category="inline-link">+++ NVIDIA Spectrum SN5600 以太网交换机+++</block>
  <block id="197d7b18bb595fa0c4339f599bb57c70" category="list-text"><block ref="197d7b18bb595fa0c4339f599bb57c70" category="inline-link-rx"></block></block>
  <block id="61345f1959bf0e90ce956f7fe87b97e6" category="inline-link">+++ NVIDIA DGX SuperPOD发行说明+++</block>
  <block id="a42d326cc55152a32997b9b244e9e4ea" category="list-text"><block ref="a42d326cc55152a32997b9b244e9e4ea" category="inline-link-rx"></block></block>
  <block id="18b5a5e73e5f66fb20d8f46f70d0c0ba" category="inline-link">+++ NetApp AFF A90安装+++</block>
  <block id="cc99b2a6b638db71f55772efa9ae5a44" category="list-text"><block ref="cc99b2a6b638db71f55772efa9ae5a44" category="inline-link-rx"></block></block>
  <block id="326b3ec244c0b719f75faee5d63eda19" category="inline-link">+++ NetApp AI 解决方案文档+++</block>
  <block id="2a6b527a76b4dd02f63188fa855840f7" category="list-text"><block ref="2a6b527a76b4dd02f63188fa855840f7" category="inline-link-rx"></block></block>
  <block id="7d3cb5a08ca45610a4bc66221efd1e06" category="inline-link">+++ NetApp ONTAP软件+++</block>
  <block id="7de45c9a3f46892f98b68ddb83483727" category="list-text"><block ref="7de45c9a3f46892f98b68ddb83483727" category="inline-link-rx"></block></block>
  <block id="b20609bf792bc04f91d5af3f95c34249" category="inline-link">+++ NetApp安装和维护AFF存储系统+++</block>
  <block id="f4f8a0ca5a3908b7ff3dc9977384172c" category="list-text"><block ref="f4f8a0ca5a3908b7ff3dc9977384172c" category="inline-link-rx"></block></block>
  <block id="784cd7f14efdcfe6b12e47d3ac14c2ea" category="list-text"><block ref="784cd7f14efdcfe6b12e47d3ac14c2ea" category="inline-link-rx"></block></block>
  <block id="2af6b6d1a0f9284afbd220786019c104" category="inline-link">+++什么是 pNFS+++</block>
  <block id="40b22abaae26a9e924653fdf64192dd5" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>（包含大量 pNFS 信息的旧文档）</block>
  <block id="8b609f2b56884902c05d97d442f1d533" category="section-title">附录 A：物料清单和机架立面图</block>
  <block id="97ac09ecf630c90bdc4eae789d1cb26e" category="paragraph">表 3 显示了部署一个、两个、三个和四个可扩展单元的存储所需的NetApp组件的部件号和数量。</block>
  <block id="a399f4735d9b76eb2c734ce8b23a4051" category="paragraph">表 3) NetApp 1、2、3 和 4 SU 的 BOM。</block>
  <block id="12671d03ae10ac5096ddbf709e44e260" category="cell">部分 ＃</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">物品</block>
  <block id="4b35db9f95e91ac3ce4b119c8d590dc3" category="cell">1SU 数量</block>
  <block id="10ae8487d40b09fd13a32fd5b761dff2" category="cell">2SU 数量</block>
  <block id="4f4a383868a5c8f1aff4d21e301cf77d" category="cell">3SU 数量</block>
  <block id="7e3f2097d4da066bf518435f0d22d629" category="cell">4SU 数量</block>
  <block id="a9eadd771f7974cbfb4a0f82da15155e" category="cell">AFF-A90A-100-C</block>
  <block id="a5b8692ce33078554d4df65b88479996" category="cell">AFF A90存储系统</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="109799441719d48125200028617a078c" category="cell">X4025A-2-A-C</block>
  <block id="ae1ffcee034fa197d7e6a3d49392ad1b" category="cell">2x7.6TB 驱动器组</block>
  <block id="0a09c8844ba8f0936c20bd791130d6b6" category="cell">144</block>
  <block id="58a2fc6ed39fd083f55d4182bf88826d" category="cell">192</block>
  <block id="01fc28c75297fac48aca3e18491846a8" category="cell">X50131A-C</block>
  <block id="ef52c5c3e61828c1957bb235e48b9aaf" category="cell">IO 模块，2PT，100/200/400GbE</block>
  <block id="76dc611d6ebaafc66cc0879c71b5db5c" category="cell">128</block>
  <block id="da07ac8264b7cdb99a4eb96ab4d91111" category="cell">X50130A-C</block>
  <block id="02104e3c4b3f8d428381d1c68b10320d" category="cell">IO 模块，2PT，100GbE</block>
  <block id="90d67d58a9628ba253eee43c6dbc9559" category="cell">X-02659-00</block>
  <block id="eaba4c24f91259319d86e2dc6a375c2c" category="cell">套件，4 柱，方孔或圆孔，24 英寸 - 32 英寸导轨</block>
  <block id="a08f2932fed05b33c4945eca514134dc" category="cell">X1558A-R6</block>
  <block id="3229af69927999e5df543d1f9fb22eb5" category="cell">电源线，机柜内，48 英寸，+ C13-C14，10A/250V</block>
  <block id="98f13708210194c475687be6106a3b84" category="cell">20</block>
  <block id="d645920e395fedad7bbbed0eca3fe2e0" category="cell">40</block>
  <block id="f033ab37c30201f73f142449d037028d" category="cell">80</block>
  <block id="e6aa165cded1f8e32159470ff027af2f" category="cell">X190200-CS</block>
  <block id="7e011d9eef19544d7078d2a70563144a" category="cell">集群交换机，N9336C 36Pt PTSX10/25/40/100G</block>
  <block id="76dedba1bf45af402ab07ddd57ff749e" category="cell">X66211A-2</block>
  <block id="2a1aeb324c9e886af32f12ad5049c6f7" category="cell">电缆，100GbE，QSFP28-QSFP28，铜，2米</block>
  <block id="e2fd227baa44b6632aa7c2fef9002b8a" category="cell">X66211A-05</block>
  <block id="0dff9249f8d94512b43527f1f5b044c9" category="cell">电缆，100GbE，QSFP28-QSFP28，铜，0.5米</block>
  <block id="6e421f2c1b8bf174d208a91d7f5dc0ae" category="cell">X6561-R6</block>
  <block id="95c7e45248e11b15430ec3c5d1d3dcc1" category="cell">以太网电缆，CAT6，RJ45，5米</block>
  <block id="e369853df766fa44e1ed0ff613f563bd" category="cell">34</block>
  <block id="3295c76acbf4caaed33c36b1b5fc2cb1" category="cell">66</block>
  <block id="2a108c75662ccb5a38e6db46a016aa40" category="paragraph">表 4 显示了将AFF A90存储系统连接到高性能存储和带内网络中的 SN5600 交换机所需的NVIDIA电缆的零件编号和数量。</block>
  <block id="c71399ea2a367ce779897d49ca77b4a0" category="paragraph">表 4) 将AFF A90存储系统连接到高性能存储和带内网络中的 SN5600 交换机所需的NVIDIA电缆。</block>
  <block id="5557f1218ab08d91639048aab26f1de0" category="cell">MCP7Y40-N003</block>
  <block id="2b11e18cd1f4ae786c28a6a1bce455ed" category="cell">DAC 3m 26ga 2x400G 至 4x200G OSFP 至 4xQSFP112</block>
  <block id="19ca14e7ea6328a42e0eb13d585e4c22" category="cell">36</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="cell">或</block>
  <block id="84686a1d557f4fefd53eaff2d691796d" category="cell">MMS4X00-NS</block>
  <block id="e67c53a2100e086542158b7496d248a7" category="cell">双端口 OSFP 2x400G 2xSR4 多模收发器双 MPO-12/APC</block>
  <block id="bbf6b7b52739d4479aae0bd6508ac746" category="cell">MFP7E20-N0XX</block>
  <block id="718b622b69fc995a4d3738ecaf2953b0" category="cell">多模光纤分路器 400G-&gt; 2x200G XX = 03、05、07、10、15、20、30、40、50) 米</block>
  <block id="7b55b9077a4e94ce71aba3fbb4b1ebcd" category="cell">MMA1Z00-NS400</block>
  <block id="1d1c4e0c3b72af208b18fbbfbf63c17b" category="cell">单端口 400G SR4 多模 QSFP112 收发器单 MPO-12/APC</block>
  <block id="098103233c14421a2092214651f99ac3" category="section-title">机架高度</block>
  <block id="64441b5a3bcfb8a874107dfe4766feb6" category="paragraph">图 4-6 显示了 1-4 SU 的示例机架立面。</block>
  <block id="c22e6da1b1ce3c83fb3004d53e804737" category="paragraph">图 4) 1 SU 和 2 SU 的机架高度。</block>
  <block id="7ef24ed03ec40ae9ef02f5c904953418" category="paragraph"><block ref="7ef24ed03ec40ae9ef02f5c904953418" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64769808ba101c666bcd29615cc1e9d3" category="paragraph">图 5) 3 SU 的机架立面图。</block>
  <block id="02a5df2de00e7145cadd3753d42d3dc1" category="paragraph"><block ref="02a5df2de00e7145cadd3753d42d3dc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d7011e8983f361d68e382e119c1819" category="paragraph">图 6) 4 SU 的机架立面图。</block>
  <block id="381008e8bad1425034ca5fa30cd57133" category="paragraph"><block ref="381008e8bad1425034ca5fa30cd57133" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9376ca935750f1ee987d9b2ce256bfbf" category="paragraph">搭配NetApp AFF A90 存储系统的NVIDIA DGX SuperPOD ™ 将NVIDIA DGX 系统的世界一流计算性能与NetApp云连接存储系统相结合，为机器学习 (ML)、人工智能 (AI) 和高性能技术计算 (HPC) 提供数据驱动的工作流程。本文档介绍了使用带有以太网存储结构的NetApp AFF A90存储系统的 DGX SuperPOD 解决方案的高级架构。</block>
  <block id="180ea794b48cd487087e5b1dd21023f0" category="paragraph">凭借NVIDIA DGX SuperPOD经过验证的计算性能以及 NetApp 业界领先的数据安全、数据治理和多租户功能，客户可以为下一代工作负载部署最高效、最敏捷的基础架构。本文档介绍了可帮助客户加快 AI/ML 计划的上市时间和投资回报的高级架构和关键功能。</block>
  <block id="98e7b017fa4951d28f1516c0bee63969" category="section-title">项目摘要</block>
  <block id="0e7a454160d4f81e5b82fe865851c0b5" category="paragraph">NVIDIA DGX SuperPOD为组织提供交钥匙 AI 数据中心解决方案，无缝提供世界一流的计算、软件工具、专业知识和持续创新。 DGX SuperPOD 可为客户提供部署 AI/ML 和 HPC 工作负载所需的一切，同时最大程度地缩短设置时间并提高生产力。图 1 显示了 DGX SuperPOD 的高级组件。</block>
  <block id="0df8fda8ee1a402c3eb7dc7582d3a710" category="paragraph"><block ref="0df8fda8ee1a402c3eb7dc7582d3a710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d91208793b9a449dbecfd553707c79d6" category="list-text">从基础设施管理和监控到预先构建的深度学习模型和工具的集成硬件和软件堆栈。</block>
  <block id="84245e1cf723377c5a2991885cd57409" category="list-text">从安装和基础设施管理到扩展工作负载和简化生产 AI 的专用服务</block>
  <block id="5d8430a9387a385c7ee9a8b83ff28b12" category="paragraph">随着各组织采用人工智能 (AI) 和机器学习 (ML) 计划，对强大、可扩展且高效的基础设施解决方案的需求从未如此强烈。这些举措的核心在于管理和训练日益复杂的人工智能模型，同时确保数据安全、可访问性和资源优化。代理人工智能的发展和复杂的模型训练要求对计算和存储基础设施提出了前所未有的需求。组织现在必须处理海量数据集、支持多个并发训练工作负载并维护高性能计算环境，同时确保数据保护和法规遵从性。传统的基础设施解决方案往往难以满足这些需求，导致运营效率低下和人工智能项目价值实现时间延迟。该解决方案具有以下主要优势：</block>
  <block id="1844a1480427b3b276783fd66fc58226" category="list-text">*可扩展性*采用NetApp AFF A90存储系统的NVIDIA DGX SuperPOD通过其模块化架构和灵活的扩展功能提供无与伦比的可扩展性。组织可以通过添加 DGX 计算节点和AFF A90存储系统来无缝扩展其 AI 基础架构，而不会中断现有工作负载或需要复杂的重新配置。</block>
  <block id="02a63d3f709e7b79dac689e7724d8821" category="list-text">*数据管理和访问。*搭载NetApp AFF A90存储系统的NVIDIA DGX SuperPOD基于NetApp ONTAP ，通过其全面的企业级功能套件在数据管理方面表现出色。使用 ONTAP 的快照和FlexClone功能，团队可以立即创建数据集和矢量数据库的节省空间的副本，以进行并行开发和测试。  FlexCache和 Snapmirror 复制技术支持从整个企业的数据源实现精简、节省空间和自动化的数据管道，而使用 NAS 和对象协议的多协议数据访问支持针对摄取和数据工程任务优化的新工作流程。</block>
  <block id="3b5ce4caaf6acea212e6608eb826a52c" category="list-text">*安全。* NetApp AFF A90存储系统通过多层保护提供企业级安全性。在基础设施层面，该解决方案实现了强大的访问控制机制，包括基于角色的访问控制（RBAC）、多因素身份验证和详细的审计日志记录功能。该平台的综合加密框架可保护静态和传输中的数据，利用行业标准协议和算法来保护知识产权并保持符合监管要求。集成的安全监控工具可实时查看潜在的安全威胁，而自动响应机制则有助于在风险影响运营之前降低风险。</block>
  <block id="d2374eb265fd2592ef7b4b817140ba67" category="paragraph">该解决方案适用于具有 HPC 和 AI/ML 工作负载的组织，这些工作负载需要更深入地集成到广泛的数据资产和传统 IT 基础设施工具和流程中。</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">解决方案的目标受众包括以下群体：</block>
  <block id="f79b8cf1009178e9a2fd45c1f4ae4ef7" category="list-text">IT 和业务决策者正在规划最高效的基础设施，以最快的上市时间和投资回报来实现 AI/ML 计划。</block>
  <block id="c328ed7f0a74043c4e73f7ea491b4eb7" category="list-text">数据科学家和数据工程师有兴趣最大程度地提高 AI/ML 工作流程中以关键数据为中心的部分的效率。</block>
  <block id="fa7b81174ad3677e1ed9da1ea8185c4d" category="list-text">IT 架构师和工程师需要提供可靠、安全的基础架构，以实现自动化数据工作流并符合现有的数据和流程治理标准。</block>
  <block id="dad37ea926873ef3d5ee869827ddc40c" category="paragraph">NVIDIA DGX SuperPOD包含必要的服务器、网络和存储，可为要求苛刻的 AI 工作负载提供经过验证的性能。 NVIDIA DGX™ H200 和NVIDIA DGX B200 系统提供世界一流的计算能力， NVIDIA Quantum 和 Spectrum™ InfiniBand 网络交换机提供超低延迟和业界领先的网络性能。借助NetApp ONTAP存储业界领先的数据管理和性能功能，客户可以更快地实现 AI/ML 计划，并减少数据迁移和管理开销。以下部分介绍了带有AFF A90存储系统的 DGX SuperPOD 的存储组件。</block>
  <block id="4caba5452d50c27473615492a421d0b7" category="section-title">搭载NetApp ONTAP 的NetApp AFF A90存储系统</block>
  <block id="5b01f10375ddf0fa7a318292fb1ab544" category="paragraph">由NetApp ONTAP数据管理软件提供支持的NetApp AFF A90提供内置数据保护、反勒索软件功能以及支持最关键业务工作负载所需的高性能、可扩展性和弹性。它消除了对关键任务操作的中断，最大限度地减少了性能调整，并保护您的数据免受勒索软件攻击。  NetApp AFF A90系统提供-</block>
  <block id="5f443413f7f04549bcfdd089e04a0c3a" category="list-text">*表现。*AFF A90可轻松管理深度学习、人工智能和高速分析等下一代工作负载以及 Oracle、SAP HANA、Microsoft SQL Server 和虚拟化应用程序等传统企业数据库。借助 NFS over RDMA、pNFS 和会话中继，客户可以使用现有的数据中心网络基础设施和行业标准协议（无需专有软件）实现下一代应用程序所需的高水平网络性能。粒度数据分布使单个文件能够分布在存储集群中的每个节点上，并且与 pNFS 结合使用时可以对单个大文件中包含的数据集进行高性能并行访问。</block>
  <block id="ae299319707718bf9587df62a89ca873" category="list-text">*智力。*利用基于数据驱动智能、面向未来的基础架构以及与NVIDIA和 MLOps 生态系统的深度集成构建的 AI 就绪生态系统来加速数字化转型。使用 ONTAP 的快照和FlexClone功能，团队可以立即创建节省空间的数据集副本，以进行并行开发和测试。 FlexCache和 Snapmirror 复制技术可实现整个企业内数据源的简化、节省空间和自动化的数据管道。使用 NAS 和对象协议进行多协议数据访问可以实现针对摄取和数据工程任务优化的新工作流程。数据和训练检查点可以分层到成本较低的存储，以避免填满主存储。客户可以通过单一存储操作系统和业界最丰富的数据服务套件，以最低的成本跨混合云无缝地管理、保护和调动数据。</block>
  <block id="3a6d4fa926afe309c404561a18033103" category="list-text">*安全。*搭载NetApp ONTAP存储的NVIDIA DGX SuperPOD通过多层保护提供企业级安全性。在基础设施层面，该解决方案实现了强大的访问控制机制，包括基于角色的访问控制（RBAC）、多因素身份验证和详细的审计日志记录功能。该平台的综合加密框架可保护静态和传输中的数据，利用行业标准协议和算法来保护知识产权并保持符合监管要求。集成的安全监控工具可实时查看潜在的安全威胁，而自动响应机制则有助于在风险影响运营之前降低风险。  NetApp ONTAP是唯一经过验证可以存储绝密数据的强化企业存储。</block>
  <block id="5a79514564c762f34f82d2f86ba269f6" category="list-text">*多租户*。 NetApp ONTAP提供最广泛的功能，支持多租户安全地使用存储资源。存储虚拟机通过 RBAC 控制提供基于租户的管理委派，全面的 QoS 控制可保证关键工作负载的性能，同时实现最大利用率，而用于卷级加密的租户管理密钥等安全功能可保证共享存储介质上的数据安全。</block>
  <block id="234fe3186330a0015f240eaa46026f52" category="inline-link">+++ ONTAP RASS 白皮书+++</block>
  <block id="aa2c50d70660a4e07e28a4a1e62cbbeb" category="list-text">*可靠性。* NetApp通过先进的可靠性、可用性、可维护性和可管理性 (RASM) 功能消除了关键任务操作的中断，从而提供了最高的正常运行时间。更多信息请参见<block ref="06c9743ea9b1147ff9ba8b6afddf02b3" category="inline-link-rx"></block>。此外，还可以通过Active IQ和Data Infrastructure Insights提供的基于 AI 的预测分析来优化系统健康状况。</block>
  <block id="dbefda683c705de53408671cbbab4e34" category="section-title">NVIDIA DGX B200 系统</block>
  <block id="c2e6165182afeb3c2d3013f3389087b6" category="inline-link">+++NVIDIA+++</block>
  <block id="2ed6f2103f37f8b4eec016533f493515" category="inline-link">+++NVLink(™)+++</block>
  <block id="1697b07c98d5b223a74b615c776f0b65" category="inline-link">+++ NVIDIA Blackwell+++</block>
  <block id="5e923560ec7f11fe71232bd344d8d81a" category="inline-link">+++建筑+++</block>
  <block id="f7be9a2901218b858c97cd4113fbc2aa" category="paragraph">NVIDIA DGX™ B200 是一个统一的 AI 平台，适用于任何规模、处于 AI 旅程任何阶段的企业的开发到部署流程。配备八个NVIDIA Blackwell GPU，与第五代<block ref="8d33a92989a52a298d52379f9acef95c" category="inline-link-rx"></block><block ref="66ff52a072f2c292b9f50112a8543358" category="inline-link-rx"></block>DGX B200 提供领先的性能，提供比前几代产品高 3 倍的训练性能和高 15 倍的推理性能。利用<block ref="113af14b044c5bd4dc15be4b6100b100" category="inline-link-rx"></block><block ref="adaec91c8092748fe326913de2b3a1f0" category="inline-link-rx"></block>DGX B200 可以处理各种工作负载，包括大型语言模型、推荐系统和聊天机器人，使其成为希望加速 AI 转型的企业的理想选择。</block>
  <block id="f94ad1ea1a52dd514a5e42a7eec71e94" category="section-title">NVIDIA Spectrum SN5600 以太网交换机</block>
  <block id="a1bd19971bc35fdd30c6a0b2eee21865" category="paragraph">SN5600 智能叶、主干和超级主干交换机在密集的 2U 外形中提供 64 个 800GbE 端口。  SN5600 支持带有架顶式 (ToR) 交换机的标准叶子/主干设计以及行末式 (EoR) 拓扑。  SN5600 提供 1 至 800GbE 组合的多样化连接，并拥有业界领先的 51.2Tb/s 总吞吐量。</block>
  <block id="ffe61852985d936bb555e1c150a3feca" category="section-title">NVIDIA Base Command 软件</block>
  <block id="040380b5657454a9d0ce1064c83dd667" category="paragraph">NVIDIA Base Command™ 为NVIDIA DGX 平台提供支持，使组织能够充分利用NVIDIA AI 创新。有了它，每个组织都可以通过一个经过验证的平台充分发挥其 DGX 基础架构的潜力，该平台包括 AI 工作流管理、企业级集群管理、加速计算、存储和网络基础架构的库以及针对运行 AI 工作负载优化的系统软件。图 2 显示了NVIDIA Base Command 软件堆栈。</block>
  <block id="9620c8c92a535942ede6a202c5bf5b0d" category="paragraph">图 2) NVIDIA基本命令软件。</block>
  <block id="2e15a851530c5d474531243cfd838752" category="paragraph"><block ref="2e15a851530c5d474531243cfd838752" category="inline-image-macro-rx" type="image"></block></block>
  <block id="651beb53a2e8224545ff56fc0d0efd02" category="paragraph">NVIDIA Base Command Manager 为边缘、数据中心以及多云和混合云环境中的异构 AI 和高性能计算 (HPC) 集群提供快速部署和端到端管理。它可以自动配置和管理从几个节点到数十万个节点大小的集群，支持NVIDIA GPU 加速和其他系统，并支持与 Kubernetes 的编排。将NetApp AFF A90存储系统与 DGX SuperPOD 集成需要对 Base Command Manager 进行最少的配置，以调整系统并安装参数以获得最佳性能，但不需要额外的软件即可在 DGX 系统和AFF A90存储系统之间提供高可用性多路径访问。</block>
  <block id="24f67e93854c90d735466339a375c002" category="paragraph">NVIDIA DGX SuperPOD旨在满足最大规模、最苛刻的工作负载的性能要求。</block>
  <block id="cfc814162b41538ad397b897a24c4937" category="list-text">针对大型语言模型、计算机视觉/图像分类、欺诈检测和无数其他用例的人工智能模型训练。</block>
  <block id="607aa89216cc994d4e20cfce8695d306" category="list-text">高性能计算，如地震分析、计算流体动力学和大规模可视化。</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">解决方案架构</block>
  <block id="d0eadc16af6d6df8893f37be51ed2bc6" category="paragraph">DGX SuperPOD 基于可扩展单元 (SU) 的概念，其中包括 32 个 DGX B200 系统以及提供所需连接和消除基础设施中任何性能瓶颈所需的所有其他组件。客户可以从一个或多个 SU 开始，然后根据需要添加其他 SU 来满足其要求。本文档介绍了单个 SU 的存储配置，表 1 显示了更大配置所需的组件。</block>
  <block id="2a4a6621abe5b6f39b1534ead593f20a" category="inline-link">+++ NVIDIA DGX SuperPOD参考架构+++</block>
  <block id="60696b15e8be9fd24231177ac611836f" category="paragraph">DGX SuperPOD 参考架构包含多个网络， AFF A90存储系统连接到其中的几个网络。有关 DGX SuperPOD 网络的更多信息，请参阅<block ref="562b92094dd1a3e9b7e68b6a6fb7de81" category="inline-link-rx"></block>。</block>
  <block id="fdd68d018aab06584c6bc4e8351fa72b" category="paragraph">对于此解决方案，高性能存储结构是基于NVIDIA Spectrum SN5600 交换机的以太网网络，具有 Spine/Leaf 配置中的 64 个 800Gb 端口。带内网络为用户提供对其他功能（例如主目录和常规文件共享）的访问，并且也基于 SN5600 交换机，而带外 (OOB) 网络用于使用 SN2201 交换机的设备级系统管理员访问。</block>
  <block id="3a812cac2db0a2d9638c3b252cc24b8e" category="paragraph">存储结构是一种叶脊架构，其中 DGX 系统连接到一对叶交换机，存储系统连接到另一对叶交换机。多个 800Gb 端口用于将每个叶交换机连接到一对主干交换机，从而通过网络创建多个高带宽路径，以实现聚合性能和冗余。为了连接到AFF A90存储系统，每个 800Gb 端口使用适当的铜缆或光纤分支电缆分成四个 200Gb 端口。为了支持客户端使用 NFS over RDMA 安装存储系统，存储结构配置为融合以太网上的 RDMA (RoCE)，这可保证网络中的无损数据包传输。图3展示了该方案的存储网络拓扑。</block>
  <block id="6a53d316acbe58b01a749e96481412aa" category="paragraph">图 3) 存储结构拓扑。</block>
  <block id="00031e516cb8c09c104ebdb164264d7f" category="paragraph"><block ref="00031e516cb8c09c104ebdb164264d7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316d243b972562ec3f8d06fcd980b1d6" category="paragraph">NetApp AFF A90存储系统是一个 4RU 机箱，包含 2 个控制器，它们彼此作为高可用性伙伴 (HA 对) 运行，最多可配备 48 个 2.5 英寸固态磁盘 (SSD)。每个控制器使用四个 200Gb 以太网连接连接到两个 SN5600 存储叶交换机，并且每个物理端口上有 2 个逻辑 IP 接口。存储集群支持具有并行 NFS (pNFS) 的 NFS v4.1，使客户端能够直接与集群中的每个控制器建立连接。此外，会话中继将多个物理接口的性能组合到单个会话中，即使是单线程工作负载也能访问比传统以太网绑定更多的网络带宽。将所有这些功能与 RDMA 相结合，使AFF A90存储系统能够提供低延迟和高吞吐量，并可利用NVIDIA GPUDirect Storage™ 线性扩展工作负载。</block>
  <block id="2ecf799238706280879a7218f5c9384f" category="paragraph">为了连接到带内网络，AFF A90控制器在 LACP 接口组中配置了额外的 200Gb 以太网接口，可提供通用 NFS v3 和 v4 服务以及对共享文件系统的 S3 访问（如果需要）。所有控制器和存储集群交换机都连接到 OOB 网络，以实现远程管理访问。</block>
  <block id="242354762ac710a9d168daccad8ea40d" category="paragraph">为了实现高性能和可扩展性，存储控制器形成一个存储集群，该集群可以将集群节点的整个性能和容量组合到一个名为FlexGroup的命名空间中，数据分布在集群中每个节点的磁盘上。借助ONTAP 9.16.1 中发布的全新粒度数据分布功能，单个文件被分离并分布在FlexGroup中，从而为单文件工作负载提供最高级别的性能。下面的图 4 显示了 pNFS 和 NFS 会话中继如何与 FlexGroups 和 GDD 协同工作，以利用存储系统中的每个网络接口和磁盘实现对大文件的并行访问。</block>
  <block id="c3c4a8bbb2b351b3bf984cb2d6864b94" category="paragraph">图 4) pNFS、会话中继、FlexGroups 和 GDD。</block>
  <block id="4f30b88a042ae485248ebaa1099b4a91" category="paragraph"><block ref="4f30b88a042ae485248ebaa1099b4a91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ac50512926081a099344a18f27b3818" category="paragraph">该解决方案利用多个存储虚拟机 (SVM) 来托管卷，以实现高性能存储访问以及管理 SVM 上的用户主目录和其他集群工件。每个 SVM 都配置了网络接口和FlexGroup卷，并实施 QoS 策略以确保数据 SVM 的性能。有关 FlexGroups、存储虚拟机和ONTAP QoS 功能的更多信息，请参阅<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block>。</block>
  <block id="2a57ec7828afba5c513d03e967cb3884" category="section-title">解决方案硬件要求</block>
  <block id="b761a63ce0a1bd27710c7207a50b8577" category="paragraph">表 1 列出了实现一个、两个、四个或八个可扩展单元所需的存储硬件组件。有关服务器和网络的详细硬件要求，请参阅<block ref="b8ab7d3cc54802757d9a49bb252840ab" category="inline-link-rx"></block>。</block>
  <block id="a7504f8a3068ecf26f816d83dfcae5a8" category="cell">SU 大小</block>
  <block id="eb94f28ae18769ccde6259223dde0683" category="cell">AFF A90 系统</block>
  <block id="258b220fa2ed31020ab102479476e757" category="cell">存储集群互连交换机</block>
  <block id="9254819941449b706e4282e2f2e6a7b9" category="cell">可用容量（典型值：3.8TB SSD）</block>
  <block id="eb17bb52c3b173b3911725d1c9a194f0" category="cell">最大可用容量（配备 15.3TB NVMe SSD）</block>
  <block id="c9d196f41b3911fefebc23e6efbc32f4" category="cell">RU（典型值）</block>
  <block id="1fec42eb0945f00ee2125c78858d7366" category="cell">功率（典型值）</block>
  <block id="f04a7a4ef42eb207cec5a3d7fcc9d3fa" category="cell">555 TB</block>
  <block id="104bf07415681a49e985f5dd5895d4d6" category="cell">13.75PB</block>
  <block id="4f10ff6d954a760dbf5b59fb54597722" category="cell">7,300 瓦</block>
  <block id="830daef3058bf009b39d03050f58f3f4" category="cell">27.5PB</block>
  <block id="62aa76bddc36c76968deb0ae09c8063f" category="cell">14,600 瓦</block>
  <block id="76a4dd9b098f9a8877b8b79d0c80c5d3" category="cell">2PB</block>
  <block id="3b07c527868f20c47db7e08e0e02ced5" category="cell">55PB</block>
  <block id="f4680500c767e37e35c38315af80e9f9" category="cell">29,200瓦</block>
  <block id="e79a79f20fe06b0beb657745cf11949a" category="cell">4PB</block>
  <block id="1609fc8f39b0baac216cbb19fb420ef2" category="cell">110PB</block>
  <block id="ec8956637a99787bd197eacd77acce5e" category="cell">102</block>
  <block id="bc6012118a1ec87da87af67c6b3a0f74" category="cell">58,400瓦</block>
  <block id="0f37a7e60b292d864a5ac969ec04cc27" category="paragraph">*注意：* NetApp建议每个AFF A90 HA 对至少配备 24 个驱动器，以实现最佳性能。额外的内部驱动器、更大容量的驱动器和外部扩展驱动器架可实现更高的总容量，而不会影响系统性能。</block>
  <block id="d3469c07f7acce56e0d039ec0b164141" category="paragraph">表 2 列出了将AFF A90存储系统与 DGX SuperPOD 集成所需的软件组件和版本。 DGX SuperPOD 还涉及此处未列出的其他软件组件。请参阅<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block>了解完整详情。</block>
  <block id="0bd0e673df4c14cae45a11fac30c530b" category="cell">9.16.1</block>
  <block id="dbc8a3aaafc47a649eed1dcc0bc5155e" category="cell">10.24.11</block>
  <block id="c6d4f54ff5f7e221a70cdd46daa396b3" category="cell">6.3.1</block>
  <block id="09e619b353cb3d3ca08701e294bb9047" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS</block>
  <block id="51eed8fde1839744a1b920b0dacb0a0a" category="cell">5.10</block>
  <block id="f11a60eea5a7abfd75bb28890eaef1ec" category="paragraph">该存储解决方案经过NetApp和NVIDIA的多阶段验证，确保性能和可扩展性满足NVIDIA DGX SuperPOD的要求。该配置通过结合合成工作负载和真实 ML/DL 工作负载进行验证，以验证最大性能和应用程序互操作性。下表 3 提供了 DGX SuperPOD 部署中常见的典型工作负载及其数据要求的示例。</block>
  <block id="e203df30cd7f31417aee170026e44f70" category="paragraph">表 3) SuperPOD 工作负载示例。</block>
  <block id="a0db49ba470c1c9ae2128c3470339153" category="cell">级别</block>
  <block id="0ba48588b95eb9052082d27db3380801" category="cell">工作描述</block>
  <block id="c8ceada943dc5d58578660bf60d0762a" category="cell">数据集大小</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">标准</block>
  <block id="c7f0dd1953999823199f993b956164f6" category="cell">多个并发的 LLM 或微调训练作业和定期检查点，其中计算需求显著地主导了数据 I/O 需求。</block>
  <block id="f2db8117278a7bff3e0e0bff0571726d" category="cell">大多数数据集在训练期间都可以放入本地计算系统的内存缓存中。数据集是单一模态的，模型有数百万个参数。</block>
  <block id="53123044b4b65d0ad1b7ed0cfa4c3480" category="cell">增强型</block>
  <block id="c9e72abf53e870d36e47df81d7f139bf" category="cell">多个并发的多模式训练作业和定期检查点，其中数据 I/O 性能是端到端训练时间的重要因素。</block>
  <block id="981d20fc47284a9be8695e715a3d1d47" category="cell">数据集太大，无法放入本地计算系统的内存缓存，在训练期间需要更多的 I/O，不足以消除频繁 I/O 的需要。数据集具有多种模式，模型具有数十亿（或更多）个参数。</block>
  <block id="255eebee8e38299d9f7282ffa8b76db3" category="paragraph">表 4 显示了上述示例工作负载的性能指南。这些值表示在理想条件下这些工作负载可以产生的存储吞吐量。</block>
  <block id="fe54d8f94c652ba49e4aba03f3107a9c" category="paragraph">表 4) DGX SuperPOD 性能指南。</block>
  <block id="f5bab93f6f25cd702dcbcb4aad615260" category="cell">性能特点</block>
  <block id="94f3edd272dbb778616c50e083536c63" category="cell">标准 (GBps)</block>
  <block id="abaf1dc2e3d5bf424c74cd4566b0f1a3" category="cell">增强型 (GBps)</block>
  <block id="c5b9e837f1006565fbb01cd3b64d3df7" category="cell">单SU聚合系统读取</block>
  <block id="3def184ad8f4755ff269862ea77393dd" category="cell">125</block>
  <block id="8eb042782ea4dd597d037482af02c144" category="cell">单SU聚合系统写入</block>
  <block id="44f683a84163b3523afe57c2e008bc8c" category="cell">62</block>
  <block id="f53ce0357707bf3db713c9d71337529d" category="cell">4 SU 聚合系统读取</block>
  <block id="b73ce398c39f506af761d2277d853a92" category="cell">160</block>
  <block id="cee631121c2ec9232f3a2f028ad5c89b" category="cell">500</block>
  <block id="bc96df788d872dc23329bae80cc02619" category="cell">4 SU 聚合系统写入</block>
  <block id="6c9882bbac1c7093bd25041881277658" category="cell">250</block>
  <block id="ef6f2913d5f1e19a1aa781a5d72d6caa" category="inline-link">NVA-1175 NVIDIA DGX SuperPOD与NetApp AFF A90存储系统部署指南</block>
  <block id="6f8af77cdc63a21a3e7b99a2511ed006" category="list-text"><block ref="6f8af77cdc63a21a3e7b99a2511ed006" category="inline-link-rx"></block></block>
  <block id="4498f6091821057a5b12bbe00bad6fb7" category="inline-link">NVIDIA DGX B200 SuperPOD 参考架构</block>
  <block id="e0ef89706b7f0268557664ed42040243" category="list-text"><block ref="e0ef89706b7f0268557664ed42040243" category="inline-link-rx"></block></block>
  <block id="076218ee0774bfaae3fcf92a3241a9fe" category="inline-link">NVIDIA DGX H200 SuperPOD 参考架构</block>
  <block id="b02d06e7da163e15a51f5a0277a72641" category="list-text"><block ref="b02d06e7da163e15a51f5a0277a72641" category="inline-link-rx"></block></block>
  <block id="e9cc843bc2157ef28fd2c0657e05a6f0" category="inline-link">NVIDIA BaseCommand 软件</block>
  <block id="5b147f17197401088429ad2165ca94db" category="list-text"><block ref="5b147f17197401088429ad2165ca94db" category="inline-link-rx"></block></block>
  <block id="f6f89e67f0d14eefc85ee96a3de66d60" category="list-text"><block ref="f6f89e67f0d14eefc85ee96a3de66d60" category="inline-link-rx"></block></block>
  <block id="8365b73ca224de7f689b1708ed448af9" category="inline-link">+++ NetApp AI 解决方案文档+++</block>
  <block id="aed2dde7ddb9cf045a1de05c19aa6fe6" category="list-text"><block ref="aed2dde7ddb9cf045a1de05c19aa6fe6" category="inline-link-rx"></block></block>
  <block id="4245faba305e62f6fdc30b1ce8bf8ac3" category="inline-link">+++ NetApp安装和维护AFF存储系统+++</block>
  <block id="bf45808f34c6dcc540de81441ed8372a" category="list-text"><block ref="bf45808f34c6dcc540de81441ed8372a" category="inline-link-rx"></block></block>
  <block id="51af5c28c5aeade3eeee8efe1cf0c265" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>（包含大量 pNFS 信息的旧文档）</block>
  <block id="e84f1067b5e0c62707fee9cec31ec6e6" category="sidebar">搭载NVIDIA DGX SuperPOD 的NetApp AFF A90存储系统 - 设计</block>
  <block id="ebe830dbdb267fd10b3f4000455f19f2" category="sidebar">搭载NVIDIA DGX SuperPOD 的NetApp AFF A90存储系统 - 部署</block>
</blocks>